{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.23247e+00 0.00000e+00 8.14000e+00 ... 2.10000e+01 3.96900e+02\n",
      "  1.87200e+01]\n",
      " [2.17700e-02 8.25000e+01 2.03000e+00 ... 1.47000e+01 3.95380e+02\n",
      "  3.11000e+00]\n",
      " [4.89822e+00 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.75520e+02\n",
      "  3.26000e+00]\n",
      " ...\n",
      " [3.46600e-02 3.50000e+01 6.06000e+00 ... 1.69000e+01 3.62250e+02\n",
      "  7.83000e+00]\n",
      " [2.14918e+00 0.00000e+00 1.95800e+01 ... 1.47000e+01 2.61950e+02\n",
      "  1.57900e+01]\n",
      " [1.43900e-02 6.00000e+01 2.93000e+00 ... 1.56000e+01 3.76700e+02\n",
      "  4.38000e+00]]\n",
      "[[-0.27224633 -0.48361547 -0.43576161 ...  1.14850044  0.44807713\n",
      "   0.8252202 ]\n",
      " [-0.40342651  2.99178419 -1.33391162 ... -1.71818909  0.43190599\n",
      "  -1.32920239]\n",
      " [ 0.1249402  -0.48361547  1.0283258  ...  0.78447637  0.22061726\n",
      "  -1.30850006]\n",
      " ...\n",
      " [-0.40202987  0.99079651 -0.7415148  ... -0.71712291  0.07943894\n",
      "  -0.67776904]\n",
      " [-0.17292018 -0.48361547  1.24588095 ... -1.71818909 -0.98764362\n",
      "   0.42083466]\n",
      " [-0.40422614  2.04394792 -1.20161456 ... -1.30866202  0.23317118\n",
      "  -1.15392266]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "print(train_data)\n",
    "# \"you subtract the mean of the feature and divide by the standard deviation, so that the feature is centered around 0 and has a unit standard deviation\"\n",
    "# Called z score.\n",
    "\n",
    "# >>> a = np.array([[1, 2], [3, 4]])\n",
    "# >>> np.mean(a, axis=0)   -> Calculates mean.\n",
    "# array([2., 3.])          -> (1+3)/2\n",
    "# >>> np.std(a, axis=0)    -> Calculates standard deviation of axis 0.\n",
    "# array([1.,  1.])         -> ... TODO: add exact calculation example\n",
    "#\n",
    "# We should normalize our data, otherwise it is going to be hard for the network to learn. \n",
    "# Since some values of the input layer are much larger then others and therefore its harder for the model to adjust the weights to keep the wide spread in \"mind\".\n",
    "# We use here https://en.wikipedia.org/wiki/Standard_score\n",
    "# To archive this we need to aim for 1. and 2. (See further below)\n",
    "\n",
    "# 1. Goal is to have a \"expected value\" of 0. https://en.wikipedia.org/wiki/Expected_value\n",
    "# So basically this will move the x center of input deviation graph to the 0 for all data arrays.\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "# 2. Goal is to have a \"variance\" of 1. https://en.wikipedia.org/wiki/Variance\n",
    "# So basically this will normalize the X axis of the input deviation graph.\n",
    "# X axis of the input deviation graph will look then like ...-2σ -1σ 0σ 1σ 2σ... σ = standard deviation for all data arrays\n",
    "std = train_data.std(axis=0) \n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean \n",
    "test_data /= std\n",
    "print(train_data)\n",
    "print(train_data.std(axis=0)) # As you see its all 1 (Goal 2.)\n",
    "\n",
    "# Basically we have at the end for every data array the same input model (scale) in form of an array of x, where x represents with x*σ+mean the old value. (σ and mean is different for each axis)\n",
    "# \"normalization helps the backpropagation algorithm converge faster\"\n",
    "# To compare this with the MNIST example.\n",
    "# Y axis of the input deviation graph is count.\n",
    "# X axis of the input deviation graph is the gray scale.\n",
    "\n",
    "# Q: Can't we just map all axis into an range of [-1,+1]? (Min-Max method)?\n",
    "# A: Yes, but min max method is better for non bell shaped distribution, like MNIST. Because TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential() \n",
    "    model.add(layers.Dense(64, activation='relu',input_shape=(train_data.shape[1],))) \n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    # Regression: the output variable takes continuous values.\n",
    "    # Classification: the output variable takes class labels.\n",
    "    # Within regression analysis we try to find the function for continous data. E.g. a simple f(x) = x function.\n",
    "    # TODO: why mse loss and mae metrics for regression analysis?\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 192.2441 - mae: 10.3309 - val_loss: 37.9975 - val_mae: 4.0681\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 0s 748us/step - loss: 29.8365 - mae: 3.7726 - val_loss: 24.1729 - val_mae: 3.0439\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 0s 779us/step - loss: 20.8449 - mae: 3.0569 - val_loss: 18.4750 - val_mae: 2.6692\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 0s 769us/step - loss: 17.5897 - mae: 2.7772 - val_loss: 16.6840 - val_mae: 2.4758\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 0s 762us/step - loss: 16.4340 - mae: 2.7185 - val_loss: 14.1461 - val_mae: 2.4539\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 0s 774us/step - loss: 15.0285 - mae: 2.6207 - val_loss: 15.1479 - val_mae: 2.3791\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 14.5518 - mae: 2.5306 - val_loss: 12.6578 - val_mae: 2.2533\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 0s 758us/step - loss: 13.4322 - mae: 2.4057 - val_loss: 13.1357 - val_mae: 2.2720\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 0s 773us/step - loss: 13.4364 - mae: 2.3892 - val_loss: 10.3806 - val_mae: 2.0617\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 0s 849us/step - loss: 12.8013 - mae: 2.3112 - val_loss: 10.7596 - val_mae: 2.3072\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 0s 919us/step - loss: 11.6910 - mae: 2.2418 - val_loss: 9.1804 - val_mae: 2.0468\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 0s 924us/step - loss: 12.1792 - mae: 2.2769 - val_loss: 9.7775 - val_mae: 1.9920\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 0s 939us/step - loss: 11.5436 - mae: 2.2301 - val_loss: 9.7894 - val_mae: 1.9169\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 0s 812us/step - loss: 11.5611 - mae: 2.2606 - val_loss: 8.5939 - val_mae: 2.0551\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 0s 762us/step - loss: 11.0585 - mae: 2.2534 - val_loss: 9.7685 - val_mae: 2.0526\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 0s 931us/step - loss: 10.8811 - mae: 2.1621 - val_loss: 8.5374 - val_mae: 1.9724\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 0s 816us/step - loss: 10.6601 - mae: 2.1674 - val_loss: 9.4152 - val_mae: 2.2411\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 0s 788us/step - loss: 10.0806 - mae: 2.1174 - val_loss: 8.2355 - val_mae: 1.8971\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 0s 862us/step - loss: 10.2685 - mae: 2.0965 - val_loss: 8.3009 - val_mae: 2.0979\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 0s 824us/step - loss: 9.5809 - mae: 2.0552 - val_loss: 8.2421 - val_mae: 2.0178\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 9.9531 - mae: 2.0523 - val_loss: 10.3525 - val_mae: 2.1729\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 9.8705 - mae: 2.0415 - val_loss: 8.0606 - val_mae: 1.9901\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 0s 751us/step - loss: 9.5027 - mae: 2.0304 - val_loss: 7.5022 - val_mae: 1.8398\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 9.1046 - mae: 2.0173 - val_loss: 7.9762 - val_mae: 2.1787\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 8.9266 - mae: 2.0290 - val_loss: 7.5121 - val_mae: 1.9588\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 0s 749us/step - loss: 9.0042 - mae: 1.9786 - val_loss: 8.0816 - val_mae: 2.0616\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 8.8130 - mae: 1.9444 - val_loss: 8.0490 - val_mae: 2.0529\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 8.7661 - mae: 1.9422 - val_loss: 8.4782 - val_mae: 2.0705\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 8.3767 - mae: 1.9617 - val_loss: 10.5768 - val_mae: 2.1728\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 8.6231 - mae: 1.9478 - val_loss: 8.3317 - val_mae: 2.1907\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 8.2930 - mae: 1.9169 - val_loss: 8.6274 - val_mae: 2.1270\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 7.7637 - mae: 1.9410 - val_loss: 8.7426 - val_mae: 2.1907\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 8.6780 - mae: 1.9254 - val_loss: 7.3293 - val_mae: 2.0304\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 0s 752us/step - loss: 8.0469 - mae: 1.8554 - val_loss: 6.8655 - val_mae: 1.9931\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 0s 822us/step - loss: 7.7248 - mae: 1.8643 - val_loss: 9.2160 - val_mae: 2.1356\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 0s 912us/step - loss: 7.9994 - mae: 1.8874 - val_loss: 7.1575 - val_mae: 1.9068\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 0s 934us/step - loss: 7.9884 - mae: 1.8823 - val_loss: 8.0912 - val_mae: 2.0094\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 0s 918us/step - loss: 7.6474 - mae: 1.8176 - val_loss: 6.7920 - val_mae: 1.9430\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 0s 861us/step - loss: 7.3303 - mae: 1.8467 - val_loss: 7.8781 - val_mae: 1.9175\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 7.9507 - mae: 1.8642 - val_loss: 7.9575 - val_mae: 2.2080\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 7.5196 - mae: 1.8587 - val_loss: 6.9282 - val_mae: 2.0001\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 7.2430 - mae: 1.8317 - val_loss: 8.9466 - val_mae: 2.1509\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 7.5529 - mae: 1.8632 - val_loss: 7.2454 - val_mae: 1.8757\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 6.6137 - mae: 1.7521 - val_loss: 8.4067 - val_mae: 2.0769\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 7.0317 - mae: 1.7515 - val_loss: 12.5780 - val_mae: 2.7838\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 7.1197 - mae: 1.7932 - val_loss: 7.2913 - val_mae: 1.9205\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 7.1869 - mae: 1.7736 - val_loss: 8.5987 - val_mae: 2.1841\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 7.2027 - mae: 1.7166 - val_loss: 7.4711 - val_mae: 1.9014\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 7.0681 - mae: 1.7550 - val_loss: 9.1779 - val_mae: 2.0977\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 7.1263 - mae: 1.7603 - val_loss: 10.6602 - val_mae: 2.5094\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 6.7610 - mae: 1.6880 - val_loss: 8.2611 - val_mae: 2.1644\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 6.7181 - mae: 1.6945 - val_loss: 7.9744 - val_mae: 2.1730\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 6.4141 - mae: 1.6769 - val_loss: 7.7085 - val_mae: 2.0793\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 6.1534 - mae: 1.6751 - val_loss: 7.7442 - val_mae: 1.9965\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 0s 702us/step - loss: 6.5113 - mae: 1.6861 - val_loss: 8.7035 - val_mae: 2.2998\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 6.4931 - mae: 1.6043 - val_loss: 7.5213 - val_mae: 2.0859\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 5.9908 - mae: 1.6393 - val_loss: 10.9269 - val_mae: 2.5534\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 0s 929us/step - loss: 6.2052 - mae: 1.6501 - val_loss: 7.4796 - val_mae: 2.0260\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 0s 910us/step - loss: 6.1162 - mae: 1.5758 - val_loss: 8.2416 - val_mae: 2.1629\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 915us/step - loss: 5.6943 - mae: 1.6144 - val_loss: 7.9935 - val_mae: 1.9892\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 5.9626 - mae: 1.6208 - val_loss: 8.0107 - val_mae: 2.0344\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 5.5521 - mae: 1.5129 - val_loss: 7.5436 - val_mae: 1.9592\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 6.1955 - mae: 1.6680 - val_loss: 7.9092 - val_mae: 1.9706\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 5.7950 - mae: 1.5700 - val_loss: 8.3681 - val_mae: 2.1919\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 0s 697us/step - loss: 5.8506 - mae: 1.6528 - val_loss: 8.3755 - val_mae: 2.2163\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 5.5432 - mae: 1.5724 - val_loss: 8.0366 - val_mae: 2.0796\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 0s 758us/step - loss: 5.9790 - mae: 1.6199 - val_loss: 7.7687 - val_mae: 1.8960\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 0s 744us/step - loss: 5.4706 - mae: 1.5522 - val_loss: 8.2384 - val_mae: 1.9708\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 0s 754us/step - loss: 6.0413 - mae: 1.5932 - val_loss: 8.7934 - val_mae: 2.0925\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 0s 749us/step - loss: 5.8331 - mae: 1.5649 - val_loss: 8.2865 - val_mae: 1.9868\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 0s 747us/step - loss: 5.7927 - mae: 1.5645 - val_loss: 8.1396 - val_mae: 2.1122\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 5.4721 - mae: 1.5508 - val_loss: 11.7716 - val_mae: 2.6926\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 5.5226 - mae: 1.5547 - val_loss: 10.3204 - val_mae: 2.5492\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 5.6479 - mae: 1.5604 - val_loss: 9.0501 - val_mae: 2.1042\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 5.5001 - mae: 1.5292 - val_loss: 9.4663 - val_mae: 2.2684\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 5.4485 - mae: 1.5336 - val_loss: 7.9183 - val_mae: 2.1086\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 5.0751 - mae: 1.5115 - val_loss: 8.2116 - val_mae: 1.9747\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 5.0343 - mae: 1.4917 - val_loss: 8.5245 - val_mae: 2.0685\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 5.2550 - mae: 1.4888 - val_loss: 8.5158 - val_mae: 2.0751\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 5.1787 - mae: 1.4996 - val_loss: 9.9204 - val_mae: 2.3923\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 5.0198 - mae: 1.4777 - val_loss: 8.5564 - val_mae: 2.1032\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 5.0534 - mae: 1.5335 - val_loss: 9.2506 - val_mae: 2.1486\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 4.9797 - mae: 1.5606 - val_loss: 9.3776 - val_mae: 2.2900\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 5.1032 - mae: 1.4591 - val_loss: 8.0884 - val_mae: 2.0153\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 0s 697us/step - loss: 4.8050 - mae: 1.4474 - val_loss: 9.2384 - val_mae: 2.3378\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 4.8262 - mae: 1.4498 - val_loss: 9.4264 - val_mae: 2.1765\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 4.7213 - mae: 1.4433 - val_loss: 8.3014 - val_mae: 2.0945\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 4.5633 - mae: 1.4562 - val_loss: 9.6940 - val_mae: 2.1766\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 4.7082 - mae: 1.4767 - val_loss: 9.7505 - val_mae: 2.4022\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 5.0356 - mae: 1.4529 - val_loss: 8.7411 - val_mae: 2.2124\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 4.8246 - mae: 1.4238 - val_loss: 10.3361 - val_mae: 2.5143\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 4.5865 - mae: 1.4306 - val_loss: 9.7179 - val_mae: 2.2077\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 4.6076 - mae: 1.4393 - val_loss: 9.1464 - val_mae: 2.1604\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 0s 699us/step - loss: 4.7558 - mae: 1.4307 - val_loss: 11.2234 - val_mae: 2.6184\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 0s 701us/step - loss: 4.4922 - mae: 1.4123 - val_loss: 9.1673 - val_mae: 2.1082\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 4.0890 - mae: 1.3955 - val_loss: 9.5229 - val_mae: 2.1835\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 0s 699us/step - loss: 4.2197 - mae: 1.4157 - val_loss: 8.3199 - val_mae: 2.0668\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 4.2487 - mae: 1.4036 - val_loss: 10.5506 - val_mae: 2.3584\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 4.5748 - mae: 1.4117 - val_loss: 8.6975 - val_mae: 2.1181\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 4.6731 - mae: 1.3976 - val_loss: 9.3813 - val_mae: 2.3569\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 4.3377 - mae: 1.3699 - val_loss: 8.2390 - val_mae: 2.0960\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 4.4139 - mae: 1.3813 - val_loss: 10.6669 - val_mae: 2.5949\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 4.2727 - mae: 1.3879 - val_loss: 12.4553 - val_mae: 2.6526\n",
      "Epoch 104/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 4.0617 - mae: 1.3432 - val_loss: 9.5090 - val_mae: 2.2757\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 0s 699us/step - loss: 4.5245 - mae: 1.4584 - val_loss: 9.4518 - val_mae: 2.3562\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 4.2929 - mae: 1.3548 - val_loss: 10.1306 - val_mae: 2.2801\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 4.1716 - mae: 1.3418 - val_loss: 9.6128 - val_mae: 2.4013\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 0s 698us/step - loss: 4.3262 - mae: 1.4067 - val_loss: 11.3443 - val_mae: 2.5896\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 4.1786 - mae: 1.3764 - val_loss: 8.7261 - val_mae: 2.2521\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 4.1785 - mae: 1.3590 - val_loss: 9.0800 - val_mae: 2.2136\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 4.0793 - mae: 1.3019 - val_loss: 11.2252 - val_mae: 2.5020\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 4.1802 - mae: 1.3164 - val_loss: 10.2423 - val_mae: 2.4358\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 3.7201 - mae: 1.2799 - val_loss: 10.6742 - val_mae: 2.4610\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 3.8840 - mae: 1.3256 - val_loss: 12.9708 - val_mae: 2.8704\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 4.0866 - mae: 1.2972 - val_loss: 11.1716 - val_mae: 2.5964\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 3.8057 - mae: 1.3386 - val_loss: 10.3587 - val_mae: 2.2686\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 3.8599 - mae: 1.3279 - val_loss: 9.2543 - val_mae: 2.2507\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 3.9514 - mae: 1.3169 - val_loss: 9.8635 - val_mae: 2.2125\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 3.6795 - mae: 1.3234 - val_loss: 11.6765 - val_mae: 2.6563\n",
      "Epoch 120/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 784us/step - loss: 3.9122 - mae: 1.3112 - val_loss: 9.0670 - val_mae: 2.2188\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 3.8791 - mae: 1.3306 - val_loss: 9.1386 - val_mae: 2.1808\n",
      "Epoch 122/500\n",
      "303/303 [==============================] - 0s 791us/step - loss: 3.7367 - mae: 1.3281 - val_loss: 12.4299 - val_mae: 2.7730\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 3.7063 - mae: 1.3351 - val_loss: 10.6514 - val_mae: 2.5286\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 3.7381 - mae: 1.3407 - val_loss: 9.6863 - val_mae: 2.3786\n",
      "Epoch 125/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 3.5375 - mae: 1.3070 - val_loss: 9.4226 - val_mae: 2.3870\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 3.3604 - mae: 1.2858 - val_loss: 10.3045 - val_mae: 2.3367\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 0s 697us/step - loss: 3.6316 - mae: 1.2831 - val_loss: 10.5455 - val_mae: 2.2449\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 3.3948 - mae: 1.2522 - val_loss: 9.9123 - val_mae: 2.3567\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 3.6703 - mae: 1.2709 - val_loss: 9.7979 - val_mae: 2.2863\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 3.7941 - mae: 1.2833 - val_loss: 9.6935 - val_mae: 2.3268\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 3.4034 - mae: 1.2458 - val_loss: 9.5929 - val_mae: 2.2099\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 3.4482 - mae: 1.2458 - val_loss: 9.8325 - val_mae: 2.3876\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 3.4280 - mae: 1.2589 - val_loss: 9.4146 - val_mae: 2.2061\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 3.2977 - mae: 1.2277 - val_loss: 12.1313 - val_mae: 2.7562\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 3.1813 - mae: 1.2044 - val_loss: 10.6810 - val_mae: 2.3773\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 3.4981 - mae: 1.2892 - val_loss: 10.7723 - val_mae: 2.4187\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 3.2290 - mae: 1.2579 - val_loss: 9.4850 - val_mae: 2.3450\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 3.1504 - mae: 1.2148 - val_loss: 10.4018 - val_mae: 2.4228\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 2.8706 - mae: 1.2169 - val_loss: 11.8841 - val_mae: 2.5577\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 3.1677 - mae: 1.2330 - val_loss: 14.5627 - val_mae: 2.9786\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 3.3531 - mae: 1.2111 - val_loss: 11.9210 - val_mae: 2.7298\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 3.2465 - mae: 1.2392 - val_loss: 10.7297 - val_mae: 2.3569\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 0s 751us/step - loss: 3.1482 - mae: 1.2134 - val_loss: 9.6752 - val_mae: 2.2136\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 2.9819 - mae: 1.1670 - val_loss: 9.8320 - val_mae: 2.2814\n",
      "Epoch 145/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 3.3918 - mae: 1.2098 - val_loss: 10.4450 - val_mae: 2.4409\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 3.0073 - mae: 1.2254 - val_loss: 9.5893 - val_mae: 2.4264\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 0s 775us/step - loss: 2.9053 - mae: 1.2233 - val_loss: 10.2620 - val_mae: 2.4837\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 3.0951 - mae: 1.2233 - val_loss: 10.0562 - val_mae: 2.3281\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 3.0427 - mae: 1.2240 - val_loss: 9.9490 - val_mae: 2.2467\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 3.1815 - mae: 1.1946 - val_loss: 11.3304 - val_mae: 2.5662\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 3.0972 - mae: 1.2166 - val_loss: 10.0170 - val_mae: 2.4017\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 3.0185 - mae: 1.2261 - val_loss: 9.6073 - val_mae: 2.2848\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 3.1927 - mae: 1.2605 - val_loss: 10.4822 - val_mae: 2.4026\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 2.9309 - mae: 1.1544 - val_loss: 10.4332 - val_mae: 2.4554\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 2.9847 - mae: 1.2072 - val_loss: 11.0571 - val_mae: 2.5182\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 0s 748us/step - loss: 2.8799 - mae: 1.1798 - val_loss: 11.2649 - val_mae: 2.4488\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 2.9307 - mae: 1.1993 - val_loss: 9.7381 - val_mae: 2.3505\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 2.9286 - mae: 1.1572 - val_loss: 11.1858 - val_mae: 2.5152\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 2.8915 - mae: 1.1863 - val_loss: 11.2261 - val_mae: 2.4552\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 0s 744us/step - loss: 3.2018 - mae: 1.1893 - val_loss: 9.4363 - val_mae: 2.3055\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 0s 773us/step - loss: 2.8300 - mae: 1.1463 - val_loss: 13.0491 - val_mae: 2.6607\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 2.9371 - mae: 1.1845 - val_loss: 11.9643 - val_mae: 2.4998\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 2.9130 - mae: 1.1702 - val_loss: 10.0188 - val_mae: 2.2173\n",
      "Epoch 164/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 2.9845 - mae: 1.1809 - val_loss: 9.0943 - val_mae: 2.2083\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 2.7430 - mae: 1.1423 - val_loss: 9.3137 - val_mae: 2.1931\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 2.9489 - mae: 1.1811 - val_loss: 9.9822 - val_mae: 2.3870\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 2.6724 - mae: 1.1132 - val_loss: 10.4718 - val_mae: 2.4067\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 0s 702us/step - loss: 2.5360 - mae: 1.1491 - val_loss: 11.1171 - val_mae: 2.3360\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 2.7660 - mae: 1.1653 - val_loss: 9.7389 - val_mae: 2.3073\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 2.3479 - mae: 1.0941 - val_loss: 11.4823 - val_mae: 2.4105\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 2.6019 - mae: 1.1159 - val_loss: 14.5979 - val_mae: 2.8626\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 2.7669 - mae: 1.1395 - val_loss: 10.1412 - val_mae: 2.2786\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 2.7575 - mae: 1.1512 - val_loss: 10.4198 - val_mae: 2.4686\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 2.7214 - mae: 1.1272 - val_loss: 10.3829 - val_mae: 2.5649\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 2.3530 - mae: 1.1316 - val_loss: 11.6586 - val_mae: 2.5561\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 0s 751us/step - loss: 2.4300 - mae: 1.0915 - val_loss: 12.1254 - val_mae: 2.5270\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 2.5908 - mae: 1.1358 - val_loss: 9.7372 - val_mae: 2.3580\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 2.7643 - mae: 1.1411 - val_loss: 9.9574 - val_mae: 2.3574\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 717us/step - loss: 2.5361 - mae: 1.1338 - val_loss: 9.8974 - val_mae: 2.3599\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 2.5628 - mae: 1.1022 - val_loss: 16.4776 - val_mae: 3.1216\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 2.2632 - mae: 1.1119 - val_loss: 10.2990 - val_mae: 2.3114\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 2.5771 - mae: 1.1306 - val_loss: 10.2340 - val_mae: 2.3950\n",
      "Epoch 183/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 2.3532 - mae: 1.1146 - val_loss: 10.3809 - val_mae: 2.4807\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 0s 748us/step - loss: 2.5645 - mae: 1.1486 - val_loss: 10.2402 - val_mae: 2.3910\n",
      "Epoch 185/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 2.3151 - mae: 1.1263 - val_loss: 10.5291 - val_mae: 2.3171\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 0s 758us/step - loss: 2.4611 - mae: 1.1107 - val_loss: 10.5366 - val_mae: 2.4256\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 0s 753us/step - loss: 2.3586 - mae: 1.0355 - val_loss: 11.8644 - val_mae: 2.4863\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 2.4409 - mae: 1.1156 - val_loss: 9.4839 - val_mae: 2.2620\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 2.4381 - mae: 1.1220 - val_loss: 10.2096 - val_mae: 2.3855\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 2.4447 - mae: 1.1210 - val_loss: 10.8185 - val_mae: 2.3936\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 0s 778us/step - loss: 2.2634 - mae: 1.0780 - val_loss: 9.7356 - val_mae: 2.3113\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 0s 744us/step - loss: 2.0667 - mae: 1.0601 - val_loss: 10.4087 - val_mae: 2.4383\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 2.1088 - mae: 1.0599 - val_loss: 9.7928 - val_mae: 2.3186\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 2.4895 - mae: 1.1014 - val_loss: 10.2631 - val_mae: 2.4458\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 0s 748us/step - loss: 2.1331 - mae: 1.0747 - val_loss: 10.1054 - val_mae: 2.3490\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 2.4764 - mae: 1.1327 - val_loss: 10.7859 - val_mae: 2.3611\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 2.3031 - mae: 1.0753 - val_loss: 10.0535 - val_mae: 2.3132\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 2.2713 - mae: 1.0947 - val_loss: 9.5983 - val_mae: 2.3108\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.9886 - mae: 1.0285 - val_loss: 9.5843 - val_mae: 2.3366\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 2.0034 - mae: 1.0319 - val_loss: 11.4200 - val_mae: 2.6838\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 2.1807 - mae: 1.0403 - val_loss: 10.6096 - val_mae: 2.3784\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 1.9226 - mae: 0.9523 - val_loss: 9.5816 - val_mae: 2.3346\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 0s 698us/step - loss: 2.1426 - mae: 1.0375 - val_loss: 10.3073 - val_mae: 2.3793\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 2.1230 - mae: 1.0530 - val_loss: 10.5721 - val_mae: 2.3911\n",
      "Epoch 205/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 2.1024 - mae: 1.0345 - val_loss: 9.5739 - val_mae: 2.2805\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 2.0051 - mae: 1.0132 - val_loss: 9.9074 - val_mae: 2.3175\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 0s 750us/step - loss: 1.9410 - mae: 1.0123 - val_loss: 10.1216 - val_mae: 2.4405\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 2.0382 - mae: 1.0186 - val_loss: 9.1785 - val_mae: 2.3338\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 0s 744us/step - loss: 1.9527 - mae: 0.9996 - val_loss: 9.6452 - val_mae: 2.3240\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 2.1950 - mae: 1.0594 - val_loss: 10.2169 - val_mae: 2.3608\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.9959 - mae: 1.0285 - val_loss: 9.8695 - val_mae: 2.3364\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.9717 - mae: 1.0291 - val_loss: 9.6444 - val_mae: 2.3414\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.9178 - mae: 1.0147 - val_loss: 11.1241 - val_mae: 2.4173\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.7191 - mae: 0.9848 - val_loss: 10.2947 - val_mae: 2.3840\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 2.0139 - mae: 0.9772 - val_loss: 11.0898 - val_mae: 2.4548\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 2.0155 - mae: 1.0236 - val_loss: 9.9606 - val_mae: 2.4456\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.9904 - mae: 1.0004 - val_loss: 9.7423 - val_mae: 2.2945\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.9034 - mae: 1.0276 - val_loss: 10.5243 - val_mae: 2.3898\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 1.9275 - mae: 0.9800 - val_loss: 9.9169 - val_mae: 2.3658\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 1.9198 - mae: 0.9738 - val_loss: 9.8739 - val_mae: 2.3899\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 2.1310 - mae: 1.0334 - val_loss: 10.8370 - val_mae: 2.4320\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 1.7019 - mae: 0.9530 - val_loss: 9.5803 - val_mae: 2.2709\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.9512 - mae: 1.0286 - val_loss: 10.3672 - val_mae: 2.4155\n",
      "Epoch 224/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 1.6585 - mae: 0.9461 - val_loss: 10.0900 - val_mae: 2.3515\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 2.0282 - mae: 1.0321 - val_loss: 10.0776 - val_mae: 2.3360\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 0s 751us/step - loss: 1.7554 - mae: 0.9618 - val_loss: 10.3890 - val_mae: 2.3526\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 1.8194 - mae: 0.9984 - val_loss: 9.6117 - val_mae: 2.3317\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 1.7789 - mae: 0.9600 - val_loss: 9.8879 - val_mae: 2.2840\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 1.8487 - mae: 0.9807 - val_loss: 9.7474 - val_mae: 2.3022\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 1.6665 - mae: 0.9492 - val_loss: 9.6544 - val_mae: 2.3660\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.7280 - mae: 0.9784 - val_loss: 10.8360 - val_mae: 2.4594\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 1.8764 - mae: 0.9908 - val_loss: 10.7883 - val_mae: 2.3706\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.8243 - mae: 1.0117 - val_loss: 11.1357 - val_mae: 2.4399\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.6580 - mae: 0.9711 - val_loss: 11.2516 - val_mae: 2.5167\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.6861 - mae: 0.9491 - val_loss: 11.2993 - val_mae: 2.4791\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 0s 752us/step - loss: 1.7724 - mae: 0.9586 - val_loss: 11.2662 - val_mae: 2.5276\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 1.6035 - mae: 0.9517 - val_loss: 11.4582 - val_mae: 2.4849\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 718us/step - loss: 1.6861 - mae: 0.9560 - val_loss: 10.8072 - val_mae: 2.4236\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.6744 - mae: 0.9666 - val_loss: 11.0904 - val_mae: 2.4110\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 1.7092 - mae: 0.9568 - val_loss: 9.2218 - val_mae: 2.1936\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 1.7997 - mae: 0.9805 - val_loss: 10.1700 - val_mae: 2.3391\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 1.7481 - mae: 0.9589 - val_loss: 11.3115 - val_mae: 2.4100\n",
      "Epoch 243/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 1.5879 - mae: 0.9368 - val_loss: 9.3910 - val_mae: 2.2833\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.5266 - mae: 0.9052 - val_loss: 12.5360 - val_mae: 2.5808\n",
      "Epoch 245/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.7010 - mae: 0.9270 - val_loss: 10.7102 - val_mae: 2.3470\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 1.5688 - mae: 0.9231 - val_loss: 10.7034 - val_mae: 2.3764\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 1.5509 - mae: 0.9052 - val_loss: 9.7732 - val_mae: 2.2926\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 1.5175 - mae: 0.9164 - val_loss: 11.1015 - val_mae: 2.4264\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.7176 - mae: 0.9789 - val_loss: 10.6316 - val_mae: 2.3968\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.7118 - mae: 0.9183 - val_loss: 10.8842 - val_mae: 2.3346\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.5309 - mae: 0.9348 - val_loss: 10.4129 - val_mae: 2.3785\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.5237 - mae: 0.8892 - val_loss: 9.9698 - val_mae: 2.3278\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 1.5284 - mae: 0.9180 - val_loss: 11.5237 - val_mae: 2.4728\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.4535 - mae: 0.8709 - val_loss: 9.6079 - val_mae: 2.2915\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 1.5486 - mae: 0.9176 - val_loss: 10.7971 - val_mae: 2.3779\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 1.5003 - mae: 0.8986 - val_loss: 9.5795 - val_mae: 2.2650\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 1.7050 - mae: 0.9274 - val_loss: 9.9147 - val_mae: 2.3263\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.5091 - mae: 0.8916 - val_loss: 9.5384 - val_mae: 2.3302\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.4376 - mae: 0.9112 - val_loss: 11.9689 - val_mae: 2.5998\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.6848 - mae: 0.9506 - val_loss: 10.3144 - val_mae: 2.3860\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.4185 - mae: 0.8866 - val_loss: 10.7962 - val_mae: 2.4216\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.5584 - mae: 0.9285 - val_loss: 10.7629 - val_mae: 2.4339\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 1.5566 - mae: 0.9092 - val_loss: 10.5537 - val_mae: 2.3864\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 1.4661 - mae: 0.8797 - val_loss: 10.5537 - val_mae: 2.3797\n",
      "Epoch 265/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 1.3386 - mae: 0.8438 - val_loss: 11.4631 - val_mae: 2.5551\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 1.4540 - mae: 0.9012 - val_loss: 10.8076 - val_mae: 2.3646\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.5295 - mae: 0.9000 - val_loss: 12.2585 - val_mae: 2.6267\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 1.5258 - mae: 0.9262 - val_loss: 10.3709 - val_mae: 2.4692\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 1.4114 - mae: 0.8687 - val_loss: 9.2018 - val_mae: 2.2470\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 0s 760us/step - loss: 1.3559 - mae: 0.8723 - val_loss: 9.8591 - val_mae: 2.4358\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 1.4755 - mae: 0.8941 - val_loss: 10.1341 - val_mae: 2.3301\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 1.3954 - mae: 0.8752 - val_loss: 9.7014 - val_mae: 2.2907\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.3504 - mae: 0.8504 - val_loss: 10.4543 - val_mae: 2.4273\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 1.4700 - mae: 0.9075 - val_loss: 9.6254 - val_mae: 2.3371\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 0s 754us/step - loss: 1.4350 - mae: 0.8555 - val_loss: 9.2014 - val_mae: 2.2616\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 0s 751us/step - loss: 1.6135 - mae: 0.9034 - val_loss: 9.9869 - val_mae: 2.2858\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 1.3872 - mae: 0.8457 - val_loss: 10.2180 - val_mae: 2.4163\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 0s 754us/step - loss: 1.3926 - mae: 0.8657 - val_loss: 10.7694 - val_mae: 2.3602\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 1.3310 - mae: 0.8535 - val_loss: 9.6099 - val_mae: 2.3350\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 0s 744us/step - loss: 1.4054 - mae: 0.8554 - val_loss: 10.9492 - val_mae: 2.3762\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 0s 750us/step - loss: 1.5392 - mae: 0.8861 - val_loss: 10.4511 - val_mae: 2.3961\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 0s 761us/step - loss: 1.4537 - mae: 0.8583 - val_loss: 9.9826 - val_mae: 2.3386\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 1.4813 - mae: 0.8529 - val_loss: 10.1491 - val_mae: 2.4328\n",
      "Epoch 284/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 1.2722 - mae: 0.8519 - val_loss: 10.0583 - val_mae: 2.3751\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.3422 - mae: 0.8689 - val_loss: 10.5944 - val_mae: 2.4494\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.5113 - mae: 0.8953 - val_loss: 9.9131 - val_mae: 2.3761\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 1.2781 - mae: 0.8550 - val_loss: 11.6996 - val_mae: 2.5173\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.3423 - mae: 0.8654 - val_loss: 11.6650 - val_mae: 2.5647\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 1.0925 - mae: 0.7884 - val_loss: 10.4875 - val_mae: 2.3704\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 1.5689 - mae: 0.8928 - val_loss: 10.7280 - val_mae: 2.4157\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 1.0979 - mae: 0.7616 - val_loss: 11.7146 - val_mae: 2.5811\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 1.4744 - mae: 0.8926 - val_loss: 11.1622 - val_mae: 2.4717\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.4123 - mae: 0.8552 - val_loss: 9.3810 - val_mae: 2.3435\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.2826 - mae: 0.8193 - val_loss: 10.4005 - val_mae: 2.4491\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.4279 - mae: 0.8838 - val_loss: 11.7132 - val_mae: 2.5682\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 0s 778us/step - loss: 1.2803 - mae: 0.8153 - val_loss: 11.2662 - val_mae: 2.4933\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 707us/step - loss: 1.2875 - mae: 0.8227 - val_loss: 10.5827 - val_mae: 2.4178\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.2217 - mae: 0.8268 - val_loss: 11.3189 - val_mae: 2.5171\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 1.3743 - mae: 0.8361 - val_loss: 11.1069 - val_mae: 2.5580\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.5082 - mae: 0.8740 - val_loss: 10.0630 - val_mae: 2.4266\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 1.3554 - mae: 0.8033 - val_loss: 10.0962 - val_mae: 2.4767\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.1764 - mae: 0.7980 - val_loss: 9.4503 - val_mae: 2.3446\n",
      "Epoch 303/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.4358 - mae: 0.8471 - val_loss: 9.2579 - val_mae: 2.2730\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.3902 - mae: 0.8840 - val_loss: 11.0583 - val_mae: 2.4008\n",
      "Epoch 305/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.1993 - mae: 0.8239 - val_loss: 9.6126 - val_mae: 2.3230\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.3226 - mae: 0.8324 - val_loss: 11.5382 - val_mae: 2.4778\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.2412 - mae: 0.8283 - val_loss: 11.5157 - val_mae: 2.5574\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.2681 - mae: 0.8304 - val_loss: 9.8756 - val_mae: 2.3640\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.3351 - mae: 0.8369 - val_loss: 10.2711 - val_mae: 2.3805\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 1.2884 - mae: 0.8245 - val_loss: 10.4163 - val_mae: 2.3707\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 1.2731 - mae: 0.8261 - val_loss: 10.8334 - val_mae: 2.4218\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.2654 - mae: 0.8352 - val_loss: 10.6188 - val_mae: 2.3333\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 1.2461 - mae: 0.8437 - val_loss: 10.2843 - val_mae: 2.4182\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 1.1824 - mae: 0.7880 - val_loss: 12.1547 - val_mae: 2.5479\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 1.2210 - mae: 0.8027 - val_loss: 10.5604 - val_mae: 2.3045\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 1.1844 - mae: 0.8278 - val_loss: 12.6325 - val_mae: 2.5553\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.4283 - mae: 0.8307 - val_loss: 11.5769 - val_mae: 2.3746\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 0s 747us/step - loss: 1.2613 - mae: 0.8155 - val_loss: 11.0606 - val_mae: 2.4927\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 1.3668 - mae: 0.8234 - val_loss: 10.3069 - val_mae: 2.3390\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 0s 782us/step - loss: 1.2718 - mae: 0.8411 - val_loss: 11.4568 - val_mae: 2.5720\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 1.2005 - mae: 0.7971 - val_loss: 9.6073 - val_mae: 2.2951\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 1.0881 - mae: 0.7761 - val_loss: 9.5186 - val_mae: 2.3341\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 1.3022 - mae: 0.8318 - val_loss: 10.9957 - val_mae: 2.4286\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 1.3335 - mae: 0.8565 - val_loss: 9.9203 - val_mae: 2.3928\n",
      "Epoch 325/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 1.2786 - mae: 0.8319 - val_loss: 9.9132 - val_mae: 2.3712\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.2565 - mae: 0.8041 - val_loss: 10.7359 - val_mae: 2.4669\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.2732 - mae: 0.8512 - val_loss: 11.1367 - val_mae: 2.5768\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.1659 - mae: 0.7782 - val_loss: 10.5029 - val_mae: 2.3633\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 1.0320 - mae: 0.7544 - val_loss: 10.9061 - val_mae: 2.4037\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 1.3586 - mae: 0.7988 - val_loss: 10.9056 - val_mae: 2.4963\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 1.2609 - mae: 0.8018 - val_loss: 10.0834 - val_mae: 2.3293\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 1.2071 - mae: 0.8248 - val_loss: 10.1076 - val_mae: 2.3793\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.1415 - mae: 0.8068 - val_loss: 11.1699 - val_mae: 2.4880\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.3182 - mae: 0.8197 - val_loss: 10.4581 - val_mae: 2.3987\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 1.1341 - mae: 0.7975 - val_loss: 11.7635 - val_mae: 2.4406\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.1281 - mae: 0.7568 - val_loss: 12.4134 - val_mae: 2.6834\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.2036 - mae: 0.8125 - val_loss: 11.4106 - val_mae: 2.5222\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 1.2200 - mae: 0.7902 - val_loss: 10.1622 - val_mae: 2.3455\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 0s 756us/step - loss: 1.1786 - mae: 0.7873 - val_loss: 10.9627 - val_mae: 2.4556\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.1207 - mae: 0.7513 - val_loss: 11.2637 - val_mae: 2.4609\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 0s 702us/step - loss: 1.1951 - mae: 0.8019 - val_loss: 10.6027 - val_mae: 2.4477\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.0485 - mae: 0.7648 - val_loss: 10.8485 - val_mae: 2.4104\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.1682 - mae: 0.7924 - val_loss: 10.7612 - val_mae: 2.5733\n",
      "Epoch 344/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.2080 - mae: 0.8112 - val_loss: 9.9938 - val_mae: 2.3958\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.3685 - mae: 0.8257 - val_loss: 11.6035 - val_mae: 2.4604\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 0.9826 - mae: 0.7236 - val_loss: 11.6356 - val_mae: 2.5079\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.1595 - mae: 0.7632 - val_loss: 11.1655 - val_mae: 2.5247\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 1.0457 - mae: 0.7564 - val_loss: 10.4755 - val_mae: 2.4137\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 1.2165 - mae: 0.7844 - val_loss: 11.0009 - val_mae: 2.4479\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.1229 - mae: 0.7157 - val_loss: 9.3252 - val_mae: 2.3101\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.9909 - mae: 0.7340 - val_loss: 12.0545 - val_mae: 2.4784\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.1855 - mae: 0.7908 - val_loss: 10.8530 - val_mae: 2.4505\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.0654 - mae: 0.7426 - val_loss: 11.5342 - val_mae: 2.3802\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 0s 777us/step - loss: 1.0965 - mae: 0.7702 - val_loss: 10.7300 - val_mae: 2.4555\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.0616 - mae: 0.7340 - val_loss: 10.5102 - val_mae: 2.3923\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 727us/step - loss: 1.2367 - mae: 0.7854 - val_loss: 12.1584 - val_mae: 2.5179\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.1049 - mae: 0.7733 - val_loss: 10.6148 - val_mae: 2.4749\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 1.0609 - mae: 0.7600 - val_loss: 11.1691 - val_mae: 2.4682\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.2286 - mae: 0.7711 - val_loss: 11.7231 - val_mae: 2.4831\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.0897 - mae: 0.7635 - val_loss: 10.7087 - val_mae: 2.4951\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.0038 - mae: 0.7335 - val_loss: 10.8062 - val_mae: 2.4650\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 1.0211 - mae: 0.7322 - val_loss: 11.4772 - val_mae: 2.4895\n",
      "Epoch 363/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 1.0375 - mae: 0.7553 - val_loss: 12.2909 - val_mae: 2.5070\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 1.0994 - mae: 0.7594 - val_loss: 10.2811 - val_mae: 2.4425\n",
      "Epoch 365/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 1.0312 - mae: 0.7756 - val_loss: 12.5681 - val_mae: 2.5423\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 1.1263 - mae: 0.7795 - val_loss: 9.7157 - val_mae: 2.3883\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 1.0246 - mae: 0.7541 - val_loss: 11.1543 - val_mae: 2.4600\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 0.9777 - mae: 0.7099 - val_loss: 10.6219 - val_mae: 2.4037\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 0s 752us/step - loss: 1.0408 - mae: 0.7389 - val_loss: 10.6301 - val_mae: 2.4826\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 1.0060 - mae: 0.7351 - val_loss: 9.6337 - val_mae: 2.4398\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 1.1132 - mae: 0.8018 - val_loss: 10.9106 - val_mae: 2.3896\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 0s 747us/step - loss: 1.0711 - mae: 0.7353 - val_loss: 10.2665 - val_mae: 2.4675\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 0s 765us/step - loss: 1.0334 - mae: 0.7270 - val_loss: 11.8656 - val_mae: 2.4611\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.2068 - mae: 0.7607 - val_loss: 10.1432 - val_mae: 2.4866\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.2101 - mae: 0.7752 - val_loss: 11.1551 - val_mae: 2.6100\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 1.0658 - mae: 0.7721 - val_loss: 11.8035 - val_mae: 2.5218\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.1543 - mae: 0.7743 - val_loss: 10.1311 - val_mae: 2.4043\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.0805 - mae: 0.7649 - val_loss: 10.0406 - val_mae: 2.3180\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 0.9725 - mae: 0.7389 - val_loss: 11.4316 - val_mae: 2.4288\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 0.9391 - mae: 0.7141 - val_loss: 10.4258 - val_mae: 2.4782\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 0s 747us/step - loss: 1.0757 - mae: 0.7285 - val_loss: 12.9794 - val_mae: 2.6068\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 0s 781us/step - loss: 1.0681 - mae: 0.7099 - val_loss: 9.9764 - val_mae: 2.4036\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.0600 - mae: 0.7478 - val_loss: 10.8498 - val_mae: 2.4081\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.0429 - mae: 0.7446 - val_loss: 10.4350 - val_mae: 2.3641\n",
      "Epoch 385/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.0014 - mae: 0.7342 - val_loss: 10.8256 - val_mae: 2.3947\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.9128 - mae: 0.6851 - val_loss: 10.1469 - val_mae: 2.3375\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 0.9204 - mae: 0.7108 - val_loss: 11.8653 - val_mae: 2.5755\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 0.9909 - mae: 0.7279 - val_loss: 11.7860 - val_mae: 2.5185\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.0736 - mae: 0.7521 - val_loss: 10.9676 - val_mae: 2.4051\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 0.9859 - mae: 0.7484 - val_loss: 10.1878 - val_mae: 2.3610\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.9692 - mae: 0.7295 - val_loss: 10.4586 - val_mae: 2.4637\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 0.9842 - mae: 0.7030 - val_loss: 10.6622 - val_mae: 2.4267\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 0.9956 - mae: 0.7270 - val_loss: 10.7237 - val_mae: 2.4515\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.0501 - mae: 0.7526 - val_loss: 11.4984 - val_mae: 2.4993\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 0s 744us/step - loss: 0.9009 - mae: 0.6776 - val_loss: 10.9643 - val_mae: 2.4874\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 0s 806us/step - loss: 0.9060 - mae: 0.6953 - val_loss: 10.0641 - val_mae: 2.3810\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 0s 753us/step - loss: 1.0328 - mae: 0.7143 - val_loss: 10.6209 - val_mae: 2.4528\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 0.9690 - mae: 0.7024 - val_loss: 10.7572 - val_mae: 2.4196\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 1.0696 - mae: 0.7719 - val_loss: 10.8611 - val_mae: 2.4391\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 0.9114 - mae: 0.6943 - val_loss: 10.8236 - val_mae: 2.4346\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 1.0477 - mae: 0.7401 - val_loss: 10.1500 - val_mae: 2.3577\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 1.1835 - mae: 0.7131 - val_loss: 10.9306 - val_mae: 2.4275\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 0.8760 - mae: 0.7073 - val_loss: 11.3098 - val_mae: 2.4803\n",
      "Epoch 404/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 0.9082 - mae: 0.7281 - val_loss: 11.3477 - val_mae: 2.4177\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 1.0498 - mae: 0.7369 - val_loss: 11.1617 - val_mae: 2.3817\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 0s 755us/step - loss: 0.8984 - mae: 0.7015 - val_loss: 12.1760 - val_mae: 2.5754\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 0s 747us/step - loss: 1.1995 - mae: 0.6732 - val_loss: 9.9279 - val_mae: 2.4520\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 0.9590 - mae: 0.7189 - val_loss: 10.7275 - val_mae: 2.3500\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 1.0036 - mae: 0.6965 - val_loss: 9.2540 - val_mae: 2.2494\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 0s 748us/step - loss: 0.9322 - mae: 0.6981 - val_loss: 10.4814 - val_mae: 2.4427\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 1.0226 - mae: 0.7244 - val_loss: 10.3319 - val_mae: 2.3551\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 0.9651 - mae: 0.7158 - val_loss: 10.1903 - val_mae: 2.4506\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 0.9936 - mae: 0.7129 - val_loss: 10.7563 - val_mae: 2.4586\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 0.9993 - mae: 0.6976 - val_loss: 9.9335 - val_mae: 2.3135\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 721us/step - loss: 0.9629 - mae: 0.7066 - val_loss: 9.3122 - val_mae: 2.3319\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 0.9124 - mae: 0.7183 - val_loss: 12.0133 - val_mae: 2.4740\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 0s 755us/step - loss: 0.9527 - mae: 0.6925 - val_loss: 11.7485 - val_mae: 2.4963\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 1.0219 - mae: 0.7459 - val_loss: 11.7128 - val_mae: 2.6352\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 0.8804 - mae: 0.7087 - val_loss: 10.8673 - val_mae: 2.4568\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 0.9976 - mae: 0.7324 - val_loss: 9.8121 - val_mae: 2.3971\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 0.8308 - mae: 0.6749 - val_loss: 10.1198 - val_mae: 2.4675\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 0s 749us/step - loss: 1.0103 - mae: 0.7235 - val_loss: 10.6470 - val_mae: 2.3533\n",
      "Epoch 423/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 0.8155 - mae: 0.6725 - val_loss: 9.5097 - val_mae: 2.3255\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.0367 - mae: 0.7451 - val_loss: 10.9207 - val_mae: 2.4823\n",
      "Epoch 425/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 0.9079 - mae: 0.7047 - val_loss: 11.2087 - val_mae: 2.4165\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 0.9536 - mae: 0.7333 - val_loss: 11.0358 - val_mae: 2.4506\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 0s 747us/step - loss: 0.9051 - mae: 0.6940 - val_loss: 10.9787 - val_mae: 2.5294\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 1.0561 - mae: 0.7481 - val_loss: 11.8009 - val_mae: 2.4766\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 0.9127 - mae: 0.6729 - val_loss: 9.6282 - val_mae: 2.3626\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 0.9248 - mae: 0.7142 - val_loss: 10.9168 - val_mae: 2.5088\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 1.0108 - mae: 0.6838 - val_loss: 11.7111 - val_mae: 2.5805\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.8891 - mae: 0.6996 - val_loss: 9.0284 - val_mae: 2.3210\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 0.7857 - mae: 0.6590 - val_loss: 9.5155 - val_mae: 2.3439\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 0s 744us/step - loss: 1.0540 - mae: 0.7206 - val_loss: 9.4697 - val_mae: 2.2590\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 0s 748us/step - loss: 1.0034 - mae: 0.7165 - val_loss: 9.1596 - val_mae: 2.2984\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 0s 753us/step - loss: 0.9281 - mae: 0.6619 - val_loss: 10.2209 - val_mae: 2.4887\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.9447 - mae: 0.7303 - val_loss: 11.5388 - val_mae: 2.5316\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 0.8017 - mae: 0.6825 - val_loss: 10.6749 - val_mae: 2.4834\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 0.8960 - mae: 0.6722 - val_loss: 9.6081 - val_mae: 2.3300\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 0.8825 - mae: 0.6843 - val_loss: 10.1795 - val_mae: 2.4065\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 0s 752us/step - loss: 0.8943 - mae: 0.7078 - val_loss: 9.2596 - val_mae: 2.2541\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 0.9138 - mae: 0.6826 - val_loss: 9.4836 - val_mae: 2.3210\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 0.9171 - mae: 0.7170 - val_loss: 10.8883 - val_mae: 2.3635\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.8273 - mae: 0.6691 - val_loss: 9.5902 - val_mae: 2.3881\n",
      "Epoch 445/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 0.9216 - mae: 0.6805 - val_loss: 11.6980 - val_mae: 2.5693\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.9719 - mae: 0.7166 - val_loss: 9.3485 - val_mae: 2.3321\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 0.9146 - mae: 0.6878 - val_loss: 9.8106 - val_mae: 2.3603\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 0.8930 - mae: 0.7034 - val_loss: 10.0921 - val_mae: 2.3930\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.0442 - mae: 0.6696 - val_loss: 10.5304 - val_mae: 2.4261\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.9097 - mae: 0.6688 - val_loss: 10.8559 - val_mae: 2.4401\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.8459 - mae: 0.6808 - val_loss: 12.0492 - val_mae: 2.6467\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.9476 - mae: 0.7205 - val_loss: 11.4868 - val_mae: 2.6084\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.0585 - mae: 0.7198 - val_loss: 9.7568 - val_mae: 2.3562\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.8286 - mae: 0.6692 - val_loss: 11.3855 - val_mae: 2.5476\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 0.8625 - mae: 0.6671 - val_loss: 12.8303 - val_mae: 2.6369\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 0.9094 - mae: 0.7014 - val_loss: 9.8170 - val_mae: 2.3689\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.8822 - mae: 0.6995 - val_loss: 9.7372 - val_mae: 2.3417\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 0.9393 - mae: 0.6817 - val_loss: 11.0531 - val_mae: 2.5221\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 0.8688 - mae: 0.6561 - val_loss: 11.3661 - val_mae: 2.6057\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 0.8158 - mae: 0.6667 - val_loss: 9.4701 - val_mae: 2.3377\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.0062 - mae: 0.7033 - val_loss: 11.2665 - val_mae: 2.4818\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 0.8018 - mae: 0.6648 - val_loss: 11.6973 - val_mae: 2.5690\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 0.8728 - mae: 0.6728 - val_loss: 10.3625 - val_mae: 2.4385\n",
      "Epoch 464/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 0.9916 - mae: 0.7330 - val_loss: 10.9004 - val_mae: 2.4401\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 0.8193 - mae: 0.6323 - val_loss: 10.6603 - val_mae: 2.4947\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 0.8871 - mae: 0.6935 - val_loss: 11.5821 - val_mae: 2.5902\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 0.9011 - mae: 0.6657 - val_loss: 10.6396 - val_mae: 2.4438\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 0s 754us/step - loss: 0.9687 - mae: 0.7335 - val_loss: 10.4519 - val_mae: 2.4665\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 0.7856 - mae: 0.6542 - val_loss: 11.0054 - val_mae: 2.4388\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 0.7646 - mae: 0.6307 - val_loss: 10.2598 - val_mae: 2.4670\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 0s 752us/step - loss: 1.0831 - mae: 0.6943 - val_loss: 11.2948 - val_mae: 2.5298\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 0.8107 - mae: 0.6553 - val_loss: 10.1501 - val_mae: 2.3243\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 0.8953 - mae: 0.6637 - val_loss: 11.3241 - val_mae: 2.5226\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 717us/step - loss: 0.9137 - mae: 0.6805 - val_loss: 11.1321 - val_mae: 2.5528\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 0.9857 - mae: 0.7024 - val_loss: 10.5563 - val_mae: 2.4553\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 0.8338 - mae: 0.6833 - val_loss: 11.5941 - val_mae: 2.4777\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 0.7915 - mae: 0.6736 - val_loss: 10.7216 - val_mae: 2.4652\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 0s 885us/step - loss: 0.7927 - mae: 0.6558 - val_loss: 10.2247 - val_mae: 2.4476\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 0.8396 - mae: 0.6641 - val_loss: 11.0014 - val_mae: 2.5326\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 0s 789us/step - loss: 0.9087 - mae: 0.6767 - val_loss: 9.6882 - val_mae: 2.3557\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 0s 827us/step - loss: 0.8688 - mae: 0.7012 - val_loss: 9.9653 - val_mae: 2.3552\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 0s 912us/step - loss: 0.9303 - mae: 0.6849 - val_loss: 9.7605 - val_mae: 2.3772\n",
      "Epoch 483/500\n",
      "303/303 [==============================] - 0s 811us/step - loss: 0.7769 - mae: 0.6315 - val_loss: 9.9182 - val_mae: 2.4888\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 0s 885us/step - loss: 0.9374 - mae: 0.6714 - val_loss: 11.1532 - val_mae: 2.3911\n",
      "Epoch 485/500\n",
      "303/303 [==============================] - 0s 856us/step - loss: 0.7830 - mae: 0.6579 - val_loss: 10.5039 - val_mae: 2.4534\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 0s 815us/step - loss: 0.9123 - mae: 0.6871 - val_loss: 11.0692 - val_mae: 2.4922\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 0s 859us/step - loss: 0.8173 - mae: 0.6690 - val_loss: 11.2358 - val_mae: 2.5752\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 0s 777us/step - loss: 0.7476 - mae: 0.6408 - val_loss: 9.9447 - val_mae: 2.3397\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 0s 863us/step - loss: 0.8102 - mae: 0.6632 - val_loss: 9.8772 - val_mae: 2.4046\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 0s 765us/step - loss: 0.9092 - mae: 0.7138 - val_loss: 9.9155 - val_mae: 2.3752\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 0.8400 - mae: 0.6390 - val_loss: 9.9508 - val_mae: 2.3711\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 0.7703 - mae: 0.6651 - val_loss: 11.0145 - val_mae: 2.4781\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 0.8367 - mae: 0.6540 - val_loss: 9.7268 - val_mae: 2.3992\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 0.8319 - mae: 0.6660 - val_loss: 10.8388 - val_mae: 2.4779\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 0s 828us/step - loss: 0.8133 - mae: 0.6587 - val_loss: 10.6491 - val_mae: 2.4776\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 0.8721 - mae: 0.6660 - val_loss: 10.6335 - val_mae: 2.3713\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 0.7923 - mae: 0.6387 - val_loss: 10.2391 - val_mae: 2.3658\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 0.8632 - mae: 0.6664 - val_loss: 10.6507 - val_mae: 2.3824\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 0.8850 - mae: 0.6963 - val_loss: 10.3721 - val_mae: 2.4189\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 0s 785us/step - loss: 0.7400 - mae: 0.6515 - val_loss: 10.6195 - val_mae: 2.4252\n",
      "{'val_loss': [37.99748458081423, 24.172939561353825, 18.474986869030943, 16.68402756070534, 14.146112710204077, 15.147855457418718, 12.65778903504845, 13.135664526778873, 10.380594173963827, 10.759573087731312, 9.180380839137833, 9.777535509409459, 9.789355131534117, 8.593918452939707, 9.768542301168955, 8.537420590682183, 9.415175298417351, 8.235462226656537, 8.300869810892877, 8.242059978794787, 10.352537804726675, 8.060607574543557, 7.50221564445678, 7.97620714306693, 7.512087079543958, 8.081631652705687, 8.049031560305197, 8.478186560435669, 10.576807095907803, 8.33165449693414, 8.627420791673202, 8.742646551759261, 7.329348747819053, 6.865512687397088, 9.216003950200006, 7.1574628700935605, 8.091216574649074, 6.792002643604929, 7.878136853484891, 7.957472015951419, 6.928168772454696, 8.946603827429751, 7.245368888644632, 8.406682089224716, 12.578038755095434, 7.291278309882665, 8.598664409597404, 7.471107022250117, 9.177935501889644, 10.660194951266345, 8.261130489406664, 7.974441383499652, 7.708465582728017, 7.744243130574261, 8.703501338129955, 7.52129708037661, 10.92694882486744, 7.479631805672578, 8.241627027010805, 7.99346358430633, 8.010713174847558, 7.543629259991576, 7.90917502310459, 8.368133185578898, 8.375471938502892, 8.036557921066668, 7.768701140780928, 8.238368857124911, 8.793414505200904, 8.286545509649994, 8.139636898256544, 11.77160435186533, 10.32037164276641, 9.050108697719521, 9.466290426168516, 7.9182826771912636, 8.211565896294266, 8.52453264153544, 8.515779183582762, 9.920422760483874, 8.556410439933725, 9.25060107805628, 9.377618911890497, 8.088383722254322, 9.238382169218402, 9.42642546856504, 8.301390383007774, 9.693968882441341, 9.750485568263766, 8.741123822164989, 10.336100714867888, 9.717865914621592, 9.146350165048734, 11.223353434360442, 9.167283554562589, 9.522907345777027, 8.319903798936462, 10.550582413132865, 8.697455136861542, 9.38132448029234, 8.238999215591212, 10.666868525133053, 12.455322425707594, 9.508973025933859, 9.45176822558451, 10.130553597492769, 9.61282932011429, 11.344328942678846, 8.726147672584474, 9.079960205947224, 11.22517462187073, 10.242264007693064, 10.674194118229934, 12.970813258846134, 11.171606327407062, 10.35865379879519, 9.254299635542464, 9.86350677667951, 11.676544549169554, 9.066960468696946, 9.138596292240823, 12.429907991670737, 10.651415588449465, 9.686259850528263, 9.422611903726574, 10.304460503539735, 10.54549536294893, 9.912259942437014, 9.797930636452742, 9.693491671111902, 9.592918642934892, 9.83252690163211, 9.414602590111627, 12.131273733026067, 10.681001413920445, 10.772323905169909, 9.484959691034176, 10.401846933079478, 11.884107345258725, 14.5626777489353, 11.921029761053234, 10.729698677170692, 9.67523104979666, 9.832047317187719, 10.444992029770436, 9.589316748950566, 10.262047711702174, 10.056181811870509, 9.948965404213794, 11.33036255765485, 10.016957357875441, 9.607331748452443, 10.482238902376116, 10.433225517696009, 11.0571312333116, 11.26493783952613, 9.738121572974723, 11.185793064613042, 11.226117528363002, 9.436289546182518, 13.049125396645406, 11.964334067602707, 10.018838655746611, 9.094321952922042, 9.313736896022824, 9.982193540648176, 10.47183179723832, 11.117112419374937, 9.738860846756747, 11.482277548166527, 14.597947293552478, 10.141154939034148, 10.419781292761634, 10.382862392656211, 11.65864486949179, 12.125448460063216, 9.737200223274257, 9.957397962564494, 9.89743611040755, 16.477637931811717, 10.299034747361935, 10.233962860653012, 10.380946313376805, 10.240218056090658, 10.529086013996828, 10.536559916732172, 11.864350791222941, 9.483869653327694, 10.209625696264885, 10.8184915810805, 9.735562363520177, 10.40873352689023, 9.792825424829314, 10.26312154513037, 10.10544398090212, 10.785915742020554, 10.053464631329755, 9.598313846581588, 9.58429895111793, 11.41996318384046, 10.609557203224648, 9.581618486104837, 10.307348585647237, 10.572106023881547, 9.57390170112439, 9.907414504885327, 10.121579157040998, 9.178523939751818, 9.64524476717014, 10.216909882276536, 9.869507657308684, 9.644428439073536, 11.124104944944024, 10.294664718697106, 11.089777746818738, 9.960578074261528, 9.742296211735004, 10.524251675569811, 9.916851321379522, 9.873944194268033, 10.837041926033113, 9.580338192439758, 10.36724546524272, 10.089953893673432, 10.077619523780495, 10.388989692689348, 9.611741327505449, 9.88790991018978, 9.747418217766121, 9.654430682108435, 10.835960297160067, 10.788262958948426, 11.135651988564733, 11.251621110443173, 11.29931696048758, 11.266241119030582, 11.458179836869148, 10.807220630647413, 11.090418419724624, 9.221782224824523, 10.169953137132486, 11.311533610352619, 9.390986226802365, 12.53602687503663, 10.71016123959631, 10.70343411954507, 9.773191319340276, 11.101539510790959, 10.631609615087475, 10.884152877270152, 10.412861259506627, 9.969762297884312, 11.523665677811398, 9.607918271526039, 10.79711168520798, 9.5794509741131, 9.914730967862392, 9.53837039944944, 11.968875413672231, 10.314430511410759, 10.796217033496768, 10.762928757972158, 10.55370964200033, 10.553741012129496, 11.463063291246348, 10.807617576849603, 12.25849090431734, 10.370902612639389, 9.201848639011622, 9.859139644193041, 10.134060324022736, 9.701392788810558, 10.454345853674793, 9.625432419575668, 9.201381817527057, 9.98689526345092, 10.218019342055719, 10.769403641179037, 9.609894602907168, 10.949195784547754, 10.451101050132397, 9.982558371903753, 10.149105705724255, 10.058303360869914, 10.594411932595886, 9.913147673640161, 11.69963984176203, 11.665031642804042, 10.487499893202658, 10.727952369314728, 11.71460556599028, 11.162236241498123, 9.381018152686371, 10.400504518729072, 11.713226263473585, 11.266195376914387, 10.582734869497985, 11.318908241708845, 11.106935935749645, 10.063010155804234, 10.096205422126845, 9.450289612479214, 9.257891539365254, 11.058275793891141, 9.612591062819108, 11.538190238807687, 11.515736626448469, 9.875590028654791, 10.27105319510228, 10.4163238251859, 10.833440464679965, 10.618788438709684, 10.28425655846189, 12.1546900845346, 10.56041538345571, 12.63254368341388, 11.57692577073029, 11.060621916144852, 10.30694547938023, 11.45678965122114, 9.607344556871876, 9.51860822538965, 10.995723036553256, 9.920317387019924, 9.913201979038739, 10.735914863944561, 11.136684084567875, 10.502888620530813, 10.906070316183879, 10.905622443373575, 10.083411206007332, 10.107618150577908, 11.169877839274704, 10.4581379872556, 11.763541381207382, 12.413430652491538, 11.410645587546773, 10.162225389990859, 10.962721104800499, 11.263657988415625, 10.602715269150673, 10.848523743249796, 10.761240867990079, 9.99383097573395, 11.603477845273307, 11.635597081094206, 11.165506702253023, 10.47551814730436, 11.000871503285344, 9.325204502341641, 12.05446362438742, 10.85302204443234, 11.534160409950292, 10.729985079547681, 10.510215682648399, 12.158410818061311, 10.614802463097863, 11.169086604743347, 11.723087812834109, 10.708651006560212, 10.806219486035591, 11.477227193017555, 12.290881757304017, 10.281086186748496, 12.568097844799347, 9.715711894841625, 11.154255354445022, 10.621907551352184, 10.630081833503901, 9.633740860590766, 10.910643891690732, 10.266482815697401, 11.86555310670692, 10.14323195155438, 11.155085424689743, 11.803521105288706, 10.131122994328859, 10.040610000543298, 11.43162223401982, 10.425759561138578, 12.979399199569874, 9.97639679835042, 10.849750643954232, 10.435045812714103, 10.825551387752489, 10.146878612960233, 11.865317024108446, 11.786038339078095, 10.967569229763619, 10.187801122218762, 10.458638680402055, 10.662184616108194, 10.723691368946117, 11.498391955592993, 10.964339361814805, 10.064059701526888, 10.620933502183485, 10.757237289821278, 10.861084947173511, 10.823580781554591, 10.149974204265595, 10.930597763528153, 11.309797722239123, 11.347703565108027, 11.161705497665835, 12.175963146825717, 9.927945115027192, 10.727511029385923, 9.254008227813504, 10.481381847560037, 10.331909707821168, 10.19025315833224, 10.756268801111128, 9.933450365591492, 9.31224793337728, 12.013337789501081, 11.748534785246472, 11.7128057212472, 10.867261319409849, 9.812086704164944, 10.119761778038262, 10.647027856883268, 9.509726936020657, 10.920653373537824, 11.208745042262235, 11.035812772280828, 10.978694615083388, 11.800901230126112, 9.628192420755536, 10.916783659479185, 11.711055030465635, 9.028437076567588, 9.51548205290248, 9.4696640721067, 9.15957913189979, 10.220871564278951, 11.538818250617732, 10.674864423954583, 9.608093912069055, 10.179485638602578, 9.259633494707026, 9.4835788001062, 10.888332634538312, 9.59024568645302, 11.69800714304265, 9.348530139543703, 9.810579433203284, 10.09209715930104, 10.53036997176414, 10.855947596005004, 12.0492416849731, 11.486828116232699, 9.756778806437069, 11.38552922039929, 12.830308241391753, 9.817006415104416, 9.737212892633282, 11.053141930567026, 11.366109607738931, 9.470114858509826, 11.266488841051318, 11.697309234594647, 10.362478478355241, 10.90044827069995, 10.660311499071113, 11.582068681829876, 10.639573910407893, 10.45193971109134, 11.005359674130778, 10.259754619052972, 11.294787338556777, 10.150078900082331, 11.324114897514873, 11.132066478325736, 10.556302947029968, 11.594137245128138, 10.721564725507626, 10.22471262957661, 11.001408502294124, 9.688237062908968, 9.965328304410571, 9.760505784835464, 9.91818226325599, 11.153184065996527, 10.503944779640193, 11.069187096555229, 11.23581327361488, 9.944731986825586, 9.877180735274024, 9.91551757804095, 9.950814239551672, 11.014472028104551, 9.726765702893534, 10.838825624781927, 10.649118866255083, 10.633485944468486, 10.239083974446991, 10.65066803883779, 10.372133428140977, 10.619485537261047], 'val_mae': [4.0681047439575195, 3.043930768966675, 2.6692354679107666, 2.475848436355591, 2.4538514614105225, 2.3791234493255615, 2.253342628479004, 2.2719924449920654, 2.0617125034332275, 2.307166337966919, 2.0468010902404785, 1.991989254951477, 1.9168964624404907, 2.0550663471221924, 2.052558660507202, 1.9724478721618652, 2.241062879562378, 1.897059679031372, 2.097867488861084, 2.0178163051605225, 2.1728856563568115, 1.9901390075683594, 1.8398433923721313, 2.178663730621338, 1.9588496685028076, 2.0615551471710205, 2.052910327911377, 2.0705342292785645, 2.1728110313415527, 2.190718650817871, 2.127021312713623, 2.190683364868164, 2.030437469482422, 1.993135690689087, 2.13557767868042, 1.9067766666412354, 2.0093882083892822, 1.9429892301559448, 1.917529582977295, 2.208029270172119, 2.000102996826172, 2.1509361267089844, 1.8756970167160034, 2.0768725872039795, 2.7837796211242676, 1.9205056428909302, 2.184077739715576, 1.9013947248458862, 2.097745656967163, 2.5094337463378906, 2.1644129753112793, 2.173022508621216, 2.079314947128296, 1.9964648485183716, 2.299791097640991, 2.0858981609344482, 2.5533604621887207, 2.025959014892578, 2.1629316806793213, 1.9892141819000244, 2.0344228744506836, 1.9591950178146362, 1.9705955982208252, 2.191863536834717, 2.2163174152374268, 2.079587936401367, 1.896016240119934, 1.9708032608032227, 2.092482805252075, 1.986836314201355, 2.112245559692383, 2.692607879638672, 2.54917049407959, 2.1041572093963623, 2.268385171890259, 2.1086435317993164, 1.9747416973114014, 2.0685086250305176, 2.0750937461853027, 2.392307758331299, 2.1031999588012695, 2.148597240447998, 2.290005922317505, 2.0152854919433594, 2.3377878665924072, 2.176548719406128, 2.0945355892181396, 2.176616907119751, 2.4022345542907715, 2.212428092956543, 2.5142810344696045, 2.2076520919799805, 2.1603546142578125, 2.61838698387146, 2.108228921890259, 2.1835198402404785, 2.066826820373535, 2.3583974838256836, 2.1180853843688965, 2.3569350242614746, 2.096024990081787, 2.5948963165283203, 2.652554750442505, 2.275740146636963, 2.356217622756958, 2.280075788497925, 2.401338815689087, 2.5895519256591797, 2.252124309539795, 2.213606595993042, 2.5020461082458496, 2.4358201026916504, 2.4609665870666504, 2.870440721511841, 2.5964391231536865, 2.268608570098877, 2.2507359981536865, 2.2125134468078613, 2.6563363075256348, 2.218836784362793, 2.1807668209075928, 2.7730472087860107, 2.528576135635376, 2.3786380290985107, 2.3870341777801514, 2.3367128372192383, 2.244870901107788, 2.356679916381836, 2.286323070526123, 2.326794385910034, 2.2098679542541504, 2.3876240253448486, 2.2061269283294678, 2.756166458129883, 2.377288579940796, 2.4187064170837402, 2.3449628353118896, 2.422802686691284, 2.5577118396759033, 2.978623151779175, 2.72981858253479, 2.3568830490112305, 2.2136049270629883, 2.28139066696167, 2.440863847732544, 2.4263646602630615, 2.4836745262145996, 2.328082799911499, 2.2466773986816406, 2.5661745071411133, 2.4016642570495605, 2.2848458290100098, 2.402629852294922, 2.455404043197632, 2.518184185028076, 2.4487850666046143, 2.3504714965820312, 2.515226364135742, 2.4552106857299805, 2.3054938316345215, 2.6607370376586914, 2.4998111724853516, 2.217276096343994, 2.2083122730255127, 2.193061351776123, 2.3870022296905518, 2.406693935394287, 2.3360490798950195, 2.3073341846466064, 2.410494565963745, 2.862605333328247, 2.278582811355591, 2.4685864448547363, 2.5649449825286865, 2.556108236312866, 2.5270488262176514, 2.3580310344696045, 2.357388734817505, 2.3599061965942383, 3.1215615272521973, 2.3114426136016846, 2.3950464725494385, 2.480733633041382, 2.3910021781921387, 2.317095994949341, 2.425603151321411, 2.4863412380218506, 2.261997938156128, 2.3854901790618896, 2.3936166763305664, 2.3113248348236084, 2.4382998943328857, 2.3186166286468506, 2.445838212966919, 2.348973274230957, 2.3611323833465576, 2.313220739364624, 2.3107850551605225, 2.3365793228149414, 2.6838345527648926, 2.3783583641052246, 2.334628105163574, 2.379296064376831, 2.3911423683166504, 2.280548095703125, 2.317544460296631, 2.440521001815796, 2.3337759971618652, 2.324037551879883, 2.360825300216675, 2.336362838745117, 2.3413894176483154, 2.4172773361206055, 2.384044885635376, 2.4547839164733887, 2.4455535411834717, 2.2945022583007812, 2.3898000717163086, 2.365793466567993, 2.3899245262145996, 2.432018995285034, 2.2709484100341797, 2.41552734375, 2.3515069484710693, 2.3360185623168945, 2.352597713470459, 2.3316586017608643, 2.2840023040771484, 2.3022446632385254, 2.366011619567871, 2.4594171047210693, 2.370551109313965, 2.439913034439087, 2.516650676727295, 2.4790894985198975, 2.5276265144348145, 2.4849448204040527, 2.4235639572143555, 2.4110026359558105, 2.193635940551758, 2.3390913009643555, 2.4099643230438232, 2.2832674980163574, 2.5807933807373047, 2.3470423221588135, 2.3764452934265137, 2.292598247528076, 2.4263882637023926, 2.3967814445495605, 2.334628105163574, 2.3785250186920166, 2.32775616645813, 2.4727718830108643, 2.291543483734131, 2.377875804901123, 2.265028238296509, 2.326277732849121, 2.330188274383545, 2.5997748374938965, 2.385990619659424, 2.421642780303955, 2.4339418411254883, 2.386439561843872, 2.379699468612671, 2.555121898651123, 2.364647626876831, 2.6266849040985107, 2.4692492485046387, 2.2470009326934814, 2.435833692550659, 2.330148696899414, 2.290700674057007, 2.4272682666778564, 2.3371028900146484, 2.261603593826294, 2.285752296447754, 2.4162917137145996, 2.3601624965667725, 2.3350069522857666, 2.3761963844299316, 2.3961234092712402, 2.3385701179504395, 2.4328439235687256, 2.3751490116119385, 2.449389934539795, 2.3760647773742676, 2.517314910888672, 2.564711809158325, 2.370384931564331, 2.415682792663574, 2.5811386108398438, 2.471691846847534, 2.3435275554656982, 2.4490859508514404, 2.5682308673858643, 2.493253231048584, 2.417827606201172, 2.517138719558716, 2.5580074787139893, 2.4266164302825928, 2.4766547679901123, 2.3445701599121094, 2.272977113723755, 2.400782585144043, 2.3230342864990234, 2.4777750968933105, 2.55743408203125, 2.364013195037842, 2.3805272579193115, 2.3706769943237305, 2.421842575073242, 2.333299398422241, 2.418200731277466, 2.5478572845458984, 2.304490804672241, 2.5553171634674072, 2.3746256828308105, 2.4926891326904297, 2.338984966278076, 2.5719799995422363, 2.295100212097168, 2.3340795040130615, 2.428593397140503, 2.392763614654541, 2.3711905479431152, 2.466888666152954, 2.5768074989318848, 2.363309383392334, 2.4037203788757324, 2.4962730407714844, 2.329324960708618, 2.379335403442383, 2.4880216121673584, 2.3986868858337402, 2.440572500228882, 2.6833958625793457, 2.5221986770629883, 2.3454840183258057, 2.4555933475494385, 2.4609262943267822, 2.447701930999756, 2.410372257232666, 2.57330322265625, 2.395792245864868, 2.4604454040527344, 2.5078859329223633, 2.524738073348999, 2.41369891166687, 2.447929859161377, 2.3100695610046387, 2.478423833847046, 2.4504520893096924, 2.3801820278167725, 2.4554529190063477, 2.3922975063323975, 2.5178534984588623, 2.4748783111572266, 2.4682302474975586, 2.4831113815307617, 2.4950764179229736, 2.4650027751922607, 2.4894766807556152, 2.50700306892395, 2.442525625228882, 2.5423288345336914, 2.3882906436920166, 2.459995746612549, 2.4036831855773926, 2.4826221466064453, 2.439805507659912, 2.389606475830078, 2.4675357341766357, 2.461120843887329, 2.4865877628326416, 2.610042095184326, 2.52181339263916, 2.404313802719116, 2.318019390106201, 2.4287843704223633, 2.478219509124756, 2.6067588329315186, 2.40358304977417, 2.4080517292022705, 2.3640575408935547, 2.394709348678589, 2.3375327587127686, 2.5755209922790527, 2.518527030944824, 2.4050517082214355, 2.360990047454834, 2.463712453842163, 2.4267444610595703, 2.4515297412872314, 2.4992752075195312, 2.487405300140381, 2.380976915359497, 2.452810049057007, 2.4196035861968994, 2.4391229152679443, 2.434598445892334, 2.3577091693878174, 2.4274842739105225, 2.480252504348755, 2.4177074432373047, 2.3817436695098877, 2.575389862060547, 2.452017068862915, 2.3500144481658936, 2.2493724822998047, 2.442652702331543, 2.355090379714966, 2.4506402015686035, 2.4586071968078613, 2.3134548664093018, 2.331946611404419, 2.4740278720855713, 2.4962615966796875, 2.6351523399353027, 2.4567806720733643, 2.3971102237701416, 2.4675495624542236, 2.353267192840576, 2.3254764080047607, 2.482254981994629, 2.4164681434631348, 2.450575113296509, 2.529353618621826, 2.476637363433838, 2.3626327514648438, 2.5087993144989014, 2.580498695373535, 2.32098126411438, 2.343874454498291, 2.2589831352233887, 2.29838490486145, 2.48870849609375, 2.5315635204315186, 2.4833624362945557, 2.329969882965088, 2.406543493270874, 2.2540652751922607, 2.320974349975586, 2.3634932041168213, 2.3881301879882812, 2.5693156719207764, 2.3320796489715576, 2.360276222229004, 2.393003225326538, 2.4261062145233154, 2.440122604370117, 2.6466867923736572, 2.6083996295928955, 2.3561575412750244, 2.547616720199585, 2.636859655380249, 2.3688650131225586, 2.3417179584503174, 2.522108554840088, 2.6057207584381104, 2.3376636505126953, 2.4817867279052734, 2.569007158279419, 2.438525438308716, 2.4401040077209473, 2.4947152137756348, 2.5902068614959717, 2.4438319206237793, 2.4665439128875732, 2.4387691020965576, 2.4669904708862305, 2.5297718048095703, 2.324267625808716, 2.5226128101348877, 2.5528202056884766, 2.455275535583496, 2.4777004718780518, 2.465207576751709, 2.4476447105407715, 2.5326321125030518, 2.355713129043579, 2.3551735877990723, 2.3772377967834473, 2.4887545108795166, 2.391120672225952, 2.45344614982605, 2.492219924926758, 2.575225830078125, 2.339728355407715, 2.404646873474121, 2.3751862049102783, 2.37111496925354, 2.478127956390381, 2.399182081222534, 2.4779274463653564, 2.4775924682617188, 2.3712925910949707, 2.3657734394073486, 2.382434606552124, 2.418879985809326, 2.4252357482910156], 'loss': [192.24407516010373, 29.836530101645767, 20.84494851372226, 17.589663921285524, 16.43402508694084, 15.028469303211942, 14.551833995067078, 13.432241397703308, 13.43639804151796, 12.801312861992587, 11.691010504124206, 12.17921192138402, 11.54361537752448, 11.561084507413463, 11.058489225440491, 10.881072735740439, 10.660068074760094, 10.080562675477328, 10.268466209546867, 9.580894260720717, 9.953112730660735, 9.870513824651713, 9.50270516017501, 9.10463096050906, 8.926610929483822, 9.004244171129944, 8.813020092366504, 8.766092137865943, 8.376735286836618, 8.623143476848277, 8.292987695764696, 7.763710185896631, 8.67800544650301, 8.046903349286433, 7.724810675669816, 7.999437774028386, 7.988437333135218, 7.647357897309697, 7.330349342542237, 7.9507164239299595, 7.519576025121459, 7.243017397887586, 7.552927689462275, 6.613699688376337, 7.031654360716767, 7.11974741877979, 7.186891821797737, 7.202710461609883, 7.068050730457201, 7.126259242667855, 6.7610378396525315, 6.718058607211494, 6.414123093280825, 6.153359452123437, 6.511250688931522, 6.493093664787311, 5.990838096245221, 6.205159417466444, 6.116170951976852, 5.694267950876748, 5.962589938951892, 5.552069079173535, 6.195522845615541, 5.79503901400831, 5.850626998510586, 5.543203849500378, 5.978983289909443, 5.470584299662456, 6.0412658665190255, 5.8331266583549395, 5.792663055140744, 5.47212989874276, 5.522631776007705, 5.647918153237937, 5.500135728036695, 5.448544857244061, 5.075122962565039, 5.034261996214524, 5.254987225033498, 5.178699874424674, 5.019762605344746, 5.053393580322723, 4.979698754729002, 5.103166178679716, 4.805021757768129, 4.826238428071916, 4.721325336378454, 4.563250585164112, 4.708234742098728, 5.035611393754914, 4.824578746129101, 4.5864868803071195, 4.607561905379494, 4.755761286682143, 4.492169486286459, 4.088960104645852, 4.219702930286874, 4.248653456773598, 4.574814686794762, 4.673113531714767, 4.337701229716601, 4.413862062959362, 4.272666844413251, 4.0617278341942376, 4.524546606765833, 4.292912810998904, 4.1716280383673805, 4.326248675068464, 4.178634390329559, 4.1785363684517005, 4.079291589108216, 4.180188714623859, 3.7200746762720143, 3.88400428547434, 4.086583131373151, 3.805667190953341, 3.859907639568831, 3.9513873640679367, 3.6795437849746797, 3.9122438831301904, 3.879135225223958, 3.7366665238886503, 3.7063262540952606, 3.738075688900719, 3.5375232636469573, 3.3603788150744625, 3.6315637222562787, 3.394777877668879, 3.670305928040581, 3.794077407629365, 3.4033864017417326, 3.448159345885996, 3.427956818357422, 3.297666690273809, 3.1812962261828344, 3.4980834430388623, 3.2290240236019745, 3.1504375467047554, 2.8705613639078136, 3.167731578044347, 3.3530887076366445, 3.2464950191363946, 3.1481675148282466, 2.981869974956071, 3.3918132628712816, 3.007311525470088, 2.9053469519103032, 3.0950939544886737, 3.0426684657394927, 3.181494733674956, 3.0972268721194065, 3.0185166342599756, 3.1927490052432117, 2.930912047710843, 2.9847228560610177, 2.8798554494629696, 2.9306878680857125, 2.928610143762235, 2.891481244279876, 3.2017963919177705, 2.8300160619705625, 2.93712506694189, 2.9130344408611073, 2.984533349466789, 2.742961774105034, 2.948907940028299, 2.6724258401985748, 2.53598534644699, 2.766029833873575, 2.3478803903799355, 2.6018915624727583, 2.766863677021704, 2.7575002879988, 2.721417320761776, 2.353009492892345, 2.430028342163934, 2.5907883406545307, 2.7642938902886347, 2.536130712177279, 2.5627620649793363, 2.263155558306055, 2.5770865462955435, 2.35319345377849, 2.5644538607732534, 2.315118075869328, 2.4610509105892175, 2.358574700259593, 2.440918074522445, 2.4380803665053254, 2.4447413017376842, 2.263380411813042, 2.066716148633625, 2.1087740673094424, 2.4894621013456235, 2.1331125522605237, 2.4763662829087365, 2.303060986619337, 2.271338585801438, 1.9886330113554938, 2.0033996303699624, 2.180687172033797, 1.9225879316336942, 2.142630751517716, 2.123023621822399, 2.1023723524931754, 2.0051338470480258, 1.941002619174367, 2.0381616474328665, 1.9527052098271236, 2.195041280915452, 1.9959339868608597, 1.9717430797662847, 1.917770039534883, 1.7191295318997957, 2.013909039838242, 2.0154678920808022, 1.9904270088901876, 1.9033673773401552, 1.9274550735730247, 1.919835572132587, 2.1310172655744597, 1.7019352618556007, 1.9511967751131554, 1.6584741403357148, 2.028188891180131, 1.755373699002763, 1.8193937398108433, 1.7788570916256066, 1.8486947001396337, 1.6664510919592443, 1.7279707840788983, 1.8763816889169944, 1.8242683220681044, 1.6579866413064726, 1.6860986078744804, 1.7723941305679058, 1.603477846547249, 1.6861186633928695, 1.6744309074216506, 1.7092379054275106, 1.7997097025060669, 1.7481324983990376, 1.587927408854703, 1.5266359518191526, 1.7010448401012668, 1.5687618894470128, 1.5508927622862692, 1.5175450918320013, 1.7175680475637918, 1.711832701897995, 1.530859736119046, 1.5237462050856938, 1.5283791109050973, 1.4534670543432873, 1.548634853795814, 1.5002509678274707, 1.705000549097436, 1.5091096702064304, 1.437584150246177, 1.684764615830675, 1.4185301916043294, 1.5583995648763453, 1.5565730675378218, 1.466067310058873, 1.3385811848292186, 1.454007075209687, 1.529512173154481, 1.5258013314511485, 1.4114075586540842, 1.3558902221657232, 1.4755286591641708, 1.395443228133799, 1.3503590810996504, 1.4700116349047934, 1.4349820184861017, 1.6135288473522709, 1.387214948272693, 1.3926266032869996, 1.3310424724271552, 1.4053627115985479, 1.539249578519528, 1.453693339981262, 1.4812767368483626, 1.2722337888330537, 1.3421553527629597, 1.5113128740267592, 1.2781290451201988, 1.3423289722871086, 1.092513112216117, 1.5689434140134288, 1.0978859876519977, 1.4743777012483028, 1.412272795435315, 1.2826090583321605, 1.4279495510262596, 1.28025327856235, 1.287458178581807, 1.221735121797669, 1.3742948304459326, 1.508208106105467, 1.355409771368076, 1.1764276195350645, 1.435811091859169, 1.3902382750475166, 1.199252928829959, 1.3225938034343392, 1.2412462245448468, 1.2681231026242068, 1.3351070740827589, 1.2883526445531173, 1.2730516819295283, 1.265398062943391, 1.2461251335918122, 1.182366280464668, 1.2210270459151011, 1.184396263162991, 1.428332370831635, 1.261318748139031, 1.3667568023932353, 1.2717825801818174, 1.2004718337835951, 1.0881459353543508, 1.3022013253370694, 1.3335303401341037, 1.2786157920247458, 1.256544700821575, 1.2731823654023606, 1.1658862554085807, 1.0319625138489554, 1.35857028554191, 1.2609163652404196, 1.2070747715572518, 1.1414675460525145, 1.318235889798827, 1.13410868092814, 1.1280909423895287, 1.2035774071585248, 1.2200194213278173, 1.178643109823236, 1.1206987212474397, 1.1951196472479027, 1.0484838006243213, 1.1681953835444074, 1.2080341245769413, 1.3685114876452735, 0.9825760155240895, 1.1595092967342377, 1.0456527710469077, 1.216528714799892, 1.1229442626172266, 0.9908673246095276, 1.185450057374594, 1.0653763302236898, 1.0965188331696236, 1.0615955118512352, 1.2367154522685133, 1.1048827676686084, 1.0609454970764383, 1.2285929431278364, 1.0897123666041513, 1.003838952021667, 1.0210984101667275, 1.037456442076405, 1.0994187326925786, 1.0311805863184749, 1.1263011727415708, 1.0246057049687434, 0.9776858571505739, 1.0407611144143596, 1.0060373098280695, 1.1131508633642033, 1.0711183472706614, 1.0334394701944607, 1.2067826021238974, 1.2100545382128367, 1.0658277518897874, 1.1543128754958594, 1.0804721819377687, 0.9724991556156443, 0.9391299680927339, 1.075713749594131, 1.06814846747926, 1.0599807685326301, 1.042916621644196, 1.0013982578731686, 0.912834418202284, 0.9203598342846157, 0.9909114978739189, 1.0736145261729684, 0.9858919149257249, 0.9691545975144162, 0.9842436644804807, 0.9955622558944963, 1.05011171473133, 0.9009435049814026, 0.9059816577927008, 1.0328203128109195, 0.9690342477239394, 1.0695519922321344, 0.9114452925457491, 1.0476587040640832, 1.1835173355590092, 0.8759870900151631, 0.9082069339332304, 1.049751697270454, 0.8984421253575804, 1.1994924319414026, 0.9590105053493582, 1.0035710407930771, 0.9321935960527151, 1.0226294799582265, 0.9651133214156589, 0.99355614294804, 0.9993399364181909, 0.9629347040628442, 0.9124419801556233, 0.9526996303820822, 1.0218938380968263, 0.8803545166323866, 0.9976138392107549, 0.8308490347937232, 1.010317743415888, 0.8154658981162092, 1.0367144705906617, 0.9079252335848969, 0.9536170090734963, 0.9050714986214228, 1.0560904340005561, 0.9127449901643439, 0.9247769664885325, 1.0108102350317698, 0.8891339234554588, 0.785674658392039, 1.0540228670803302, 1.0034177968773292, 0.928089502310727, 0.9447361303753874, 0.8016823380733246, 0.895984545705264, 0.882548531823748, 0.8943247445602346, 0.9137992513116644, 0.9171482732740259, 0.8272994123187102, 0.9216264899721852, 0.9719030534939436, 0.914645784069393, 0.8930357865921227, 1.0441963075460956, 0.9096587290551655, 0.845938997722721, 0.9475858804120789, 1.0584625648212636, 0.8285685285383698, 0.8625211266644148, 0.9093656270431851, 0.8821877468573275, 0.9392657780894411, 0.8688011602040422, 0.815835495779232, 1.00617442040142, 0.8018282711901361, 0.872812146809797, 0.9916190319678274, 0.8193023671597931, 0.8870679455333093, 0.9010909568080936, 0.9686781354049215, 0.7855532407757763, 0.7646336585317907, 1.0831467696761776, 0.8107188945188454, 0.8953191969508301, 0.913692296549595, 0.9857430657710319, 0.833799504132324, 0.7914665995787452, 0.7927254339414227, 0.8396170073149556, 0.9086556213687319, 0.868774229752036, 0.9302516292036641, 0.7768808151077212, 0.9373956009658406, 0.7829890061264738, 0.9122753593126245, 0.8173216618627404, 0.7476390518535085, 0.81024636419458, 0.9092258742468775, 0.8400427723975586, 0.7702974885393541, 0.8366590878807407, 0.8318745399049869, 0.8132978268879837, 0.8721449792074324, 0.7922971660800343, 0.8632140043451914, 0.884954665307533, 0.7400178437088987], 'mae': [10.330855, 3.7725797, 3.0568767, 2.7771614, 2.7185013, 2.6206734, 2.5305858, 2.4056675, 2.3892372, 2.3111799, 2.241837, 2.2769327, 2.2301166, 2.2605896, 2.2533708, 2.1620672, 2.1674097, 2.1174378, 2.0965312, 2.055196, 2.0522733, 2.0414872, 2.0303638, 2.017343, 2.0290306, 1.9785519, 1.9443938, 1.9421953, 1.9616542, 1.9478077, 1.9169372, 1.940954, 1.9254284, 1.8554019, 1.8643309, 1.8873618, 1.8823496, 1.8176006, 1.8467268, 1.8642278, 1.8587147, 1.8316671, 1.8632033, 1.7521093, 1.7515454, 1.7932383, 1.7736194, 1.7165656, 1.755028, 1.7603176, 1.6879568, 1.6944752, 1.6769396, 1.6751076, 1.6861196, 1.6043146, 1.6392506, 1.6501365, 1.5758063, 1.6144392, 1.6207741, 1.5128542, 1.6679531, 1.5700011, 1.6527513, 1.5724146, 1.6198566, 1.552155, 1.5931517, 1.5649005, 1.5644518, 1.5507985, 1.5547329, 1.5603993, 1.5291809, 1.5335708, 1.5114528, 1.4917454, 1.4887692, 1.4995626, 1.4776525, 1.5335402, 1.560603, 1.4591328, 1.4473932, 1.4498032, 1.4433085, 1.4561701, 1.4767216, 1.4528646, 1.4237684, 1.4306122, 1.439302, 1.4307247, 1.4123491, 1.3954948, 1.4156886, 1.4035969, 1.4117335, 1.397554, 1.3699329, 1.3812762, 1.3878655, 1.3431528, 1.4584275, 1.3547691, 1.3417829, 1.4066831, 1.3764133, 1.3589885, 1.3019019, 1.3163567, 1.2798802, 1.3256009, 1.2972318, 1.3386364, 1.3279449, 1.3168805, 1.3233571, 1.3112102, 1.330552, 1.3280653, 1.3350531, 1.3406891, 1.3070241, 1.2858124, 1.2830973, 1.252209, 1.2709311, 1.2833164, 1.2457638, 1.2457552, 1.258926, 1.2277164, 1.2043952, 1.2892327, 1.2578703, 1.2148129, 1.2168816, 1.2330384, 1.2110969, 1.2392277, 1.2134236, 1.1669649, 1.2097973, 1.2254217, 1.2233262, 1.2232802, 1.2239964, 1.1946161, 1.2165529, 1.2261429, 1.2605172, 1.1543803, 1.2072328, 1.1797742, 1.1993275, 1.1571999, 1.1862549, 1.1893218, 1.1462828, 1.1844898, 1.1702291, 1.180867, 1.1422544, 1.1811365, 1.1131978, 1.1490715, 1.1652904, 1.094073, 1.1158808, 1.1395161, 1.1511675, 1.1271971, 1.1315808, 1.0915021, 1.1357563, 1.1411113, 1.1337953, 1.1021684, 1.1119156, 1.1306092, 1.1145508, 1.1485797, 1.1262789, 1.1107227, 1.0355045, 1.1155707, 1.1220455, 1.1210468, 1.078029, 1.0600923, 1.0599312, 1.101393, 1.0747405, 1.13274, 1.0753487, 1.0947379, 1.0284957, 1.0319424, 1.0403484, 0.95230305, 1.0375375, 1.0529944, 1.0344905, 1.0132333, 1.012347, 1.0185596, 0.99961966, 1.0593914, 1.0285147, 1.0291208, 1.0147216, 0.98475933, 0.9772345, 1.0236499, 1.0004417, 1.0276058, 0.98001987, 0.97375005, 1.033367, 0.95299107, 1.0285751, 0.9460987, 1.0321409, 0.961836, 0.99835706, 0.9599993, 0.9806732, 0.94923395, 0.9783522, 0.99078923, 1.0117255, 0.971148, 0.94909465, 0.9586208, 0.9517254, 0.956037, 0.96655244, 0.95677423, 0.9804911, 0.95888525, 0.93683183, 0.9051579, 0.92698574, 0.9231227, 0.9051952, 0.91636944, 0.9788852, 0.9182939, 0.9348334, 0.88916904, 0.9179838, 0.8709098, 0.9176242, 0.8985727, 0.9273891, 0.89155734, 0.9111817, 0.95063424, 0.88656473, 0.9284925, 0.9091519, 0.87973565, 0.8437503, 0.9012464, 0.9000015, 0.9262041, 0.86873984, 0.87228507, 0.8941191, 0.8752104, 0.85039157, 0.90751946, 0.85550135, 0.903387, 0.84571964, 0.8656853, 0.853488, 0.85543907, 0.88609993, 0.85825944, 0.85289764, 0.8518545, 0.8688756, 0.8952989, 0.8549679, 0.86539, 0.7884173, 0.89284724, 0.7615872, 0.89257056, 0.85520273, 0.8192761, 0.88380086, 0.81527394, 0.82270765, 0.826793, 0.83607566, 0.8740439, 0.803329, 0.79802984, 0.8470625, 0.8840236, 0.8238901, 0.83243966, 0.8282747, 0.83040756, 0.83692074, 0.82454157, 0.82612455, 0.83524096, 0.84371084, 0.7880171, 0.8026506, 0.82782716, 0.8306604, 0.81547993, 0.82338357, 0.841051, 0.7971225, 0.7760963, 0.8318029, 0.8564598, 0.8318634, 0.8040928, 0.85116154, 0.77818686, 0.7544018, 0.7987666, 0.8017534, 0.82482177, 0.80677253, 0.81974614, 0.7974808, 0.7568066, 0.81248486, 0.79020065, 0.78729963, 0.75128514, 0.80193645, 0.7648129, 0.79240066, 0.81116664, 0.8256729, 0.7235977, 0.7632449, 0.7564008, 0.7843908, 0.7157271, 0.7339832, 0.7908074, 0.74257004, 0.77022535, 0.73403984, 0.7853687, 0.7732585, 0.7599622, 0.7710807, 0.7635453, 0.73350286, 0.7321544, 0.75534916, 0.7593832, 0.7755827, 0.77946913, 0.7541434, 0.70985496, 0.73888487, 0.73513776, 0.8018336, 0.73526365, 0.7270285, 0.7607381, 0.7751506, 0.77214366, 0.7742948, 0.76488715, 0.73892945, 0.71411043, 0.72850186, 0.7098657, 0.7477532, 0.74458814, 0.734159, 0.6850842, 0.71083796, 0.7279126, 0.7521125, 0.7483804, 0.7294916, 0.7029712, 0.7270477, 0.7526091, 0.67761934, 0.69533116, 0.71429807, 0.7024233, 0.77188313, 0.69428086, 0.7400751, 0.7131126, 0.7073119, 0.7280598, 0.7369477, 0.70154405, 0.67317283, 0.7188927, 0.69648015, 0.69808805, 0.72444314, 0.7157742, 0.7129299, 0.6976482, 0.70658034, 0.7182514, 0.6925161, 0.7459225, 0.7086776, 0.73235786, 0.67489123, 0.72353405, 0.6724831, 0.74508846, 0.70474523, 0.7333386, 0.6940481, 0.7481461, 0.6729052, 0.7141768, 0.68381435, 0.69960165, 0.65895754, 0.72062474, 0.7165376, 0.6618736, 0.7303034, 0.68253595, 0.6722427, 0.6842556, 0.7078332, 0.682611, 0.71697485, 0.66912585, 0.6805361, 0.7166144, 0.68784577, 0.7034329, 0.6695974, 0.6687583, 0.6807759, 0.7204888, 0.7197734, 0.66917443, 0.6670927, 0.70138675, 0.69950026, 0.6816847, 0.6561261, 0.6667167, 0.70330775, 0.66476786, 0.67281705, 0.73297364, 0.6322939, 0.693479, 0.6657489, 0.7334832, 0.6541601, 0.6306768, 0.6942557, 0.6552605, 0.66365004, 0.6805356, 0.7024252, 0.68326724, 0.67358935, 0.65576935, 0.66412014, 0.6766622, 0.7012176, 0.6848619, 0.63150805, 0.6714091, 0.65788966, 0.68710554, 0.6689885, 0.6408046, 0.6632403, 0.71380633, 0.6390268, 0.66512316, 0.65396875, 0.665985, 0.6586726, 0.6659784, 0.63872, 0.66643304, 0.69627154, 0.651466]}\n",
      "processing fold # 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 220.9122 - mae: 11.1088 - val_loss: 23.3067 - val_mae: 3.6919\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 27.1138 - mae: 3.4790 - val_loss: 19.4115 - val_mae: 3.3728\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 19.7599 - mae: 2.9694 - val_loss: 15.8217 - val_mae: 3.0137\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 15.3109 - mae: 2.6740 - val_loss: 14.7753 - val_mae: 2.9092\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 13.4645 - mae: 2.4557 - val_loss: 14.3250 - val_mae: 2.8314\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 12.4605 - mae: 2.4222 - val_loss: 14.4741 - val_mae: 2.9090\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 11.8409 - mae: 2.3568 - val_loss: 12.5759 - val_mae: 2.6612\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 0s 753us/step - loss: 10.7626 - mae: 2.2346 - val_loss: 12.6627 - val_mae: 2.7042\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 10.9814 - mae: 2.2336 - val_loss: 12.9572 - val_mae: 2.7413\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 10.9573 - mae: 2.2282 - val_loss: 14.2111 - val_mae: 2.8975\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 9.8901 - mae: 2.2125 - val_loss: 11.4629 - val_mae: 2.5918\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 10.3259 - mae: 2.1494 - val_loss: 12.2719 - val_mae: 2.6529\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 9.9473 - mae: 2.0650 - val_loss: 12.7673 - val_mae: 2.7555\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 9.6816 - mae: 2.1263 - val_loss: 11.2063 - val_mae: 2.5121\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 0s 750us/step - loss: 9.6015 - mae: 2.0732 - val_loss: 12.4679 - val_mae: 2.6980\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 9.3912 - mae: 2.0972 - val_loss: 10.9131 - val_mae: 2.5171\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 9.3753 - mae: 1.9805 - val_loss: 10.7300 - val_mae: 2.4724\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 8.6693 - mae: 2.0001 - val_loss: 10.6902 - val_mae: 2.5014\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 8.8648 - mae: 1.9735 - val_loss: 11.1434 - val_mae: 2.5458\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 8.3837 - mae: 1.8898 - val_loss: 11.0198 - val_mae: 2.5187\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 8.8667 - mae: 1.9360 - val_loss: 13.4625 - val_mae: 2.8346\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 8.2935 - mae: 1.8977 - val_loss: 10.5458 - val_mae: 2.4776\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 8.2699 - mae: 1.9503 - val_loss: 9.7035 - val_mae: 2.3591\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 8.3605 - mae: 1.9098 - val_loss: 13.7857 - val_mae: 2.9293\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 0s 797us/step - loss: 7.8706 - mae: 1.9261 - val_loss: 10.1750 - val_mae: 2.4165\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 7.9321 - mae: 1.8414 - val_loss: 10.1794 - val_mae: 2.4369\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 8.0232 - mae: 1.9216 - val_loss: 11.0319 - val_mae: 2.5664\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 0s 747us/step - loss: 7.8112 - mae: 1.8479 - val_loss: 9.5022 - val_mae: 2.3347\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 7.4804 - mae: 1.7766 - val_loss: 11.0966 - val_mae: 2.5874\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 7.3448 - mae: 1.8238 - val_loss: 10.4782 - val_mae: 2.4777\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 6.9589 - mae: 1.7502 - val_loss: 10.6035 - val_mae: 2.5019\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 7.4423 - mae: 1.8385 - val_loss: 10.7905 - val_mae: 2.5588\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 7.0059 - mae: 1.7935 - val_loss: 10.9107 - val_mae: 2.5840\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 7.1948 - mae: 1.7680 - val_loss: 13.1217 - val_mae: 2.8718\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 7.1222 - mae: 1.7942 - val_loss: 11.1469 - val_mae: 2.5903\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 7.0614 - mae: 1.7924 - val_loss: 10.1811 - val_mae: 2.4365\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 7.0532 - mae: 1.7762 - val_loss: 10.2742 - val_mae: 2.5293\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 7.0669 - mae: 1.7917 - val_loss: 9.2949 - val_mae: 2.3410\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 0s 780us/step - loss: 6.9117 - mae: 1.7152 - val_loss: 10.8636 - val_mae: 2.6121\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 0s 778us/step - loss: 6.5532 - mae: 1.7355 - val_loss: 10.3708 - val_mae: 2.4905\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 6.7082 - mae: 1.7526 - val_loss: 10.7892 - val_mae: 2.5275\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 6.6009 - mae: 1.7293 - val_loss: 11.8473 - val_mae: 2.6767\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 0s 748us/step - loss: 6.2248 - mae: 1.6795 - val_loss: 13.2475 - val_mae: 2.8725\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 0s 744us/step - loss: 5.9649 - mae: 1.7223 - val_loss: 8.5585 - val_mae: 2.2259\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 0s 765us/step - loss: 6.7186 - mae: 1.7316 - val_loss: 12.3039 - val_mae: 2.7626\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 6.2163 - mae: 1.6985 - val_loss: 9.5870 - val_mae: 2.3435\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 6.0765 - mae: 1.6652 - val_loss: 10.1210 - val_mae: 2.4652\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 5.9781 - mae: 1.6682 - val_loss: 11.5053 - val_mae: 2.6255\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 6.2034 - mae: 1.6913 - val_loss: 9.0978 - val_mae: 2.2982\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 6.0060 - mae: 1.6623 - val_loss: 9.6144 - val_mae: 2.3818\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 6.1037 - mae: 1.5986 - val_loss: 9.8413 - val_mae: 2.4068\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 6.0318 - mae: 1.6068 - val_loss: 11.2591 - val_mae: 2.6738\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 5.6117 - mae: 1.6061 - val_loss: 9.3340 - val_mae: 2.3863\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 5.9398 - mae: 1.5877 - val_loss: 10.2513 - val_mae: 2.4574\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 5.7392 - mae: 1.6125 - val_loss: 9.8211 - val_mae: 2.3744\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 5.5503 - mae: 1.5989 - val_loss: 10.9406 - val_mae: 2.5654\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 5.9053 - mae: 1.5889 - val_loss: 8.9228 - val_mae: 2.3203\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 5.3548 - mae: 1.5870 - val_loss: 9.1558 - val_mae: 2.2743\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 5.7439 - mae: 1.6097 - val_loss: 10.3879 - val_mae: 2.5061\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 726us/step - loss: 5.4421 - mae: 1.5761 - val_loss: 9.7828 - val_mae: 2.3933\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 5.5635 - mae: 1.5364 - val_loss: 12.1393 - val_mae: 2.6061\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 5.4677 - mae: 1.5852 - val_loss: 11.3953 - val_mae: 2.5701\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 5.3600 - mae: 1.5895 - val_loss: 9.3875 - val_mae: 2.2970\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 5.1863 - mae: 1.5462 - val_loss: 9.7616 - val_mae: 2.4105\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 0s 757us/step - loss: 5.6680 - mae: 1.5510 - val_loss: 10.2174 - val_mae: 2.4088\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 0s 796us/step - loss: 5.1858 - mae: 1.4517 - val_loss: 9.9983 - val_mae: 2.3787\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 5.3720 - mae: 1.4980 - val_loss: 10.1405 - val_mae: 2.4251\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 4.8358 - mae: 1.4554 - val_loss: 13.5313 - val_mae: 2.7101\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 5.0062 - mae: 1.4986 - val_loss: 12.2256 - val_mae: 2.6429\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 4.7755 - mae: 1.4966 - val_loss: 10.5109 - val_mae: 2.4876\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 4.8865 - mae: 1.5123 - val_loss: 10.4326 - val_mae: 2.4042\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 0s 747us/step - loss: 5.2687 - mae: 1.5131 - val_loss: 11.3737 - val_mae: 2.5421\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 4.8701 - mae: 1.4764 - val_loss: 9.9943 - val_mae: 2.3783\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 0s 751us/step - loss: 4.9255 - mae: 1.4608 - val_loss: 11.4384 - val_mae: 2.5703\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 4.7090 - mae: 1.4283 - val_loss: 14.9247 - val_mae: 2.9801\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 4.9649 - mae: 1.4765 - val_loss: 12.1333 - val_mae: 2.6370\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 4.5414 - mae: 1.5062 - val_loss: 11.1154 - val_mae: 2.5856\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 4.5701 - mae: 1.4603 - val_loss: 11.8327 - val_mae: 2.6063\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 4.4391 - mae: 1.4375 - val_loss: 10.3283 - val_mae: 2.4303\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 4.7715 - mae: 1.4178 - val_loss: 15.2957 - val_mae: 2.8808\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 4.7036 - mae: 1.4312 - val_loss: 12.0373 - val_mae: 2.5515\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 4.4874 - mae: 1.4027 - val_loss: 13.8801 - val_mae: 2.7643\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 4.6516 - mae: 1.3942 - val_loss: 10.1182 - val_mae: 2.3647\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 0s 701us/step - loss: 4.7028 - mae: 1.4524 - val_loss: 12.1020 - val_mae: 2.6404\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 4.6644 - mae: 1.4231 - val_loss: 10.9975 - val_mae: 2.4602\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 4.4682 - mae: 1.4054 - val_loss: 12.0794 - val_mae: 2.5930\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 4.4508 - mae: 1.3699 - val_loss: 12.0156 - val_mae: 2.6115\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 4.5971 - mae: 1.3969 - val_loss: 12.0082 - val_mae: 2.5941\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 4.1936 - mae: 1.3427 - val_loss: 13.0961 - val_mae: 2.7103\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 4.2907 - mae: 1.3849 - val_loss: 10.9273 - val_mae: 2.4498\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 4.3101 - mae: 1.3361 - val_loss: 14.8938 - val_mae: 2.8278\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 3.8246 - mae: 1.3157 - val_loss: 13.8685 - val_mae: 2.6939\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 0s 825us/step - loss: 3.9711 - mae: 1.3795 - val_loss: 13.2471 - val_mae: 2.7053\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 3.3863 - mae: 1.2993 - val_loss: 11.1562 - val_mae: 2.4540\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 3.9078 - mae: 1.3726 - val_loss: 12.2297 - val_mae: 2.5541\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 4.1497 - mae: 1.3817 - val_loss: 13.8326 - val_mae: 2.7206\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 3.9355 - mae: 1.3170 - val_loss: 15.3918 - val_mae: 2.8261\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 4.0079 - mae: 1.3944 - val_loss: 13.4639 - val_mae: 2.6581\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 3.9944 - mae: 1.3275 - val_loss: 13.5402 - val_mae: 2.5863\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 3.8032 - mae: 1.3126 - val_loss: 16.4650 - val_mae: 2.9516\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 3.8230 - mae: 1.3373 - val_loss: 15.6646 - val_mae: 2.8779\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 4.0044 - mae: 1.2908 - val_loss: 13.1490 - val_mae: 2.5941\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 3.6638 - mae: 1.2835 - val_loss: 16.1511 - val_mae: 3.0133\n",
      "Epoch 104/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 3.8140 - mae: 1.3270 - val_loss: 20.2092 - val_mae: 3.1441\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 0s 820us/step - loss: 3.7061 - mae: 1.3417 - val_loss: 13.0200 - val_mae: 2.6004\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 3.7178 - mae: 1.3187 - val_loss: 14.3938 - val_mae: 2.7365\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 3.9829 - mae: 1.3373 - val_loss: 14.5065 - val_mae: 2.7107\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 3.8454 - mae: 1.3088 - val_loss: 13.2373 - val_mae: 2.6052\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 3.6752 - mae: 1.3038 - val_loss: 11.6873 - val_mae: 2.4630\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 0s 752us/step - loss: 3.7008 - mae: 1.2865 - val_loss: 15.9290 - val_mae: 2.8597\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 3.7314 - mae: 1.3043 - val_loss: 17.3984 - val_mae: 2.9033\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 3.8045 - mae: 1.3470 - val_loss: 14.0465 - val_mae: 2.7351\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 0s 750us/step - loss: 3.6150 - mae: 1.2547 - val_loss: 16.2627 - val_mae: 2.8563\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 3.3134 - mae: 1.2007 - val_loss: 14.3332 - val_mae: 2.6282\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 0s 748us/step - loss: 3.5528 - mae: 1.2577 - val_loss: 12.6241 - val_mae: 2.5609\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 0s 775us/step - loss: 3.2376 - mae: 1.2326 - val_loss: 13.2501 - val_mae: 2.5539\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 0s 790us/step - loss: 3.6674 - mae: 1.2582 - val_loss: 22.8367 - val_mae: 3.2291\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 3.5204 - mae: 1.2413 - val_loss: 14.7953 - val_mae: 2.6714\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 0s 782us/step - loss: 3.4353 - mae: 1.2087 - val_loss: 14.0004 - val_mae: 2.7004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "303/303 [==============================] - 0s 783us/step - loss: 3.6584 - mae: 1.2186 - val_loss: 19.1295 - val_mae: 2.8369\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 3.3680 - mae: 1.2484 - val_loss: 13.2776 - val_mae: 2.6690\n",
      "Epoch 122/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 3.5560 - mae: 1.2250 - val_loss: 15.6700 - val_mae: 2.7492\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 3.0498 - mae: 1.1638 - val_loss: 24.5541 - val_mae: 3.1866\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 3.2668 - mae: 1.1583 - val_loss: 17.7144 - val_mae: 2.8765\n",
      "Epoch 125/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 3.3148 - mae: 1.2520 - val_loss: 15.0385 - val_mae: 2.7487\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 3.3127 - mae: 1.2339 - val_loss: 15.5817 - val_mae: 2.7186\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 3.1899 - mae: 1.1907 - val_loss: 15.6366 - val_mae: 2.6780\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 3.0414 - mae: 1.1784 - val_loss: 21.3379 - val_mae: 3.1071\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 3.1617 - mae: 1.1993 - val_loss: 16.7621 - val_mae: 2.7939\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 3.0479 - mae: 1.1932 - val_loss: 13.5184 - val_mae: 2.6506\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 3.0369 - mae: 1.1850 - val_loss: 19.9204 - val_mae: 3.0509\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 3.0434 - mae: 1.1295 - val_loss: 18.4670 - val_mae: 2.9045\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 2.8968 - mae: 1.1695 - val_loss: 22.0711 - val_mae: 3.1830\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 3.1835 - mae: 1.2019 - val_loss: 15.2406 - val_mae: 2.6496\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 3.0659 - mae: 1.1492 - val_loss: 13.6886 - val_mae: 2.5757\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 3.0285 - mae: 1.1588 - val_loss: 15.3253 - val_mae: 2.6819\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 3.1700 - mae: 1.1902 - val_loss: 20.6064 - val_mae: 2.9034\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 2.9572 - mae: 1.1341 - val_loss: 19.3560 - val_mae: 2.9357\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 0s 835us/step - loss: 2.9995 - mae: 1.1798 - val_loss: 16.4881 - val_mae: 2.7946\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 2.8703 - mae: 1.1121 - val_loss: 20.9102 - val_mae: 3.0823\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 2.7359 - mae: 1.1262 - val_loss: 17.6296 - val_mae: 2.7261\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 2.8369 - mae: 1.1839 - val_loss: 14.2618 - val_mae: 2.5735\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 2.6570 - mae: 1.1535 - val_loss: 21.4135 - val_mae: 3.2061\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 2.7186 - mae: 1.1409 - val_loss: 25.1049 - val_mae: 3.3621\n",
      "Epoch 145/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 3.0173 - mae: 1.1362 - val_loss: 17.1108 - val_mae: 2.7418\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 2.9341 - mae: 1.1783 - val_loss: 19.1646 - val_mae: 2.9524\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 2.6805 - mae: 1.1296 - val_loss: 24.5529 - val_mae: 3.2309\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 2.6143 - mae: 1.1014 - val_loss: 15.3449 - val_mae: 2.6262\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 2.5240 - mae: 1.1072 - val_loss: 20.2536 - val_mae: 3.0099\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 2.6558 - mae: 1.1275 - val_loss: 17.8859 - val_mae: 2.8378\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 2.7345 - mae: 1.1398 - val_loss: 23.9148 - val_mae: 3.1669\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 0s 758us/step - loss: 2.3632 - mae: 1.0636 - val_loss: 22.1864 - val_mae: 3.0009\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 0s 765us/step - loss: 2.7196 - mae: 1.1414 - val_loss: 23.3165 - val_mae: 3.0379\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 2.4677 - mae: 1.0654 - val_loss: 18.1911 - val_mae: 2.8336\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 2.4598 - mae: 1.1125 - val_loss: 24.1049 - val_mae: 3.1846\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 2.2960 - mae: 1.1202 - val_loss: 19.0903 - val_mae: 2.9033\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 2.4357 - mae: 1.1045 - val_loss: 16.9871 - val_mae: 2.7972\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 2.4366 - mae: 1.0948 - val_loss: 20.3581 - val_mae: 2.9123\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 2.4192 - mae: 1.0719 - val_loss: 19.7528 - val_mae: 2.9318\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 2.3170 - mae: 1.0638 - val_loss: 23.1752 - val_mae: 2.9516\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 0s 771us/step - loss: 2.2560 - mae: 1.0430 - val_loss: 20.8737 - val_mae: 2.9859\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 2.3880 - mae: 1.0893 - val_loss: 24.5015 - val_mae: 3.3092\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 2.5493 - mae: 1.0809 - val_loss: 18.9740 - val_mae: 2.8813\n",
      "Epoch 164/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 2.2358 - mae: 1.0350 - val_loss: 19.2785 - val_mae: 3.1420\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 2.4478 - mae: 1.0873 - val_loss: 22.2462 - val_mae: 3.1094\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 2.2741 - mae: 1.1052 - val_loss: 26.6944 - val_mae: 3.3312\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 2.2974 - mae: 1.0180 - val_loss: 22.7226 - val_mae: 3.0694\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 2.4118 - mae: 1.0629 - val_loss: 22.8907 - val_mae: 3.0716\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 2.4256 - mae: 1.0610 - val_loss: 19.4246 - val_mae: 2.9490\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 2.4713 - mae: 1.1251 - val_loss: 19.9390 - val_mae: 3.0947\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 2.1539 - mae: 1.0264 - val_loss: 20.4817 - val_mae: 3.1306\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 2.2256 - mae: 1.0356 - val_loss: 20.3299 - val_mae: 2.8749\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 2.3671 - mae: 1.0877 - val_loss: 23.2778 - val_mae: 3.0483\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 2.1555 - mae: 1.0508 - val_loss: 24.7056 - val_mae: 3.0557\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 2.1448 - mae: 1.0000 - val_loss: 21.0517 - val_mae: 2.8259\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 2.1553 - mae: 1.0451 - val_loss: 20.3344 - val_mae: 2.9197\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 2.1693 - mae: 1.0295 - val_loss: 18.3338 - val_mae: 2.7626\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 2.1995 - mae: 1.0647 - val_loss: 21.6967 - val_mae: 3.1308\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 726us/step - loss: 2.1919 - mae: 1.0524 - val_loss: 29.3906 - val_mae: 3.4322\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 2.0133 - mae: 0.9937 - val_loss: 32.0535 - val_mae: 3.5338\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 2.1266 - mae: 1.0372 - val_loss: 20.3531 - val_mae: 2.7779\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 2.0157 - mae: 0.9761 - val_loss: 20.2017 - val_mae: 2.9896\n",
      "Epoch 183/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 2.0607 - mae: 0.9940 - val_loss: 22.6178 - val_mae: 3.0759\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 2.1156 - mae: 0.9953 - val_loss: 20.9583 - val_mae: 3.0218\n",
      "Epoch 185/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 2.0142 - mae: 0.9882 - val_loss: 18.9127 - val_mae: 2.9012\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.9499 - mae: 1.0000 - val_loss: 20.5079 - val_mae: 2.8756\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 2.0263 - mae: 1.0188 - val_loss: 17.9159 - val_mae: 2.9123\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.9702 - mae: 0.9787 - val_loss: 22.1791 - val_mae: 3.0832\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 2.1138 - mae: 1.0062 - val_loss: 19.4571 - val_mae: 3.0818\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 2.0127 - mae: 0.9990 - val_loss: 24.3378 - val_mae: 3.0468\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.9804 - mae: 1.0315 - val_loss: 20.6793 - val_mae: 2.9587\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.9458 - mae: 1.0191 - val_loss: 23.5573 - val_mae: 3.0656\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.8734 - mae: 0.9668 - val_loss: 17.7789 - val_mae: 3.0403\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.9492 - mae: 1.0118 - val_loss: 28.1619 - val_mae: 3.1153\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.9001 - mae: 0.9873 - val_loss: 20.9926 - val_mae: 2.9461\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.8948 - mae: 0.9838 - val_loss: 19.2069 - val_mae: 2.9327\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 1.8068 - mae: 0.9435 - val_loss: 23.3878 - val_mae: 3.0032\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.9981 - mae: 0.9887 - val_loss: 26.4517 - val_mae: 3.1884\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.9377 - mae: 0.9768 - val_loss: 29.0013 - val_mae: 3.2777\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.8082 - mae: 0.9776 - val_loss: 29.4186 - val_mae: 3.3025\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 2.0541 - mae: 1.0132 - val_loss: 27.4685 - val_mae: 3.3799\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 1.8012 - mae: 0.9605 - val_loss: 23.3730 - val_mae: 3.0990\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.9507 - mae: 1.0174 - val_loss: 32.9657 - val_mae: 3.2330\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 2.0381 - mae: 1.0265 - val_loss: 29.3623 - val_mae: 3.3624\n",
      "Epoch 205/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.8153 - mae: 0.9581 - val_loss: 24.3794 - val_mae: 2.9960\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 1.8616 - mae: 0.9518 - val_loss: 23.4691 - val_mae: 3.0029\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.6563 - mae: 0.9279 - val_loss: 26.1922 - val_mae: 3.3590\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.7961 - mae: 0.9762 - val_loss: 25.1822 - val_mae: 3.2089\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.8644 - mae: 0.9805 - val_loss: 30.4330 - val_mae: 3.3246\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.6551 - mae: 0.9189 - val_loss: 31.3974 - val_mae: 3.2136\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 1.7199 - mae: 0.9144 - val_loss: 31.2046 - val_mae: 3.4274\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.7879 - mae: 0.9662 - val_loss: 39.5082 - val_mae: 3.5294\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.7604 - mae: 0.9845 - val_loss: 24.0381 - val_mae: 3.1590\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.6910 - mae: 0.9208 - val_loss: 33.6266 - val_mae: 3.2706\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.7260 - mae: 0.9562 - val_loss: 22.3741 - val_mae: 3.1181\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.6848 - mae: 0.9415 - val_loss: 33.8584 - val_mae: 3.4967\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.6680 - mae: 0.9496 - val_loss: 26.3017 - val_mae: 3.4083\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.6738 - mae: 0.9068 - val_loss: 32.6295 - val_mae: 3.3877\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.6310 - mae: 0.9491 - val_loss: 27.6267 - val_mae: 3.2597\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 1.7262 - mae: 0.9671 - val_loss: 29.7579 - val_mae: 3.3054\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 1.5405 - mae: 0.9496 - val_loss: 23.6787 - val_mae: 3.1244\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.5930 - mae: 0.9559 - val_loss: 27.1619 - val_mae: 3.2038\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 1.6174 - mae: 0.9434 - val_loss: 29.6516 - val_mae: 3.3636\n",
      "Epoch 224/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.7316 - mae: 0.9725 - val_loss: 32.7835 - val_mae: 3.1801\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.6134 - mae: 0.9079 - val_loss: 24.5653 - val_mae: 3.0644\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.6048 - mae: 0.9499 - val_loss: 28.5893 - val_mae: 3.2404\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.5576 - mae: 0.9401 - val_loss: 28.8053 - val_mae: 3.2152\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.5707 - mae: 0.9056 - val_loss: 33.8182 - val_mae: 3.4328\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.6914 - mae: 0.9493 - val_loss: 37.6175 - val_mae: 3.3106\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.6516 - mae: 0.9155 - val_loss: 26.5085 - val_mae: 3.1254\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.5281 - mae: 0.9164 - val_loss: 32.3801 - val_mae: 3.1898\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.5159 - mae: 0.9186 - val_loss: 30.3004 - val_mae: 3.3105\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.6877 - mae: 0.9761 - val_loss: 26.4241 - val_mae: 3.0559\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.5542 - mae: 0.9361 - val_loss: 29.2629 - val_mae: 3.2803\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.5162 - mae: 0.8981 - val_loss: 34.4999 - val_mae: 3.4545\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.5138 - mae: 0.9278 - val_loss: 32.1641 - val_mae: 3.2426\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.6068 - mae: 0.9191 - val_loss: 37.0336 - val_mae: 3.3927\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 735us/step - loss: 1.5177 - mae: 0.9388 - val_loss: 34.3315 - val_mae: 3.2976\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.5619 - mae: 0.8991 - val_loss: 32.5276 - val_mae: 3.4025\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.5738 - mae: 0.9201 - val_loss: 42.9342 - val_mae: 3.7616\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.5757 - mae: 0.9073 - val_loss: 28.4854 - val_mae: 3.2402\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.5096 - mae: 0.8808 - val_loss: 33.3112 - val_mae: 3.3907\n",
      "Epoch 243/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.5094 - mae: 0.9000 - val_loss: 35.9696 - val_mae: 3.4220\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.5776 - mae: 0.9370 - val_loss: 40.8391 - val_mae: 3.4765\n",
      "Epoch 245/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.4417 - mae: 0.8774 - val_loss: 36.7851 - val_mae: 3.5208\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.5437 - mae: 0.9502 - val_loss: 31.4610 - val_mae: 3.2479\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.4838 - mae: 0.8610 - val_loss: 38.0469 - val_mae: 3.6896\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.3637 - mae: 0.8572 - val_loss: 21.1461 - val_mae: 3.0892\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.4733 - mae: 0.8814 - val_loss: 22.6983 - val_mae: 3.0703\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.5311 - mae: 0.9209 - val_loss: 34.1321 - val_mae: 3.2062\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.3224 - mae: 0.8545 - val_loss: 22.2042 - val_mae: 2.9817\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.4426 - mae: 0.8681 - val_loss: 30.9957 - val_mae: 3.1963\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.3424 - mae: 0.8559 - val_loss: 25.4928 - val_mae: 3.0677\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.3387 - mae: 0.8592 - val_loss: 41.9183 - val_mae: 3.6247\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.4313 - mae: 0.8996 - val_loss: 32.6526 - val_mae: 3.1855\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 1.2688 - mae: 0.8412 - val_loss: 29.8064 - val_mae: 3.4820\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.4328 - mae: 0.8687 - val_loss: 30.5340 - val_mae: 3.3022\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.3851 - mae: 0.8750 - val_loss: 27.5346 - val_mae: 3.0303\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.2398 - mae: 0.8447 - val_loss: 38.5991 - val_mae: 3.7609\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 0s 837us/step - loss: 1.4515 - mae: 0.8515 - val_loss: 33.9082 - val_mae: 3.3089\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.3824 - mae: 0.8792 - val_loss: 36.9875 - val_mae: 3.3538\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.3672 - mae: 0.8768 - val_loss: 40.4455 - val_mae: 3.4816\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.2178 - mae: 0.8273 - val_loss: 43.9459 - val_mae: 3.9200\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 0s 756us/step - loss: 1.3623 - mae: 0.8588 - val_loss: 35.7150 - val_mae: 3.3358\n",
      "Epoch 265/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 1.4575 - mae: 0.8713 - val_loss: 28.3943 - val_mae: 3.3183\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 1.3199 - mae: 0.8422 - val_loss: 31.5600 - val_mae: 3.2591\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.3634 - mae: 0.8798 - val_loss: 36.9442 - val_mae: 3.3134\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.3350 - mae: 0.8269 - val_loss: 36.2080 - val_mae: 3.4523\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 1.3458 - mae: 0.8366 - val_loss: 43.1216 - val_mae: 3.6975\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 1.2941 - mae: 0.8085 - val_loss: 38.4956 - val_mae: 3.4350\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.2730 - mae: 0.8408 - val_loss: 33.1829 - val_mae: 3.2930\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 1.3136 - mae: 0.8701 - val_loss: 32.0018 - val_mae: 3.2927\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.3007 - mae: 0.8341 - val_loss: 41.7735 - val_mae: 3.6552\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.2844 - mae: 0.8514 - val_loss: 37.2188 - val_mae: 3.6022\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 1.2377 - mae: 0.8232 - val_loss: 37.4525 - val_mae: 3.4023\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.3248 - mae: 0.8497 - val_loss: 31.4944 - val_mae: 3.2716\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.3216 - mae: 0.8644 - val_loss: 30.9141 - val_mae: 3.1709\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 1.3008 - mae: 0.8361 - val_loss: 37.2927 - val_mae: 3.6191\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 1.1758 - mae: 0.8095 - val_loss: 32.2757 - val_mae: 3.3139\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.4480 - mae: 0.8641 - val_loss: 36.6522 - val_mae: 3.2585\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 1.0486 - mae: 0.7742 - val_loss: 34.7239 - val_mae: 3.5259\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 1.2591 - mae: 0.8414 - val_loss: 33.9725 - val_mae: 3.4445\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.2167 - mae: 0.8231 - val_loss: 41.0786 - val_mae: 3.3785\n",
      "Epoch 284/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.4618 - mae: 0.8744 - val_loss: 37.3722 - val_mae: 3.3595\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.3287 - mae: 0.8302 - val_loss: 28.8843 - val_mae: 3.1139\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 1.2589 - mae: 0.8157 - val_loss: 36.8245 - val_mae: 3.4044\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.0961 - mae: 0.7771 - val_loss: 32.4380 - val_mae: 3.3937\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.3018 - mae: 0.8517 - val_loss: 29.9052 - val_mae: 3.0796\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.3717 - mae: 0.8369 - val_loss: 38.5761 - val_mae: 3.3722\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.3353 - mae: 0.8305 - val_loss: 34.9589 - val_mae: 3.4544\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.2059 - mae: 0.7998 - val_loss: 35.4194 - val_mae: 3.4283\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.1777 - mae: 0.7964 - val_loss: 35.4517 - val_mae: 3.4451\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.3617 - mae: 0.8443 - val_loss: 32.7259 - val_mae: 3.3573\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.1842 - mae: 0.8181 - val_loss: 38.7314 - val_mae: 3.6832\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.2793 - mae: 0.8497 - val_loss: 38.3690 - val_mae: 3.3352\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.1701 - mae: 0.7915 - val_loss: 33.2264 - val_mae: 3.3814\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 719us/step - loss: 1.1666 - mae: 0.7771 - val_loss: 32.3471 - val_mae: 3.2132\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 1.2585 - mae: 0.8209 - val_loss: 29.1085 - val_mae: 3.1338\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.2470 - mae: 0.8235 - val_loss: 29.8729 - val_mae: 3.2052\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 1.0852 - mae: 0.7712 - val_loss: 40.3340 - val_mae: 3.5187\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.0555 - mae: 0.7798 - val_loss: 34.5015 - val_mae: 3.3457\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 1.0661 - mae: 0.7702 - val_loss: 34.4909 - val_mae: 3.3223\n",
      "Epoch 303/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 1.2071 - mae: 0.7933 - val_loss: 34.6956 - val_mae: 3.3931\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.3068 - mae: 0.8010 - val_loss: 40.6123 - val_mae: 3.7368\n",
      "Epoch 305/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.1567 - mae: 0.7827 - val_loss: 44.4467 - val_mae: 3.8473\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 1.1584 - mae: 0.8148 - val_loss: 35.3293 - val_mae: 3.2801\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.2086 - mae: 0.7984 - val_loss: 35.3999 - val_mae: 3.3907\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 1.1294 - mae: 0.7616 - val_loss: 30.6173 - val_mae: 3.2936\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.2195 - mae: 0.8205 - val_loss: 33.5904 - val_mae: 3.3522\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.0618 - mae: 0.7793 - val_loss: 38.0234 - val_mae: 3.4822\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.3086 - mae: 0.8402 - val_loss: 37.0223 - val_mae: 3.6723\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.2271 - mae: 0.7889 - val_loss: 29.0498 - val_mae: 3.1160\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 1.1735 - mae: 0.7898 - val_loss: 34.7674 - val_mae: 3.2772\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.2834 - mae: 0.8592 - val_loss: 35.1013 - val_mae: 3.5356\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.0915 - mae: 0.7703 - val_loss: 39.1713 - val_mae: 3.5154\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.2283 - mae: 0.8317 - val_loss: 34.8892 - val_mae: 3.4982\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.1327 - mae: 0.7816 - val_loss: 38.6286 - val_mae: 3.5551\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.1431 - mae: 0.7810 - val_loss: 38.1441 - val_mae: 3.5902\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.1172 - mae: 0.7646 - val_loss: 29.7340 - val_mae: 3.3117\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.2425 - mae: 0.7885 - val_loss: 28.3656 - val_mae: 3.0793\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 1.1271 - mae: 0.7793 - val_loss: 35.8333 - val_mae: 3.4665\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 1.0438 - mae: 0.7689 - val_loss: 34.7407 - val_mae: 3.5816\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 1.1416 - mae: 0.7828 - val_loss: 33.8672 - val_mae: 3.4212\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.1681 - mae: 0.7907 - val_loss: 29.7059 - val_mae: 3.2675\n",
      "Epoch 325/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.1246 - mae: 0.7938 - val_loss: 30.3629 - val_mae: 3.2473\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.0748 - mae: 0.7639 - val_loss: 34.0226 - val_mae: 3.3549\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.1255 - mae: 0.8137 - val_loss: 33.3660 - val_mae: 3.2999\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.2626 - mae: 0.7931 - val_loss: 28.0551 - val_mae: 3.2574\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 1.1432 - mae: 0.7530 - val_loss: 30.6546 - val_mae: 3.2297\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.0316 - mae: 0.7580 - val_loss: 35.7994 - val_mae: 3.4497\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 1.2414 - mae: 0.7727 - val_loss: 35.0023 - val_mae: 3.2438\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.0721 - mae: 0.7582 - val_loss: 32.8750 - val_mae: 3.4662\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 0.9618 - mae: 0.7289 - val_loss: 31.0022 - val_mae: 3.2790\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.0149 - mae: 0.7591 - val_loss: 33.1828 - val_mae: 3.3778\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.0556 - mae: 0.7955 - val_loss: 30.9739 - val_mae: 3.2155\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.1068 - mae: 0.7784 - val_loss: 33.6822 - val_mae: 3.3138\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 0.9983 - mae: 0.7222 - val_loss: 34.2579 - val_mae: 3.2406\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.1211 - mae: 0.7921 - val_loss: 26.4723 - val_mae: 3.1604\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.0496 - mae: 0.7303 - val_loss: 21.6099 - val_mae: 2.9259\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.1025 - mae: 0.7608 - val_loss: 30.0048 - val_mae: 3.2933\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.9907 - mae: 0.7610 - val_loss: 27.4560 - val_mae: 3.1055\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.0137 - mae: 0.7480 - val_loss: 35.4531 - val_mae: 3.2455\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 1.1317 - mae: 0.7855 - val_loss: 34.1151 - val_mae: 3.4649\n",
      "Epoch 344/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 1.1124 - mae: 0.7923 - val_loss: 33.5645 - val_mae: 3.2301\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.9732 - mae: 0.7399 - val_loss: 29.1441 - val_mae: 3.2404\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.9797 - mae: 0.7089 - val_loss: 32.1006 - val_mae: 3.3772\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.1398 - mae: 0.7795 - val_loss: 35.5774 - val_mae: 3.2098\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.0720 - mae: 0.7721 - val_loss: 31.2247 - val_mae: 3.2464\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.9965 - mae: 0.7387 - val_loss: 34.7230 - val_mae: 3.5990\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.0286 - mae: 0.7412 - val_loss: 27.9067 - val_mae: 3.1746\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.9704 - mae: 0.7120 - val_loss: 30.1358 - val_mae: 3.3680\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.0525 - mae: 0.7391 - val_loss: 29.2455 - val_mae: 3.1810\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 0.8944 - mae: 0.6545 - val_loss: 32.1323 - val_mae: 3.2695\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.1611 - mae: 0.7898 - val_loss: 27.1913 - val_mae: 3.1521\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.0261 - mae: 0.7457 - val_loss: 27.2609 - val_mae: 3.2906\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 713us/step - loss: 1.0130 - mae: 0.7180 - val_loss: 31.5244 - val_mae: 3.2472\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.9707 - mae: 0.7051 - val_loss: 29.4334 - val_mae: 3.1907\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.9597 - mae: 0.7275 - val_loss: 36.8312 - val_mae: 3.4859\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.0150 - mae: 0.7401 - val_loss: 31.8830 - val_mae: 3.3580\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.0165 - mae: 0.7341 - val_loss: 29.4672 - val_mae: 3.1468\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.0106 - mae: 0.7359 - val_loss: 34.4685 - val_mae: 3.2990\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.9901 - mae: 0.7294 - val_loss: 36.7599 - val_mae: 3.4386\n",
      "Epoch 363/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 0.9491 - mae: 0.7611 - val_loss: 29.7988 - val_mae: 3.2626\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.9149 - mae: 0.7247 - val_loss: 33.7493 - val_mae: 3.3774\n",
      "Epoch 365/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.1293 - mae: 0.7499 - val_loss: 26.1991 - val_mae: 3.0620\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 0s 701us/step - loss: 1.0028 - mae: 0.7474 - val_loss: 35.3041 - val_mae: 3.3909\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.9949 - mae: 0.7319 - val_loss: 30.2883 - val_mae: 3.2959\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.9472 - mae: 0.7293 - val_loss: 27.9149 - val_mae: 3.2278\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.8794 - mae: 0.6855 - val_loss: 31.2239 - val_mae: 3.1953\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.0877 - mae: 0.7412 - val_loss: 31.0537 - val_mae: 3.2523\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.0393 - mae: 0.7300 - val_loss: 25.5904 - val_mae: 3.2369\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.0316 - mae: 0.7222 - val_loss: 32.9127 - val_mae: 3.3962\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.9627 - mae: 0.7415 - val_loss: 31.1228 - val_mae: 3.2689\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 0.8818 - mae: 0.7141 - val_loss: 31.0359 - val_mae: 3.2925\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.0025 - mae: 0.7376 - val_loss: 27.4963 - val_mae: 3.2497\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 0.9632 - mae: 0.7554 - val_loss: 38.9477 - val_mae: 3.4837\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.9483 - mae: 0.6926 - val_loss: 33.2073 - val_mae: 3.4035\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.9608 - mae: 0.7341 - val_loss: 34.4408 - val_mae: 3.4207\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.0346 - mae: 0.7543 - val_loss: 34.6526 - val_mae: 3.4140\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.9889 - mae: 0.7343 - val_loss: 29.4314 - val_mae: 3.2432\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 1.0039 - mae: 0.7247 - val_loss: 33.2445 - val_mae: 3.3097\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.8897 - mae: 0.7196 - val_loss: 22.3724 - val_mae: 3.0270\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.9511 - mae: 0.7163 - val_loss: 32.4038 - val_mae: 3.2184\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.9956 - mae: 0.7300 - val_loss: 28.8133 - val_mae: 3.3752\n",
      "Epoch 385/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.9938 - mae: 0.7623 - val_loss: 24.7082 - val_mae: 3.0899\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.0034 - mae: 0.7337 - val_loss: 26.3724 - val_mae: 3.2068\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 0.9609 - mae: 0.7300 - val_loss: 35.0581 - val_mae: 3.4237\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 0.8721 - mae: 0.6989 - val_loss: 29.9873 - val_mae: 3.3456\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.9605 - mae: 0.7398 - val_loss: 32.7614 - val_mae: 3.4196\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.0125 - mae: 0.7317 - val_loss: 24.7012 - val_mae: 3.0159\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 0.9066 - mae: 0.7067 - val_loss: 30.6205 - val_mae: 3.1762\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 0s 748us/step - loss: 1.0062 - mae: 0.7196 - val_loss: 30.1495 - val_mae: 3.2441\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 0.8681 - mae: 0.7007 - val_loss: 31.6986 - val_mae: 3.4469\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.9740 - mae: 0.7236 - val_loss: 38.2451 - val_mae: 3.3889\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 0.8220 - mae: 0.6673 - val_loss: 32.7863 - val_mae: 3.3321\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.9451 - mae: 0.7148 - val_loss: 33.9362 - val_mae: 3.3240\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 0.9866 - mae: 0.7250 - val_loss: 31.8246 - val_mae: 3.2854\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.8261 - mae: 0.6617 - val_loss: 25.4021 - val_mae: 2.9719\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 0.9864 - mae: 0.7343 - val_loss: 35.2711 - val_mae: 3.3469\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.9640 - mae: 0.7484 - val_loss: 29.6478 - val_mae: 3.2444\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.7847 - mae: 0.6573 - val_loss: 27.7938 - val_mae: 3.2920\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 0.8222 - mae: 0.6706 - val_loss: 30.3920 - val_mae: 3.2244\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.9468 - mae: 0.7173 - val_loss: 26.3713 - val_mae: 3.0903\n",
      "Epoch 404/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.9053 - mae: 0.7224 - val_loss: 31.2489 - val_mae: 3.2824\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 0.8179 - mae: 0.6779 - val_loss: 36.1091 - val_mae: 3.3442\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.8931 - mae: 0.6991 - val_loss: 27.6199 - val_mae: 3.1728\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.8268 - mae: 0.6896 - val_loss: 34.4776 - val_mae: 3.3872\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 0.8991 - mae: 0.6620 - val_loss: 25.3969 - val_mae: 2.9785\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.8230 - mae: 0.6560 - val_loss: 27.1181 - val_mae: 3.0910\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 0.9252 - mae: 0.6857 - val_loss: 29.2938 - val_mae: 3.2442\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 0.8655 - mae: 0.6932 - val_loss: 32.2383 - val_mae: 3.1582\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.9254 - mae: 0.6785 - val_loss: 23.2767 - val_mae: 2.9438\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.8738 - mae: 0.6966 - val_loss: 29.3403 - val_mae: 3.2673\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.9857 - mae: 0.7530 - val_loss: 27.1125 - val_mae: 3.1796\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 711us/step - loss: 0.7618 - mae: 0.6599 - val_loss: 29.2943 - val_mae: 3.3238\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 0.9234 - mae: 0.6855 - val_loss: 20.3373 - val_mae: 2.8834\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 0.9395 - mae: 0.7196 - val_loss: 22.7544 - val_mae: 3.0242\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.8667 - mae: 0.6784 - val_loss: 21.2774 - val_mae: 2.9562\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.8375 - mae: 0.6629 - val_loss: 25.0380 - val_mae: 3.0608\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.8495 - mae: 0.7035 - val_loss: 27.4743 - val_mae: 3.1752\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 0.8806 - mae: 0.6809 - val_loss: 26.7673 - val_mae: 3.1630\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 0.8416 - mae: 0.7039 - val_loss: 29.8981 - val_mae: 3.2133\n",
      "Epoch 423/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 0.8140 - mae: 0.6747 - val_loss: 36.1520 - val_mae: 3.4324\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.8013 - mae: 0.6607 - val_loss: 31.6624 - val_mae: 3.2586\n",
      "Epoch 425/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.8932 - mae: 0.7027 - val_loss: 25.2667 - val_mae: 3.0896\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 0.8714 - mae: 0.6860 - val_loss: 31.5826 - val_mae: 3.2685\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.8218 - mae: 0.6724 - val_loss: 34.2257 - val_mae: 3.4066\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.7782 - mae: 0.6600 - val_loss: 24.6701 - val_mae: 3.0535\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.8354 - mae: 0.6891 - val_loss: 22.9187 - val_mae: 3.0084\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.8495 - mae: 0.6629 - val_loss: 21.8603 - val_mae: 3.0131\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 0.7915 - mae: 0.6669 - val_loss: 25.3513 - val_mae: 3.0818\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.8399 - mae: 0.6772 - val_loss: 24.0091 - val_mae: 3.0376\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.9697 - mae: 0.7107 - val_loss: 28.2730 - val_mae: 3.3215\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.8078 - mae: 0.6774 - val_loss: 27.8620 - val_mae: 3.1588\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.8507 - mae: 0.6844 - val_loss: 27.0358 - val_mae: 3.0158\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 0.8048 - mae: 0.6640 - val_loss: 18.1039 - val_mae: 2.7578\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.8227 - mae: 0.6662 - val_loss: 23.3536 - val_mae: 3.0562\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.7479 - mae: 0.6467 - val_loss: 22.6080 - val_mae: 3.1090\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 0.8549 - mae: 0.6854 - val_loss: 27.2359 - val_mae: 3.1172\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.9435 - mae: 0.6825 - val_loss: 27.9686 - val_mae: 3.1697\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.7795 - mae: 0.6153 - val_loss: 30.1414 - val_mae: 3.3600\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.8165 - mae: 0.6463 - val_loss: 19.8581 - val_mae: 2.9028\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 0.9891 - mae: 0.7228 - val_loss: 26.7229 - val_mae: 3.1095\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 0.8276 - mae: 0.6733 - val_loss: 27.4026 - val_mae: 3.2096\n",
      "Epoch 445/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.8643 - mae: 0.6436 - val_loss: 25.8397 - val_mae: 3.1170\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.7893 - mae: 0.6490 - val_loss: 25.3919 - val_mae: 3.1084\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.7829 - mae: 0.6580 - val_loss: 26.5634 - val_mae: 3.1385\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 0.7732 - mae: 0.6526 - val_loss: 17.4792 - val_mae: 2.7893\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 0.7720 - mae: 0.6431 - val_loss: 21.2757 - val_mae: 2.9340\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.7936 - mae: 0.6723 - val_loss: 19.9198 - val_mae: 2.8215\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.8057 - mae: 0.6708 - val_loss: 20.1226 - val_mae: 2.7909\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.8168 - mae: 0.6654 - val_loss: 25.2671 - val_mae: 3.1009\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 0.7715 - mae: 0.6572 - val_loss: 20.4930 - val_mae: 2.8655\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.7672 - mae: 0.6248 - val_loss: 20.3760 - val_mae: 2.9169\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.8496 - mae: 0.6609 - val_loss: 23.4195 - val_mae: 3.0545\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.7534 - mae: 0.6626 - val_loss: 26.0510 - val_mae: 3.0715\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 0.7265 - mae: 0.6517 - val_loss: 23.2786 - val_mae: 2.9793\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.7580 - mae: 0.6473 - val_loss: 27.9382 - val_mae: 3.1293\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.8234 - mae: 0.6636 - val_loss: 21.4575 - val_mae: 3.0201\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.7507 - mae: 0.6474 - val_loss: 24.3479 - val_mae: 3.0717\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 0s 842us/step - loss: 0.7875 - mae: 0.6280 - val_loss: 28.3297 - val_mae: 3.1768\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 0.9019 - mae: 0.6893 - val_loss: 28.8076 - val_mae: 3.1570\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 0.9210 - mae: 0.6815 - val_loss: 23.9240 - val_mae: 2.9624\n",
      "Epoch 464/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 0.8585 - mae: 0.6952 - val_loss: 30.5070 - val_mae: 3.2288\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.8174 - mae: 0.6601 - val_loss: 25.7519 - val_mae: 3.1675\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 0s 758us/step - loss: 0.7971 - mae: 0.6532 - val_loss: 29.1286 - val_mae: 3.4657\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 0.7681 - mae: 0.6505 - val_loss: 24.7647 - val_mae: 3.2860\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 0.7663 - mae: 0.6485 - val_loss: 20.6359 - val_mae: 2.9174\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 0.8156 - mae: 0.6645 - val_loss: 19.5856 - val_mae: 2.8315\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.7990 - mae: 0.6634 - val_loss: 24.9232 - val_mae: 3.0907\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 0.8031 - mae: 0.6630 - val_loss: 24.0795 - val_mae: 2.9980\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 0s 750us/step - loss: 0.8105 - mae: 0.6668 - val_loss: 21.6384 - val_mae: 2.9429\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 0s 747us/step - loss: 0.7749 - mae: 0.6394 - val_loss: 20.8915 - val_mae: 2.9022\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 732us/step - loss: 0.8020 - mae: 0.6521 - val_loss: 24.8818 - val_mae: 3.1016\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 0.7980 - mae: 0.6513 - val_loss: 19.8471 - val_mae: 2.9037\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 0.7124 - mae: 0.5982 - val_loss: 24.6735 - val_mae: 3.0716\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 0.8302 - mae: 0.6607 - val_loss: 24.4531 - val_mae: 3.0854\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 0.7857 - mae: 0.6531 - val_loss: 22.0683 - val_mae: 2.8905\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 0s 753us/step - loss: 0.7289 - mae: 0.6413 - val_loss: 23.2443 - val_mae: 2.8987\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 0.7544 - mae: 0.6448 - val_loss: 28.9767 - val_mae: 3.2746\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.8577 - mae: 0.7007 - val_loss: 22.0414 - val_mae: 2.9652\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 0.7422 - mae: 0.6386 - val_loss: 26.4043 - val_mae: 3.0924\n",
      "Epoch 483/500\n",
      "303/303 [==============================] - 0s 758us/step - loss: 0.7465 - mae: 0.6316 - val_loss: 26.1435 - val_mae: 3.0337\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 0.7422 - mae: 0.6358 - val_loss: 24.5094 - val_mae: 3.1157\n",
      "Epoch 485/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 0.7416 - mae: 0.6489 - val_loss: 24.6809 - val_mae: 3.0276\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 0.7572 - mae: 0.6563 - val_loss: 19.2110 - val_mae: 2.9015\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 0.7195 - mae: 0.6217 - val_loss: 21.8654 - val_mae: 2.8947\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.8025 - mae: 0.6704 - val_loss: 18.1462 - val_mae: 2.7879\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.7260 - mae: 0.6174 - val_loss: 24.5947 - val_mae: 3.2310\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.7423 - mae: 0.6355 - val_loss: 23.0748 - val_mae: 3.0194\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 0s 759us/step - loss: 0.7158 - mae: 0.6452 - val_loss: 23.5291 - val_mae: 3.0694\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.8061 - mae: 0.6697 - val_loss: 22.5035 - val_mae: 3.0083\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.7771 - mae: 0.6582 - val_loss: 26.1156 - val_mae: 3.1282\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 0.7338 - mae: 0.6294 - val_loss: 23.8742 - val_mae: 2.9541\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 0.8338 - mae: 0.6558 - val_loss: 25.6363 - val_mae: 3.0817\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 0s 751us/step - loss: 0.7569 - mae: 0.6302 - val_loss: 20.0009 - val_mae: 2.8637\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 0.7660 - mae: 0.6246 - val_loss: 23.6576 - val_mae: 2.9655\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 0.6757 - mae: 0.6150 - val_loss: 25.6453 - val_mae: 2.9890\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 0.6786 - mae: 0.6142 - val_loss: 27.0286 - val_mae: 3.2922\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 0.7486 - mae: 0.6236 - val_loss: 26.0754 - val_mae: 3.1397\n",
      "{'val_loss': [23.30668069356776, 19.4114972274188, 15.821659102542602, 14.775328675215825, 14.324985993721771, 14.474084677253066, 12.57586570565432, 12.66273593286163, 12.957171575910882, 14.211055739241015, 11.462888566710257, 12.271922934855713, 12.76728905640727, 11.206280336326845, 12.467912481931767, 10.913082473270485, 10.730003850535134, 10.690198328385204, 11.143433358354292, 11.019842703323892, 13.462466146632115, 10.545794345009991, 9.703529471707286, 13.785694989780918, 10.174995549502643, 10.179396767177918, 11.03194738866411, 9.50224467470094, 11.096614867453416, 10.47818361175832, 10.603533497585058, 10.790511168711266, 10.910682894900386, 13.121699906924814, 11.146917643299842, 10.181082312576414, 10.274218170141737, 9.2949311917655, 10.863555738074666, 10.37082960512397, 10.789243180654335, 11.84728705446195, 13.247532818217458, 8.558480660286433, 12.303891232632571, 9.587049222082744, 10.120992840627913, 11.505305873223616, 9.0977808769941, 9.614387243829373, 9.841265216922746, 11.259058076337368, 9.333982960655272, 10.251258765743806, 9.821055682867046, 10.940628760115654, 8.92284081329216, 9.15578567299138, 10.387880727747033, 9.782845478251318, 12.139314578510394, 11.395285010961112, 9.387466272426968, 9.761642854642451, 10.217350726561058, 9.998340954967212, 10.14049998949291, 13.531296156457161, 12.225645084420044, 10.510864033379896, 10.432619013915923, 11.37374033661799, 9.994347218161282, 11.438424149312029, 14.924739945635526, 12.133277628797863, 11.1153680682482, 11.832682166973562, 10.32831903501073, 15.295658255664177, 12.037299964835148, 13.880113550686591, 10.118218785875689, 12.101981303781436, 10.997547652766034, 12.079366915949187, 12.015623398583918, 12.008245851069983, 13.09613085203426, 10.927330585062801, 14.89382211189535, 13.868511297908038, 13.24710171449224, 11.156190790005471, 12.229651401845258, 13.83259613741429, 15.391750661750775, 13.46392451832705, 13.5402266324122, 16.465002311841413, 15.664568548437696, 13.14897129929735, 16.15114014241199, 20.209247061537837, 13.020043308606366, 14.393770690278915, 14.506453555188543, 13.237332392152858, 11.687254346257202, 15.928973259307481, 17.39837313088759, 14.046533902216066, 16.26267620560478, 14.333182901955476, 12.624085352463316, 13.250075694927716, 22.836706162458007, 14.795317586498694, 14.000439705840973, 19.12947804544416, 13.277597449558538, 15.669992142362695, 24.554099019695798, 17.714418748759037, 15.038478822919936, 15.581686090359563, 15.636639078736701, 21.337939436135393, 16.76211059040051, 13.518447350563093, 19.92038755425388, 18.467024153686015, 22.071149508155294, 15.24060467722374, 13.688556671142686, 15.325291234329066, 20.606373405342204, 19.356006301347794, 16.48805711434066, 20.910241937077497, 17.629635488040577, 14.26183648069509, 21.413475485938996, 25.104910651388426, 17.11077351815132, 19.16461903057384, 24.552869010386342, 15.344924527250397, 20.25361673429719, 17.885924769529876, 23.914791626970743, 22.18644320933725, 23.31647490394892, 18.191082228851126, 24.104922352546577, 19.090272392549707, 16.98714386085786, 20.35813616605958, 19.7527876075099, 23.175169508042053, 20.873745038044998, 24.50150279841953, 18.97399258283935, 19.27846780222625, 22.24621565056167, 26.694391748102586, 22.72263133286102, 22.890721869035993, 19.42459429184201, 19.938996735840373, 20.481742620966074, 20.329883020989296, 23.27782593027122, 24.705602256235398, 21.05171346858985, 20.33440194474931, 18.333836895648833, 21.696668438996088, 29.390616400181177, 32.053502740424925, 20.353108621608712, 20.201686215578352, 22.617842275630867, 20.95827247121943, 18.91270958720983, 20.507866039603606, 17.91585367803674, 22.179137032481353, 19.45711499691876, 24.337802142967877, 20.679298439518565, 23.557257807604024, 17.778894441229944, 28.161914503879586, 20.99261137512155, 19.206877906728675, 23.38775188664878, 26.45173506962486, 29.001256775816945, 29.418604040816646, 27.468497451049764, 23.373034539849193, 32.96567167930716, 29.36228059085275, 24.379351015538152, 23.469124252677982, 26.19220042823685, 25.182189513998345, 30.432999543299093, 31.397425271903792, 31.204649400362506, 39.508193720429205, 24.03811409786611, 33.62658171506949, 22.374102710864662, 33.858422220252386, 26.30171048980999, 32.62948439160989, 27.626716382766954, 29.757900167302697, 23.67868878758088, 27.16190398009586, 29.65159501264818, 32.78346550423222, 24.56534688680267, 28.58934089206136, 28.805300810807708, 33.81815214555867, 37.61747591843192, 26.508536727580307, 32.38006722586838, 30.300387196110112, 26.424056880367477, 29.26289941734487, 34.499906978031106, 32.1641026477417, 37.03362345873461, 34.33145697959621, 32.5275830621762, 42.93417836234693, 28.485428248723597, 33.311234348204906, 35.969589448329934, 40.83908173600849, 36.78506339174502, 31.46103773277978, 38.0468550746094, 21.146138057346676, 22.698331533115713, 34.13212958723307, 22.20416198051212, 30.99570303255955, 25.492809686126883, 41.918318571840956, 32.652625353113315, 29.80642481736774, 30.534005363372103, 27.534583946699183, 38.599116454726214, 33.90822801472321, 36.9874887596992, 40.44551743375251, 43.94588502532187, 35.71501866359227, 28.394345009871206, 31.559958796938975, 36.94419034816195, 36.20800838125469, 43.121636989691275, 38.49561439358055, 33.18292445379959, 32.001816981453054, 41.77353486719733, 37.218843224340254, 37.45246474026232, 31.494382769556832, 30.914069332922683, 37.292696684271576, 32.275683002073855, 36.65221654468661, 34.72392252616778, 33.97247281659966, 41.07856413339135, 37.37223157844087, 28.884254001837114, 36.82450747239838, 32.438015688239, 29.905175433558696, 38.5761328672303, 34.95894641965388, 35.41938590057342, 35.45172664723682, 32.72585291915232, 38.73142775713405, 38.369043283963165, 33.22636672945251, 32.3470830299072, 29.108531395342236, 29.872896871132294, 40.334034086719136, 34.501536378462085, 34.490855172626894, 34.695599536978555, 40.61227447746234, 44.446746126066266, 35.32931484636507, 35.39990598100755, 30.617288097780715, 33.590411755765814, 38.023368864853595, 37.022308066800825, 29.04980002496032, 34.76740577158496, 35.1012714506671, 39.17134156197282, 34.88924818094024, 38.62864792067298, 38.14406912935518, 29.733970089561403, 28.365606439405923, 35.83328850636325, 34.74070948349441, 33.86719243554917, 29.70585576016433, 30.36286083676986, 34.022629213058345, 33.36595743081889, 28.05505903475194, 30.654597132773475, 35.79937927843113, 35.002341527661386, 32.87498819232817, 31.002204196456137, 33.18279646083815, 30.973911284927812, 33.68222222625656, 34.25785168568757, 26.472293286994077, 21.609946270391465, 30.004811560347825, 27.45603219648975, 35.45310795380927, 34.11511538464848, 33.56447438450327, 29.144057121074823, 32.10060600272572, 35.577412179871786, 31.224680132793935, 34.72297622846502, 27.906698352673395, 30.135796771217645, 29.245518305534866, 32.132280905098014, 27.191267862863548, 27.260909574355303, 31.524388793718202, 29.43339349799455, 36.831181707152275, 31.882975673214833, 29.467199320304392, 34.46852226706111, 36.759899029584304, 29.798759277402837, 33.74925416794843, 26.199142032851565, 35.30414289714294, 30.288260641775214, 27.914878172984366, 31.22391662316853, 31.05370324271064, 25.59038609672672, 32.91271966316013, 31.122841096968425, 31.035940842062125, 27.496260105189638, 38.947688647485876, 33.20725709176871, 34.44079513262005, 34.65258026582599, 29.431391621109945, 33.24450700282837, 22.372444325555485, 32.403776329036084, 28.81331117091629, 24.708248703830442, 26.372361003255016, 35.05813963368355, 29.987264154929008, 32.76144868168187, 24.70119034205788, 30.620545447933704, 30.1495187629088, 31.698596155731984, 38.24514185147139, 32.786311151655326, 33.93624959074625, 31.824556886287645, 25.402119297972227, 35.27108378302004, 29.64783351084835, 27.793766280610832, 30.391989813599015, 26.37130885024219, 31.248900788108873, 36.109068975932, 27.619890897011494, 34.47760772352504, 25.39686915664464, 27.11813688789273, 29.29375426318395, 32.23829376968382, 23.276735254468875, 29.34027462093722, 27.11249403141688, 29.294264942803572, 20.337288536068563, 22.754373488293634, 21.277439525756797, 25.037952029874713, 27.474272827458762, 26.76732051939307, 29.898066239602088, 36.151973367096986, 31.66236106556409, 25.266667324212833, 31.582615212273396, 34.22570472996968, 24.670142720862625, 22.918739627347684, 21.860345670119468, 25.351255796344876, 24.009107403847906, 28.272998633930495, 27.86198827842888, 27.035821152317645, 18.103870865736457, 23.353619897682773, 22.60800660762355, 27.235926612130466, 27.968598846839463, 30.14136586076203, 19.858067952326987, 26.722892600063254, 27.402552733940677, 25.83971839158457, 25.39185563809962, 26.56335584826002, 17.479223165503186, 21.27568351342574, 19.919803449851784, 20.12255633848784, 25.26711572431398, 20.493029002380894, 20.376027182051175, 23.419527610588133, 26.05102892458038, 23.27857142028521, 27.938180947616363, 21.457506478026435, 24.347934487520714, 28.32966662941519, 28.807587163476736, 23.92398000148063, 30.506979550166392, 25.75186463961802, 29.128596983431024, 24.76466374221433, 20.635919069147455, 19.585576560362103, 24.92324435311756, 24.07950774169534, 21.63841115137433, 20.891475900050395, 24.881788969143653, 19.847085240380586, 24.673533154688982, 24.4531146679732, 22.06831918402326, 23.244342572738113, 28.976744857056545, 22.04141589757954, 26.40428120586422, 26.143498394537048, 24.509370907106078, 24.680871204095016, 19.21100458773464, 21.86539674869054, 18.146208716626163, 24.594654811586548, 23.074828761849624, 23.52908949926265, 22.503479533541793, 26.115632246686424, 23.87419289338868, 25.63628009001112, 20.000915981899514, 23.65756241268695, 25.64534816770448, 27.028625635180095, 26.07541687926335], 'val_mae': [3.691866636276245, 3.372844934463501, 3.013678550720215, 2.909219980239868, 2.831394672393799, 2.908968448638916, 2.6611950397491455, 2.7041919231414795, 2.741262197494507, 2.8974814414978027, 2.591783046722412, 2.6528632640838623, 2.755450963973999, 2.512105703353882, 2.698026418685913, 2.517106294631958, 2.472428321838379, 2.5014255046844482, 2.5458133220672607, 2.5186872482299805, 2.834573268890381, 2.477550506591797, 2.359058141708374, 2.9293487071990967, 2.4165313243865967, 2.436943769454956, 2.5663719177246094, 2.334728956222534, 2.587395191192627, 2.477738857269287, 2.5018906593322754, 2.5588431358337402, 2.584043264389038, 2.8718080520629883, 2.5903050899505615, 2.436493396759033, 2.5292766094207764, 2.341033935546875, 2.612137794494629, 2.4905407428741455, 2.527547597885132, 2.6767146587371826, 2.8724851608276367, 2.2259268760681152, 2.7625527381896973, 2.343538999557495, 2.465198040008545, 2.6254992485046387, 2.2981507778167725, 2.3818001747131348, 2.406812906265259, 2.673755645751953, 2.386284351348877, 2.457443952560425, 2.3744499683380127, 2.5654497146606445, 2.320349931716919, 2.27425217628479, 2.506129741668701, 2.3933117389678955, 2.606123924255371, 2.570075035095215, 2.296989917755127, 2.410478353500366, 2.4088339805603027, 2.378726005554199, 2.4250659942626953, 2.710132360458374, 2.6428616046905518, 2.4875919818878174, 2.4041881561279297, 2.542055606842041, 2.3783109188079834, 2.5702810287475586, 2.980088710784912, 2.6370487213134766, 2.5855636596679688, 2.6062679290771484, 2.4303271770477295, 2.8807759284973145, 2.551495313644409, 2.764319896697998, 2.3647336959838867, 2.640432596206665, 2.460245132446289, 2.592968702316284, 2.611522674560547, 2.5940911769866943, 2.710331916809082, 2.449816942214966, 2.8278138637542725, 2.6939353942871094, 2.705296039581299, 2.454040765762329, 2.554081916809082, 2.7205588817596436, 2.826070547103882, 2.658143997192383, 2.5862627029418945, 2.9515604972839355, 2.8779027462005615, 2.594087839126587, 3.013338565826416, 3.1440792083740234, 2.6004323959350586, 2.7364604473114014, 2.710738182067871, 2.6052346229553223, 2.463008165359497, 2.859724998474121, 2.9032888412475586, 2.735058069229126, 2.856250524520874, 2.6282122135162354, 2.560917615890503, 2.553865432739258, 3.2291407585144043, 2.671445608139038, 2.700428009033203, 2.836918354034424, 2.669044017791748, 2.7491536140441895, 3.1865763664245605, 2.876518726348877, 2.748725414276123, 2.7186439037323, 2.678039789199829, 3.1070713996887207, 2.79392409324646, 2.650646209716797, 3.050922155380249, 2.9044888019561768, 3.1830263137817383, 2.6496100425720215, 2.5757291316986084, 2.6819279193878174, 2.9034454822540283, 2.9356513023376465, 2.7946066856384277, 3.0823187828063965, 2.7260653972625732, 2.5734894275665283, 3.2061350345611572, 3.3620901107788086, 2.741797685623169, 2.9524216651916504, 3.2309110164642334, 2.6261775493621826, 3.0099337100982666, 2.837759494781494, 3.1669349670410156, 3.0008976459503174, 3.037917375564575, 2.8335931301116943, 3.1845691204071045, 2.9032907485961914, 2.79718017578125, 2.91227650642395, 2.931839942932129, 2.9516215324401855, 2.9858624935150146, 3.3092048168182373, 2.8812665939331055, 3.1420347690582275, 3.1093640327453613, 3.331209421157837, 3.069434404373169, 3.071551561355591, 2.9489755630493164, 3.0946760177612305, 3.130570888519287, 2.8749122619628906, 3.048276662826538, 3.0556933879852295, 2.825915575027466, 2.9196784496307373, 2.7626490592956543, 3.1307833194732666, 3.4321885108947754, 3.5338499546051025, 2.7779464721679688, 2.9896421432495117, 3.0759499073028564, 3.0218396186828613, 2.9011542797088623, 2.8756356239318848, 2.9123306274414062, 3.0832104682922363, 3.081800699234009, 3.046835422515869, 2.9587013721466064, 3.0656070709228516, 3.0402629375457764, 3.115309715270996, 2.9460761547088623, 2.932746171951294, 3.0031723976135254, 3.188356399536133, 3.2776644229888916, 3.3024892807006836, 3.3798704147338867, 3.098991870880127, 3.2329883575439453, 3.36244797706604, 2.995962619781494, 3.0029327869415283, 3.3590171337127686, 3.2088558673858643, 3.324589729309082, 3.213580369949341, 3.427443027496338, 3.52939772605896, 3.158968210220337, 3.2705612182617188, 3.1181187629699707, 3.49666428565979, 3.4083187580108643, 3.3876984119415283, 3.259692907333374, 3.305424451828003, 3.1244311332702637, 3.203843593597412, 3.3635544776916504, 3.18011212348938, 3.0643770694732666, 3.2403554916381836, 3.215228796005249, 3.432760715484619, 3.310563802719116, 3.125438928604126, 3.1897568702697754, 3.3104567527770996, 3.0559051036834717, 3.2802720069885254, 3.454531192779541, 3.2425692081451416, 3.3927078247070312, 3.29756236076355, 3.402487277984619, 3.7615935802459717, 3.2402448654174805, 3.390695333480835, 3.4219977855682373, 3.476457357406616, 3.5208168029785156, 3.247931957244873, 3.689570665359497, 3.0892021656036377, 3.0702574253082275, 3.2062363624572754, 2.9816646575927734, 3.1963307857513428, 3.0676891803741455, 3.6247305870056152, 3.1855037212371826, 3.4819602966308594, 3.302237033843994, 3.0302822589874268, 3.760881185531616, 3.3088557720184326, 3.353807210922241, 3.481585741043091, 3.9199535846710205, 3.3358147144317627, 3.318265199661255, 3.259108781814575, 3.3134264945983887, 3.4523375034332275, 3.697507381439209, 3.4350385665893555, 3.292992115020752, 3.2927346229553223, 3.6551811695098877, 3.602166175842285, 3.402254581451416, 3.2715535163879395, 3.1709253787994385, 3.6190712451934814, 3.313915252685547, 3.2584609985351562, 3.525890350341797, 3.4445486068725586, 3.378450870513916, 3.3595242500305176, 3.113931179046631, 3.404378652572632, 3.393707036972046, 3.0796430110931396, 3.3722383975982666, 3.4544317722320557, 3.4283008575439453, 3.445075035095215, 3.3573288917541504, 3.68316650390625, 3.3352103233337402, 3.381350040435791, 3.213179588317871, 3.133760690689087, 3.205197811126709, 3.5187275409698486, 3.345735549926758, 3.322279214859009, 3.3931379318237305, 3.736849069595337, 3.847332000732422, 3.2800517082214355, 3.3907229900360107, 3.293607234954834, 3.3521556854248047, 3.482187509536743, 3.6723179817199707, 3.116010904312134, 3.277158737182617, 3.535576820373535, 3.515434741973877, 3.4981565475463867, 3.5551319122314453, 3.590151309967041, 3.3116893768310547, 3.079322099685669, 3.4664928913116455, 3.5815725326538086, 3.4212067127227783, 3.267474889755249, 3.24725079536438, 3.3548641204833984, 3.29988956451416, 3.2573814392089844, 3.2297472953796387, 3.449655771255493, 3.243845224380493, 3.4661850929260254, 3.2790169715881348, 3.3778159618377686, 3.215519905090332, 3.313779830932617, 3.240602970123291, 3.1603825092315674, 2.9258852005004883, 3.2932751178741455, 3.10548996925354, 3.245548725128174, 3.464904546737671, 3.23009991645813, 3.240402936935425, 3.3772082328796387, 3.209782361984253, 3.246412515640259, 3.599010467529297, 3.1745941638946533, 3.3679585456848145, 3.181049108505249, 3.2694814205169678, 3.1521291732788086, 3.290595054626465, 3.247161626815796, 3.190708637237549, 3.4859321117401123, 3.3579940795898438, 3.1468112468719482, 3.2990033626556396, 3.438566207885742, 3.2625627517700195, 3.3774466514587402, 3.061988115310669, 3.3909168243408203, 3.2959489822387695, 3.2278473377227783, 3.195338726043701, 3.2523465156555176, 3.236881732940674, 3.3962290287017822, 3.2689385414123535, 3.2925474643707275, 3.249681234359741, 3.48372483253479, 3.4035160541534424, 3.420736789703369, 3.413982391357422, 3.24316668510437, 3.3097238540649414, 3.027012348175049, 3.2183871269226074, 3.3752431869506836, 3.089940071105957, 3.206794023513794, 3.423712968826294, 3.3455891609191895, 3.4195611476898193, 3.0159435272216797, 3.1762263774871826, 3.244149923324585, 3.4469008445739746, 3.3888816833496094, 3.332063674926758, 3.3240370750427246, 3.2854297161102295, 2.971881151199341, 3.346867322921753, 3.2443599700927734, 3.2920033931732178, 3.2244207859039307, 3.0902650356292725, 3.282411575317383, 3.3441994190216064, 3.1727566719055176, 3.3871898651123047, 2.9784717559814453, 3.0909647941589355, 3.2441530227661133, 3.158155918121338, 2.943842887878418, 3.267253875732422, 3.179605007171631, 3.323758363723755, 2.8833839893341064, 3.024226427078247, 2.9562323093414307, 3.060774326324463, 3.1751742362976074, 3.1630077362060547, 3.2132928371429443, 3.4324162006378174, 3.2585818767547607, 3.0895652770996094, 3.268481969833374, 3.4065909385681152, 3.053546190261841, 3.0083587169647217, 3.013137102127075, 3.081848382949829, 3.0376064777374268, 3.3214638233184814, 3.158841609954834, 3.0158169269561768, 2.7577719688415527, 3.0561602115631104, 3.108978033065796, 3.117152452468872, 3.1697194576263428, 3.359982967376709, 2.9028265476226807, 3.1094963550567627, 3.2096004486083984, 3.116957902908325, 3.1084144115448, 3.1385111808776855, 2.789299964904785, 2.933955669403076, 2.8215227127075195, 2.790879011154175, 3.100888729095459, 2.865518093109131, 2.9168896675109863, 3.054525852203369, 3.0715322494506836, 2.9792799949645996, 3.129260301589966, 3.0201008319854736, 3.0717084407806396, 3.1768040657043457, 3.157043695449829, 2.962395191192627, 3.228766441345215, 3.167510986328125, 3.4657206535339355, 3.286003589630127, 2.917365312576294, 2.8314754962921143, 3.090651750564575, 2.9980340003967285, 2.942857265472412, 2.9022388458251953, 3.101646900177002, 2.9037113189697266, 3.071648359298706, 3.0854098796844482, 2.8905444145202637, 2.8986892700195312, 3.2746121883392334, 2.965207576751709, 3.0924489498138428, 3.033717632293701, 3.1156725883483887, 3.0276482105255127, 2.901515007019043, 2.8947315216064453, 2.7878730297088623, 3.2310428619384766, 3.0193676948547363, 3.0693812370300293, 3.008265733718872, 3.128249406814575, 2.954129457473755, 3.0816574096679688, 2.863710641860962, 2.9655027389526367, 2.9889743328094482, 3.2922353744506836, 3.13974666595459], 'loss': [220.91224119501715, 27.11379536372481, 19.75985872979729, 15.31094120937253, 13.464548753163243, 12.460527471249794, 11.840887709317943, 10.76261305504228, 10.981404301236314, 10.957343825148518, 9.890129657083842, 10.325946078887048, 9.947287542329372, 9.681579461634028, 9.60147193553748, 9.391210629138124, 9.375327706723109, 8.669306792650394, 8.864843734879505, 8.383677586692585, 8.86665691632207, 8.29350437614186, 8.269894245649098, 8.36051216852921, 7.870618710060106, 7.932055111702698, 8.023172340885301, 7.8112231256681754, 7.4804007015954275, 7.344806748516144, 6.958852902038746, 7.442269975422425, 7.0059389828436025, 7.194817034163681, 7.122247566256498, 7.061409716926916, 7.053239899652422, 7.066888882098535, 6.9116902592092115, 6.553164155416657, 6.708218656152678, 6.600882849722706, 6.224811665246697, 5.964946027466458, 6.7186251910658035, 6.2162915318403735, 6.076515348873781, 5.978053831265443, 6.203378342769073, 6.005951501595444, 6.10373431106123, 6.031846877247091, 5.611678487574182, 5.939773235444375, 5.739223147619623, 5.550288088494565, 5.905297863312245, 5.3547766714844975, 5.7438805633009125, 5.442136294139213, 5.563534920883792, 5.46765416179528, 5.360013791876434, 5.18632851165382, 5.6680000758403395, 5.185825531731758, 5.372011352118747, 4.835808624457977, 5.006181174999619, 4.775472341100899, 4.886543388130113, 5.268671605127491, 4.870051594338364, 4.925476956561271, 4.709018894961995, 4.964945808667775, 4.541372822300773, 4.5701188863985776, 4.439109129608702, 4.771510168906773, 4.70363363432606, 4.487363526615581, 4.6515532814143326, 4.702772705628503, 4.664398209838783, 4.468242031022432, 4.450822159764033, 4.597142791134811, 4.193608800989402, 4.290739727830976, 4.310078868349478, 3.8245893656195844, 3.9711119270730992, 3.3862823578644803, 3.9078300297959543, 4.149722717437669, 3.935468622611735, 4.0079219393485355, 3.994436159268811, 3.8031890725154516, 3.822983033752571, 4.004397827452452, 3.6637890925430177, 3.8140189423740276, 3.706124739664699, 3.717836206185137, 3.982879416452519, 3.8453902893897554, 3.675185812533089, 3.7008064239802265, 3.7314128937983524, 3.8045240363241013, 3.614959992593273, 3.3133707649165673, 3.552822416560384, 3.2376482366553767, 3.667392593624736, 3.5203603538694153, 3.4353133592432443, 3.6583944125910546, 3.3679687238044975, 3.55595834629123, 3.0497521782729655, 3.2667896676040753, 3.3147589361102807, 3.312737437869488, 3.189856316449787, 3.041384048266445, 3.1616697287682256, 3.0479042055023466, 3.0368866726025305, 3.043378943252764, 2.896820044461588, 3.183512478442413, 3.065891515837714, 3.028521969385861, 3.16996098223097, 2.957201387994579, 2.999539022561384, 2.8702565439716548, 2.7359099086130096, 2.836873066297353, 2.6569730833148135, 2.7186044950524626, 3.0172945553873527, 2.9340931485946413, 2.6805481886079963, 2.614343753343269, 2.5239766503147965, 2.6557610630729735, 2.7344737455254764, 2.363218407938908, 2.719602029811351, 2.4677373373755827, 2.4597544200729473, 2.2960417912089253, 2.4356719948290606, 2.436594188580451, 2.4192404047449365, 2.3169820907217584, 2.256019571108998, 2.3880130263856616, 2.549289781856324, 2.235822229215064, 2.447789186053096, 2.2740804099475738, 2.2974493517415437, 2.4117827153600784, 2.4255892936676005, 2.4712730353893986, 2.1538969890238806, 2.2256407506935316, 2.367148330895163, 2.155478122864158, 2.1447630209745916, 2.1552501524496703, 2.1693342327946725, 2.199473210870667, 2.1919444512764534, 2.0133177702626215, 2.1265838141404942, 2.015728377012679, 2.0606871624857575, 2.1155971019250157, 2.014167261573969, 1.9498829831525883, 2.0263248856677376, 1.970220763204818, 2.113811645251988, 2.0127392694291357, 1.9803574614235055, 1.9458322659542342, 1.8733985906302184, 1.9492439013313085, 1.9001288809494785, 1.8947842335687575, 1.8067972267020498, 1.9981241624561932, 1.9376523488475683, 1.8081758764456988, 2.0540595711252583, 1.8011670542024876, 1.9506510906430177, 2.038098420324459, 1.8152780582792727, 1.861597094607193, 1.6563254789125434, 1.7960822108348546, 1.8643914003389763, 1.6551089676073334, 1.7198912764029513, 1.7879104773425027, 1.7603640996316208, 1.690964080677977, 1.7260188934591671, 1.6848063499702601, 1.6680388582490286, 1.6737809484523078, 1.6310393360838595, 1.726207880432358, 1.5404503408155787, 1.592968801545329, 1.6174243116672935, 1.731628572464801, 1.6133730883161916, 1.6048228723055507, 1.5575646838591122, 1.5707179891951606, 1.6914289049344984, 1.6516051299529941, 1.5280912321079818, 1.5159309491418003, 1.6877274084428502, 1.554219910255774, 1.5161738381665488, 1.5137974172673536, 1.606801586825163, 1.5176931005157728, 1.5618887859460127, 1.5737950650922472, 1.5757200583164725, 1.50961691405205, 1.509412109386128, 1.5776486646264247, 1.4416635346907563, 1.543662933674274, 1.4838317418489708, 1.3636738258016818, 1.4733365962088567, 1.5310551114837567, 1.3223683024937332, 1.4426200088986205, 1.3424031598886528, 1.338710654734689, 1.4312863380184215, 1.2687942722798655, 1.4328492359604046, 1.3851005729620707, 1.2398154753494417, 1.4515347597509372, 1.3823894605048546, 1.367234700512079, 1.2178496401213346, 1.3623442399412002, 1.4575416156630225, 1.3198828462062688, 1.3633698775642902, 1.3349833153895294, 1.345828467031175, 1.294084144704714, 1.2729606445838497, 1.313645998941163, 1.3007187646074665, 1.2843536176270862, 1.2376577820903687, 1.3248087214488375, 1.3216268575185701, 1.3007545194303038, 1.1757884729114167, 1.4479533696192766, 1.0485849376323686, 1.2590909552999687, 1.2167479827111922, 1.4617832374229098, 1.32866633056791, 1.2589042982506984, 1.0961458269457611, 1.3017733160115144, 1.3717133421181307, 1.3352703253912726, 1.2059083385840026, 1.1777346773727817, 1.3617466180453492, 1.1841612893935498, 1.279330125836099, 1.170127375784402, 1.1666135986296986, 1.2584698941582517, 1.246953520219886, 1.0852485173470714, 1.0554912648335766, 1.066068597180455, 1.2070643117632085, 1.3067903496322157, 1.1567447933147688, 1.1583991655799897, 1.2085598613300823, 1.1293754294358596, 1.2194841457030543, 1.0617781322489643, 1.3086350457248141, 1.227144411801803, 1.173508362082604, 1.283440615008664, 1.0914517428778834, 1.228315661189242, 1.1327272878136776, 1.143110521377872, 1.1171542162023482, 1.2424655028588598, 1.1270764292028785, 1.0437970179497131, 1.1416165729298444, 1.168079768781813, 1.124622258143423, 1.074848326540797, 1.1254901071066588, 1.2626460650320315, 1.143151830286214, 1.031550853374698, 1.241387583928474, 1.072140857189321, 0.9618494064183588, 1.0149246203810276, 1.055557140413572, 1.10676705279191, 0.9982957801476364, 1.121132867885193, 1.0495711138193338, 1.102536779768385, 0.9907024197135056, 1.0137033133194162, 1.1316764637979972, 1.1124353278130674, 0.9732115305479797, 0.9797133631055769, 1.1397655381000906, 1.0720497339597186, 0.9964709937896391, 1.0286070202532411, 0.9703504125927193, 1.0524801094148468, 0.8944385798702317, 1.1610814795010918, 1.0261290600340758, 1.013005669751533, 0.970673960727467, 0.9596502576917106, 1.0150106651338322, 1.0164869718558387, 1.0106247339700762, 0.9900873331910531, 0.9490547028874043, 0.9149024388380825, 1.1292564142352397, 1.0028182974901367, 0.9949028543784578, 0.947173465561076, 0.879397995414239, 1.0876770165777998, 1.0393430721658408, 1.0316072741620805, 0.9627289716495803, 0.8817517558639251, 1.0025034670784723, 0.9632411973710651, 0.9483465420411022, 0.9607984036367462, 1.0346359282751412, 0.988866827502765, 1.003904072037096, 0.8897048479055427, 0.9511195045793988, 0.9955627776407019, 0.9938171030025902, 1.0033837781306485, 0.9609428469596697, 0.8721480149976709, 0.9604779968770287, 1.0124612304223852, 0.9066010922602806, 1.006189721259457, 0.868111842277556, 0.9739818001384529, 0.8219633923332913, 0.9451093490532261, 0.9866277020519703, 0.8261441654103211, 0.98640727031327, 0.963991801244666, 0.7847173433025457, 0.8221821062853802, 0.9468108394011693, 0.9053456065699036, 0.8179488015913815, 0.8930683078917127, 0.8268197980039433, 0.8990923751016843, 0.8229739544322211, 0.9251912083046612, 0.8654989015802839, 0.9254462217086677, 0.8738174059847855, 0.9856739915047259, 0.7618332348163904, 0.923385757804768, 0.9395470937079994, 0.8667005486850721, 0.8375123277178183, 0.8494916393061707, 0.8806246784328376, 0.8415660043722983, 0.813960931477064, 0.8012913809368839, 0.8932395058242523, 0.8713983495506927, 0.8218317342954244, 0.7781917498350205, 0.8353918872930044, 0.8494726595346208, 0.7914743980706256, 0.8399024233239477, 0.9697028278711189, 0.8078188178693537, 0.8506744499304014, 0.8048172535214816, 0.8227315513753362, 0.7479096876093344, 0.8549474828756417, 0.9434965695026981, 0.7794676317839055, 0.816477275672459, 0.9890861832268891, 0.8276335188888264, 0.8643097595448144, 0.7892674626374945, 0.7829429917401645, 0.7732397041985402, 0.771968421384408, 0.7936207587124763, 0.8056626168745125, 0.8167547005505905, 0.7714595113352771, 0.7672187475883782, 0.8495934076286221, 0.7534499657272151, 0.726539524988598, 0.7579913166057792, 0.8234275760626141, 0.7507289737801486, 0.787532362199164, 0.90188623564119, 0.921033318667733, 0.8585136196628503, 0.8174264788298622, 0.7970750739178996, 0.768076838379904, 0.7662790325745362, 0.8155710406695272, 0.7989824763325346, 0.8031331604746594, 0.8105335038070143, 0.7748877840639168, 0.8020361412858373, 0.7980409558821169, 0.7123604975078508, 0.8302453823784637, 0.7856907962116809, 0.7289384341592067, 0.7543973369747349, 0.8576904918040887, 0.7421829518842168, 0.7465030506016882, 0.7421747938891047, 0.7415580222435586, 0.7571673097458662, 0.7195336663094393, 0.8024518257486304, 0.7259955413855975, 0.742279115735091, 0.7158275534502566, 0.8061376278246285, 0.777091532761933, 0.733830549760878, 0.8337959597985612, 0.7568912740451424, 0.7660218680760832, 0.6757487690322798, 0.6786116168187069, 0.7485554677352453], 'mae': [11.108775, 3.4790046, 2.9694169, 2.6739872, 2.455744, 2.4222183, 2.3567622, 2.2346067, 2.233563, 2.2282329, 2.2124648, 2.149398, 2.0649798, 2.126299, 2.0731704, 2.0971808, 1.9805473, 2.0000548, 1.9735307, 1.8897752, 1.9360108, 1.8977091, 1.9502972, 1.909759, 1.9260697, 1.8413972, 1.9216194, 1.8478593, 1.77655, 1.8238392, 1.7501607, 1.8384919, 1.7934657, 1.7679843, 1.7942327, 1.792439, 1.7762489, 1.7916791, 1.7151799, 1.7354935, 1.7525929, 1.729271, 1.6794893, 1.7222852, 1.7315696, 1.69847, 1.665157, 1.668176, 1.6912652, 1.6623439, 1.5986372, 1.6068105, 1.6060749, 1.5876663, 1.6125263, 1.5989406, 1.5888852, 1.5869702, 1.6096941, 1.5761154, 1.5363572, 1.5852256, 1.5895147, 1.5461948, 1.5509725, 1.451734, 1.4980012, 1.4554462, 1.4986466, 1.496644, 1.5123386, 1.5130932, 1.4764217, 1.46082, 1.4282695, 1.476522, 1.5061955, 1.4603366, 1.4374919, 1.4177656, 1.4311825, 1.4026519, 1.3941692, 1.4523757, 1.4230535, 1.4053538, 1.3699176, 1.3969204, 1.3426938, 1.3849157, 1.3360709, 1.315669, 1.3794848, 1.2992897, 1.3725607, 1.3817443, 1.3170238, 1.3944403, 1.3275158, 1.3126088, 1.3372929, 1.2907985, 1.2834833, 1.3270491, 1.3416822, 1.3187172, 1.3372501, 1.3088182, 1.30376, 1.2865117, 1.304325, 1.3469577, 1.2547266, 1.2006733, 1.2576638, 1.232565, 1.2581793, 1.2413408, 1.2087102, 1.218562, 1.2484084, 1.2249688, 1.1638355, 1.158345, 1.2520239, 1.233859, 1.1907058, 1.1783735, 1.1993318, 1.1932433, 1.1850015, 1.1295462, 1.1694926, 1.2019401, 1.14923, 1.1588169, 1.1901965, 1.1340946, 1.1798272, 1.1121044, 1.1262486, 1.1838627, 1.1534508, 1.1409311, 1.1361642, 1.1782607, 1.1296222, 1.1014135, 1.1071886, 1.1274924, 1.1397961, 1.0635679, 1.1413708, 1.0653545, 1.1124581, 1.1201988, 1.104504, 1.0948339, 1.0719482, 1.0638212, 1.0429888, 1.0893091, 1.080893, 1.0350039, 1.0873249, 1.1051834, 1.0180349, 1.062869, 1.0609976, 1.1250702, 1.026377, 1.0356371, 1.0876864, 1.0508159, 0.99999344, 1.0450947, 1.0295358, 1.0646613, 1.0524058, 0.9937233, 1.0371535, 0.97613347, 0.9940431, 0.9953397, 0.98822755, 1.0000379, 1.0187968, 0.978745, 1.0062305, 0.9990199, 1.0314925, 1.0190786, 0.9667915, 1.0117629, 0.9873075, 0.98377645, 0.94345474, 0.98871714, 0.9768313, 0.9776435, 1.0131752, 0.9605026, 1.0173904, 1.0265439, 0.9580731, 0.95176387, 0.92790884, 0.9762001, 0.98048437, 0.918887, 0.9144455, 0.96620286, 0.9844959, 0.92077345, 0.9561536, 0.9414996, 0.9496356, 0.90678924, 0.9490602, 0.9670934, 0.9495718, 0.9558744, 0.9434466, 0.97254634, 0.9079441, 0.9499023, 0.9400815, 0.9056015, 0.94927585, 0.9155314, 0.91643995, 0.91860366, 0.97607535, 0.9361381, 0.89805233, 0.92783076, 0.9190567, 0.938774, 0.8991102, 0.9200983, 0.90728027, 0.88083905, 0.9000237, 0.93698394, 0.8773929, 0.9502494, 0.86100894, 0.8572474, 0.8814084, 0.9209025, 0.8545233, 0.8680824, 0.8559487, 0.8592411, 0.89955586, 0.84122336, 0.86866957, 0.8749965, 0.8447253, 0.8515342, 0.87920326, 0.8768194, 0.8273236, 0.85884947, 0.871283, 0.84216887, 0.8797501, 0.8269093, 0.8366318, 0.80850005, 0.8407623, 0.8700592, 0.8341303, 0.85141915, 0.82320327, 0.84966606, 0.86437285, 0.8361125, 0.809543, 0.8641337, 0.7741931, 0.84136176, 0.8231442, 0.8744393, 0.83017784, 0.8156674, 0.77713656, 0.8516726, 0.836938, 0.8305093, 0.7997664, 0.7964258, 0.8443251, 0.8181351, 0.8497366, 0.7915195, 0.7771243, 0.82093614, 0.8235232, 0.77116776, 0.77983004, 0.77021533, 0.7932761, 0.8009726, 0.7827357, 0.8148138, 0.7984318, 0.76158804, 0.82054496, 0.77927285, 0.84022295, 0.7888918, 0.78977376, 0.8592411, 0.77030206, 0.8317483, 0.7816241, 0.78098214, 0.7645707, 0.78849614, 0.77931815, 0.76892775, 0.7827686, 0.7906908, 0.79383, 0.7639438, 0.8137108, 0.7930541, 0.7529506, 0.75800675, 0.7726658, 0.7582228, 0.7288612, 0.7590642, 0.7954714, 0.7784276, 0.72224706, 0.79209656, 0.7303026, 0.7607701, 0.7610005, 0.7479841, 0.7854727, 0.79232913, 0.7399001, 0.708878, 0.7795002, 0.77209526, 0.7386788, 0.74117106, 0.71202254, 0.7391042, 0.6545464, 0.789755, 0.74574, 0.7180493, 0.7051498, 0.7275211, 0.74009573, 0.7340996, 0.7358634, 0.729389, 0.76111156, 0.72474504, 0.7499373, 0.74744153, 0.73193896, 0.729262, 0.6854698, 0.7411706, 0.7299579, 0.7222133, 0.74151695, 0.71407837, 0.7376117, 0.7553906, 0.69255733, 0.73406154, 0.754252, 0.7342661, 0.72470564, 0.7195643, 0.7163426, 0.72998726, 0.7623485, 0.73365957, 0.7300325, 0.6989129, 0.7397771, 0.73171806, 0.70666987, 0.7196075, 0.70067304, 0.7236249, 0.6672518, 0.7147662, 0.7249965, 0.661747, 0.73428714, 0.74842227, 0.657322, 0.6705904, 0.7173292, 0.72238654, 0.6778532, 0.6990887, 0.68962765, 0.66198325, 0.65596616, 0.68572897, 0.6932323, 0.6784528, 0.6965621, 0.7529912, 0.6599239, 0.68554646, 0.71962917, 0.67842835, 0.66290236, 0.70351833, 0.6809195, 0.7038798, 0.67465484, 0.6606604, 0.7027048, 0.6859779, 0.6723694, 0.65998656, 0.6891034, 0.6628944, 0.66688716, 0.67719483, 0.7107262, 0.67738295, 0.6844358, 0.6640348, 0.6662366, 0.6467264, 0.68544316, 0.68245876, 0.6152917, 0.6463104, 0.72280437, 0.673316, 0.643611, 0.6489984, 0.6580233, 0.6526064, 0.643125, 0.6723163, 0.6708384, 0.6653662, 0.6571673, 0.62477845, 0.6608637, 0.6626089, 0.6517198, 0.647269, 0.6636098, 0.64742184, 0.6279655, 0.6892886, 0.68149143, 0.6952065, 0.66012764, 0.65323985, 0.6505066, 0.64850324, 0.6645129, 0.663399, 0.663002, 0.6667813, 0.63942385, 0.6520926, 0.651263, 0.59817004, 0.66074955, 0.65312093, 0.6412549, 0.644782, 0.7007107, 0.63862675, 0.63161737, 0.63577026, 0.64895, 0.65628767, 0.62170684, 0.67039, 0.6174392, 0.6355379, 0.6451937, 0.6696951, 0.6581906, 0.6293691, 0.6557931, 0.63024867, 0.62455356, 0.6150126, 0.6141726, 0.623574]}\n",
      "processing fold # 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 174.8522 - mae: 9.7786 - val_loss: 34.4877 - val_mae: 4.0601\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 25.9737 - mae: 3.5894 - val_loss: 24.7265 - val_mae: 3.1817\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 18.6501 - mae: 2.9261 - val_loss: 18.9500 - val_mae: 2.9170\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 15.9700 - mae: 2.7430 - val_loss: 18.4464 - val_mae: 2.7155\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 13.7509 - mae: 2.5401 - val_loss: 17.6567 - val_mae: 2.6591\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 11.9931 - mae: 2.4081 - val_loss: 19.7682 - val_mae: 2.8888\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 11.7664 - mae: 2.3352 - val_loss: 16.5465 - val_mae: 2.6008\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 10.9038 - mae: 2.2709 - val_loss: 16.9247 - val_mae: 2.7689\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 10.3958 - mae: 2.2574 - val_loss: 18.2452 - val_mae: 2.9493\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 0s 681us/step - loss: 9.9839 - mae: 2.1335 - val_loss: 17.3046 - val_mae: 2.9565\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 9.7394 - mae: 2.1706 - val_loss: 14.7930 - val_mae: 2.4537\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 9.1144 - mae: 2.1273 - val_loss: 15.1483 - val_mae: 2.5701\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 8.9679 - mae: 2.0653 - val_loss: 14.9128 - val_mae: 2.5556\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 8.6884 - mae: 2.0393 - val_loss: 14.3109 - val_mae: 2.3717\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 8.3268 - mae: 2.0238 - val_loss: 15.2581 - val_mae: 2.4374\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 8.1623 - mae: 1.9429 - val_loss: 15.0230 - val_mae: 2.6461\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 7.7444 - mae: 1.9673 - val_loss: 15.9297 - val_mae: 2.5895\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 7.5213 - mae: 1.9014 - val_loss: 15.1031 - val_mae: 2.4751\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 7.5527 - mae: 1.9299 - val_loss: 15.2008 - val_mae: 2.5013\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 7.1763 - mae: 1.9148 - val_loss: 15.2667 - val_mae: 2.6074\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 6.8984 - mae: 1.9069 - val_loss: 14.6131 - val_mae: 2.4344\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 0s 781us/step - loss: 6.9536 - mae: 1.8628 - val_loss: 16.3941 - val_mae: 2.5719\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 7.0755 - mae: 1.8362 - val_loss: 14.4413 - val_mae: 2.5480\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 6.9357 - mae: 1.8301 - val_loss: 14.4946 - val_mae: 2.4618\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 6.6626 - mae: 1.7817 - val_loss: 13.3967 - val_mae: 2.3502\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 0s 761us/step - loss: 6.8489 - mae: 1.8683 - val_loss: 14.1089 - val_mae: 2.4239\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 6.4873 - mae: 1.7729 - val_loss: 14.6806 - val_mae: 2.5769\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 6.3405 - mae: 1.7664 - val_loss: 14.4122 - val_mae: 2.5375\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 6.3208 - mae: 1.7639 - val_loss: 14.5563 - val_mae: 2.5725\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 6.3971 - mae: 1.7384 - val_loss: 15.9331 - val_mae: 2.6362\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 5.9149 - mae: 1.7186 - val_loss: 13.9471 - val_mae: 2.4472\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 6.0668 - mae: 1.6713 - val_loss: 14.9393 - val_mae: 2.4834\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 6.0493 - mae: 1.7163 - val_loss: 13.7822 - val_mae: 2.3795\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 6.0341 - mae: 1.7131 - val_loss: 15.5719 - val_mae: 2.5221\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 6.0501 - mae: 1.7200 - val_loss: 13.4670 - val_mae: 2.3778\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 5.8451 - mae: 1.6820 - val_loss: 13.7096 - val_mae: 2.3459\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 5.6993 - mae: 1.6523 - val_loss: 13.7116 - val_mae: 2.3042\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 5.6472 - mae: 1.7189 - val_loss: 14.9685 - val_mae: 2.5401\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 0s 764us/step - loss: 5.7310 - mae: 1.5892 - val_loss: 13.4677 - val_mae: 2.4797\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 5.6083 - mae: 1.6353 - val_loss: 13.9722 - val_mae: 2.4131\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 5.7138 - mae: 1.6270 - val_loss: 14.1898 - val_mae: 2.5774\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 5.6092 - mae: 1.6603 - val_loss: 13.8536 - val_mae: 2.3022\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 5.6866 - mae: 1.6402 - val_loss: 13.9104 - val_mae: 2.4543\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 5.6225 - mae: 1.5364 - val_loss: 13.2739 - val_mae: 2.3078\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 5.6172 - mae: 1.6393 - val_loss: 14.0363 - val_mae: 2.5599\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 5.1982 - mae: 1.5420 - val_loss: 14.2660 - val_mae: 2.5857\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 4.8411 - mae: 1.5914 - val_loss: 13.9969 - val_mae: 2.4934\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 5.1114 - mae: 1.5297 - val_loss: 16.2467 - val_mae: 2.6749\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 5.0785 - mae: 1.5632 - val_loss: 15.0493 - val_mae: 2.6658\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 4.8837 - mae: 1.5290 - val_loss: 14.4142 - val_mae: 2.5066\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 4.8575 - mae: 1.5634 - val_loss: 14.7705 - val_mae: 2.5344\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 4.8104 - mae: 1.5284 - val_loss: 13.1887 - val_mae: 2.4728\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 4.8321 - mae: 1.5179 - val_loss: 14.8507 - val_mae: 2.5806\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 0s 753us/step - loss: 4.8292 - mae: 1.5058 - val_loss: 13.5133 - val_mae: 2.3773\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 4.6943 - mae: 1.5489 - val_loss: 14.0238 - val_mae: 2.5186\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 4.5950 - mae: 1.5295 - val_loss: 15.2609 - val_mae: 2.7629\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 5.0183 - mae: 1.5426 - val_loss: 15.5378 - val_mae: 2.6100\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 4.8654 - mae: 1.5342 - val_loss: 14.1620 - val_mae: 2.4829\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 4.6642 - mae: 1.4253 - val_loss: 14.1381 - val_mae: 2.4796\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 860us/step - loss: 4.6985 - mae: 1.5068 - val_loss: 13.9912 - val_mae: 2.4805\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 4.5017 - mae: 1.5151 - val_loss: 15.1868 - val_mae: 2.5500\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 0s 751us/step - loss: 4.6038 - mae: 1.5255 - val_loss: 15.0338 - val_mae: 2.5807\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 4.2011 - mae: 1.4644 - val_loss: 14.4868 - val_mae: 2.6328\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 4.1401 - mae: 1.4499 - val_loss: 14.8310 - val_mae: 2.5048\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 4.3578 - mae: 1.4489 - val_loss: 14.3622 - val_mae: 2.5186\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 4.0923 - mae: 1.3891 - val_loss: 15.8559 - val_mae: 2.7407\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 4.2215 - mae: 1.4491 - val_loss: 13.7145 - val_mae: 2.3813\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 4.1020 - mae: 1.3820 - val_loss: 13.6796 - val_mae: 2.4949\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 3.9736 - mae: 1.4033 - val_loss: 15.2219 - val_mae: 2.6508\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 4.2808 - mae: 1.4392 - val_loss: 14.2422 - val_mae: 2.5025\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 3.6371 - mae: 1.3695 - val_loss: 15.1059 - val_mae: 2.6434\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 4.0023 - mae: 1.3618 - val_loss: 14.8161 - val_mae: 2.4617\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 4.0470 - mae: 1.4237 - val_loss: 15.2841 - val_mae: 2.6621\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 4.1309 - mae: 1.3840 - val_loss: 16.1696 - val_mae: 2.8224\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 4.1080 - mae: 1.4306 - val_loss: 15.8694 - val_mae: 2.8084\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 3.6300 - mae: 1.3936 - val_loss: 15.3950 - val_mae: 2.6274\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 4.0869 - mae: 1.4316 - val_loss: 15.0962 - val_mae: 2.6491\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 3.8482 - mae: 1.3771 - val_loss: 14.3831 - val_mae: 2.5323\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 3.6870 - mae: 1.4086 - val_loss: 15.3297 - val_mae: 2.5614\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 3.8965 - mae: 1.3856 - val_loss: 15.6115 - val_mae: 2.5457\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 0s 836us/step - loss: 3.8012 - mae: 1.4110 - val_loss: 14.8604 - val_mae: 2.5074\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 3.5580 - mae: 1.3940 - val_loss: 15.8266 - val_mae: 2.6761\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 3.7175 - mae: 1.3694 - val_loss: 15.9575 - val_mae: 2.6244\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 3.4610 - mae: 1.3319 - val_loss: 16.2984 - val_mae: 2.7007\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 3.3697 - mae: 1.3300 - val_loss: 16.0066 - val_mae: 2.6860\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 0s 786us/step - loss: 3.5865 - mae: 1.3591 - val_loss: 16.0727 - val_mae: 2.5676\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 0s 930us/step - loss: 3.4396 - mae: 1.3065 - val_loss: 15.9011 - val_mae: 2.6057\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 3.5209 - mae: 1.3323 - val_loss: 17.6098 - val_mae: 2.8414\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 3.6092 - mae: 1.3564 - val_loss: 15.5672 - val_mae: 2.6250\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 0s 929us/step - loss: 3.4650 - mae: 1.3461 - val_loss: 16.1146 - val_mae: 2.6788\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 0s 776us/step - loss: 3.1784 - mae: 1.3092 - val_loss: 15.5982 - val_mae: 2.5909\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 3.4091 - mae: 1.3081 - val_loss: 17.3382 - val_mae: 2.7611\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 3.2062 - mae: 1.3517 - val_loss: 16.4346 - val_mae: 2.6997\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 3.5328 - mae: 1.3187 - val_loss: 17.5784 - val_mae: 2.7793\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 3.1552 - mae: 1.2681 - val_loss: 15.9874 - val_mae: 2.5538\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 3.1999 - mae: 1.3204 - val_loss: 16.5180 - val_mae: 2.6721\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 3.1817 - mae: 1.2575 - val_loss: 16.9607 - val_mae: 2.7014\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 3.1008 - mae: 1.3047 - val_loss: 16.5632 - val_mae: 2.6748\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 3.3445 - mae: 1.2659 - val_loss: 15.6819 - val_mae: 2.6567\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 2.9371 - mae: 1.2604 - val_loss: 17.6938 - val_mae: 2.8374\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 3.0238 - mae: 1.2521 - val_loss: 17.3800 - val_mae: 2.7467\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 3.1223 - mae: 1.2451 - val_loss: 16.1696 - val_mae: 2.6492\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 2.6819 - mae: 1.1864 - val_loss: 17.8980 - val_mae: 2.9197\n",
      "Epoch 104/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 3.2103 - mae: 1.2984 - val_loss: 17.3139 - val_mae: 2.7701\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 2.8084 - mae: 1.2151 - val_loss: 16.4891 - val_mae: 2.7744\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 2.9286 - mae: 1.2410 - val_loss: 16.5301 - val_mae: 2.6828\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 3.0346 - mae: 1.2313 - val_loss: 17.5998 - val_mae: 2.7717\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 2.9938 - mae: 1.2306 - val_loss: 17.8476 - val_mae: 2.7734\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 2.6364 - mae: 1.1797 - val_loss: 15.9846 - val_mae: 2.6191\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 3.0345 - mae: 1.2515 - val_loss: 16.5949 - val_mae: 2.6920\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 2.7559 - mae: 1.2357 - val_loss: 17.0417 - val_mae: 2.6849\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 2.7936 - mae: 1.1870 - val_loss: 17.7215 - val_mae: 2.8512\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 2.4181 - mae: 1.1591 - val_loss: 16.3820 - val_mae: 2.6370\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 2.7778 - mae: 1.2519 - val_loss: 18.0264 - val_mae: 2.7816\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 2.6890 - mae: 1.1440 - val_loss: 17.0570 - val_mae: 2.7159\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 2.4239 - mae: 1.1597 - val_loss: 18.6876 - val_mae: 2.7854\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 2.4208 - mae: 1.1572 - val_loss: 17.0931 - val_mae: 2.6939\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 2.3452 - mae: 1.1255 - val_loss: 20.0604 - val_mae: 3.0052\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 2.6766 - mae: 1.1991 - val_loss: 17.8101 - val_mae: 2.7780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 2.5638 - mae: 1.1793 - val_loss: 17.4959 - val_mae: 2.7511\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 2.3972 - mae: 1.1543 - val_loss: 17.1045 - val_mae: 2.6945\n",
      "Epoch 122/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 2.5678 - mae: 1.1859 - val_loss: 17.5303 - val_mae: 2.8220\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 2.4394 - mae: 1.1215 - val_loss: 17.4694 - val_mae: 2.7594\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 0s 701us/step - loss: 2.5042 - mae: 1.1849 - val_loss: 17.2837 - val_mae: 2.7630\n",
      "Epoch 125/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 2.6907 - mae: 1.1866 - val_loss: 19.0555 - val_mae: 2.9023\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 2.4090 - mae: 1.1125 - val_loss: 18.2452 - val_mae: 2.7424\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 2.0314 - mae: 1.0608 - val_loss: 17.6139 - val_mae: 2.7725\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 2.6094 - mae: 1.1871 - val_loss: 17.7620 - val_mae: 2.7364\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 2.2924 - mae: 1.1118 - val_loss: 18.7346 - val_mae: 2.7453\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 2.2625 - mae: 1.1153 - val_loss: 19.6049 - val_mae: 2.8372\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 2.4123 - mae: 1.0970 - val_loss: 17.3982 - val_mae: 2.7613\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 2.1131 - mae: 1.0889 - val_loss: 17.6298 - val_mae: 2.7015\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 2.2387 - mae: 1.1038 - val_loss: 17.1295 - val_mae: 2.6513\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 2.1802 - mae: 1.0806 - val_loss: 18.9123 - val_mae: 2.8158\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 2.3466 - mae: 1.1021 - val_loss: 17.4088 - val_mae: 2.7477\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 2.0840 - mae: 1.0341 - val_loss: 18.2921 - val_mae: 2.7624\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 2.2251 - mae: 1.0989 - val_loss: 17.8405 - val_mae: 2.8507\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 2.4464 - mae: 1.1509 - val_loss: 17.7473 - val_mae: 2.7158\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 2.1088 - mae: 1.0302 - val_loss: 20.7283 - val_mae: 3.0005\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 2.3805 - mae: 1.1221 - val_loss: 17.2286 - val_mae: 2.5959\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 0s 700us/step - loss: 2.3280 - mae: 1.1281 - val_loss: 17.1238 - val_mae: 2.6443\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 2.2529 - mae: 1.0864 - val_loss: 16.9991 - val_mae: 2.7220\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 2.1409 - mae: 1.0311 - val_loss: 18.8862 - val_mae: 2.8666\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 2.1113 - mae: 1.0591 - val_loss: 18.7602 - val_mae: 2.8869\n",
      "Epoch 145/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 2.3242 - mae: 1.1106 - val_loss: 20.4088 - val_mae: 2.9321\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 2.1730 - mae: 1.0693 - val_loss: 16.1302 - val_mae: 2.6481\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.9336 - mae: 1.0290 - val_loss: 17.5499 - val_mae: 2.7115\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 2.1885 - mae: 1.0147 - val_loss: 17.2402 - val_mae: 2.6896\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 2.1389 - mae: 1.0483 - val_loss: 16.8649 - val_mae: 2.6426\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 2.2909 - mae: 1.1252 - val_loss: 17.0678 - val_mae: 2.6713\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.9511 - mae: 1.0097 - val_loss: 19.0942 - val_mae: 2.7515\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.7556 - mae: 0.9849 - val_loss: 19.0205 - val_mae: 2.9805\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.8945 - mae: 1.0067 - val_loss: 18.6519 - val_mae: 2.8564\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 0s 700us/step - loss: 2.0916 - mae: 1.0603 - val_loss: 17.0054 - val_mae: 2.6688\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 2.0303 - mae: 1.0017 - val_loss: 18.3584 - val_mae: 2.8214\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 2.1753 - mae: 1.0454 - val_loss: 18.1187 - val_mae: 2.7152\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.8585 - mae: 0.9970 - val_loss: 16.6030 - val_mae: 2.5988\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 1.9692 - mae: 1.0483 - val_loss: 18.1990 - val_mae: 2.7668\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 2.0546 - mae: 1.0007 - val_loss: 18.6686 - val_mae: 2.8070\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.8060 - mae: 0.9865 - val_loss: 17.0242 - val_mae: 2.6863\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.8874 - mae: 1.0034 - val_loss: 15.9152 - val_mae: 2.6627\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.7515 - mae: 0.9985 - val_loss: 21.2581 - val_mae: 3.2272\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.9925 - mae: 1.0393 - val_loss: 19.7218 - val_mae: 2.9444\n",
      "Epoch 164/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.7125 - mae: 0.9487 - val_loss: 17.7807 - val_mae: 2.7987\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.9779 - mae: 1.0273 - val_loss: 18.7604 - val_mae: 2.8452\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 1.8060 - mae: 0.9547 - val_loss: 18.4482 - val_mae: 2.7924\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.7277 - mae: 0.9671 - val_loss: 19.4865 - val_mae: 2.9226\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.7300 - mae: 0.9914 - val_loss: 19.0489 - val_mae: 2.8634\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 1.7830 - mae: 0.9783 - val_loss: 20.5211 - val_mae: 3.0051\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.7602 - mae: 0.9685 - val_loss: 17.9719 - val_mae: 2.7680\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.6846 - mae: 0.9297 - val_loss: 19.7511 - val_mae: 3.0271\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.7075 - mae: 0.9492 - val_loss: 18.0518 - val_mae: 2.8412\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.8183 - mae: 1.0125 - val_loss: 16.4392 - val_mae: 2.6348\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.7173 - mae: 0.9608 - val_loss: 16.5359 - val_mae: 2.6799\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.5722 - mae: 0.9494 - val_loss: 19.2533 - val_mae: 2.9089\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.9501 - mae: 1.0024 - val_loss: 17.4723 - val_mae: 2.7564\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.6755 - mae: 0.9203 - val_loss: 20.7980 - val_mae: 3.0592\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.4941 - mae: 0.9134 - val_loss: 17.9914 - val_mae: 2.7441\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 742us/step - loss: 1.7503 - mae: 0.9273 - val_loss: 18.7015 - val_mae: 2.8931\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.5998 - mae: 0.9310 - val_loss: 17.8757 - val_mae: 2.8615\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 0s 701us/step - loss: 1.7875 - mae: 0.9708 - val_loss: 17.9173 - val_mae: 2.7513\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.5255 - mae: 0.9119 - val_loss: 18.9350 - val_mae: 2.8570\n",
      "Epoch 183/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.7949 - mae: 0.9956 - val_loss: 18.2067 - val_mae: 2.8214\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.6941 - mae: 0.9308 - val_loss: 18.9747 - val_mae: 2.9175\n",
      "Epoch 185/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.6239 - mae: 0.9550 - val_loss: 17.4197 - val_mae: 2.7737\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.5096 - mae: 0.9131 - val_loss: 18.5963 - val_mae: 2.9042\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 1.8086 - mae: 0.9638 - val_loss: 18.1281 - val_mae: 2.7991\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 1.3047 - mae: 0.8558 - val_loss: 18.7838 - val_mae: 2.8607\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.9690 - mae: 1.0004 - val_loss: 20.1395 - val_mae: 3.0293\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.4873 - mae: 0.8993 - val_loss: 20.6996 - val_mae: 3.0323\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.6028 - mae: 0.9003 - val_loss: 17.7869 - val_mae: 2.7390\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.5120 - mae: 0.8970 - val_loss: 17.8170 - val_mae: 2.7517\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 1.6003 - mae: 0.9513 - val_loss: 18.5581 - val_mae: 2.8783\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.5186 - mae: 0.8928 - val_loss: 18.6468 - val_mae: 2.9121\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.4815 - mae: 0.9012 - val_loss: 18.2305 - val_mae: 2.7337\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.5541 - mae: 0.9325 - val_loss: 17.5952 - val_mae: 2.6923\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.6025 - mae: 0.9170 - val_loss: 17.5818 - val_mae: 2.7198\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.6155 - mae: 0.9245 - val_loss: 17.2096 - val_mae: 2.8149\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 1.3677 - mae: 0.8506 - val_loss: 19.8752 - val_mae: 3.0007\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.7289 - mae: 0.9453 - val_loss: 18.2264 - val_mae: 2.8294\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.3422 - mae: 0.8752 - val_loss: 20.1553 - val_mae: 2.9709\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.3062 - mae: 0.8597 - val_loss: 18.0998 - val_mae: 2.9117\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.3852 - mae: 0.8731 - val_loss: 17.3867 - val_mae: 2.6937\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.6347 - mae: 0.9078 - val_loss: 19.1029 - val_mae: 2.8349\n",
      "Epoch 205/500\n",
      "303/303 [==============================] - 0s 702us/step - loss: 1.4727 - mae: 0.8589 - val_loss: 19.3053 - val_mae: 2.9307\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.6342 - mae: 0.9104 - val_loss: 18.5649 - val_mae: 2.8866\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 0s 701us/step - loss: 1.3305 - mae: 0.8563 - val_loss: 16.5825 - val_mae: 2.6308\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.3731 - mae: 0.8585 - val_loss: 19.3042 - val_mae: 3.0600\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.5658 - mae: 0.9271 - val_loss: 18.1354 - val_mae: 2.8002\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.3232 - mae: 0.8810 - val_loss: 18.9126 - val_mae: 3.0127\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 0s 762us/step - loss: 1.4791 - mae: 0.8700 - val_loss: 18.6729 - val_mae: 2.8658\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 1.4250 - mae: 0.8614 - val_loss: 17.0770 - val_mae: 2.8552\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.4433 - mae: 0.8769 - val_loss: 17.0441 - val_mae: 2.7755\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.4532 - mae: 0.8929 - val_loss: 18.7894 - val_mae: 2.8331\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 1.2350 - mae: 0.8517 - val_loss: 22.6103 - val_mae: 3.3525\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.5363 - mae: 0.9108 - val_loss: 18.1296 - val_mae: 2.8656\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 1.4638 - mae: 0.8680 - val_loss: 18.6352 - val_mae: 2.9168\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 1.3546 - mae: 0.8315 - val_loss: 19.4878 - val_mae: 3.0114\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.4479 - mae: 0.8811 - val_loss: 18.9119 - val_mae: 2.9474\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.4058 - mae: 0.8917 - val_loss: 18.6796 - val_mae: 2.8707\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 1.3103 - mae: 0.8480 - val_loss: 17.3125 - val_mae: 2.7747\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.3981 - mae: 0.8586 - val_loss: 18.2557 - val_mae: 2.8576\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.3642 - mae: 0.8614 - val_loss: 17.6771 - val_mae: 2.8265\n",
      "Epoch 224/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.3204 - mae: 0.8542 - val_loss: 19.6131 - val_mae: 2.9918\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.3226 - mae: 0.7963 - val_loss: 18.6904 - val_mae: 2.8072\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.4137 - mae: 0.8547 - val_loss: 16.6070 - val_mae: 2.7333\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.3607 - mae: 0.8467 - val_loss: 18.1679 - val_mae: 2.8121\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 1.3371 - mae: 0.8371 - val_loss: 17.9197 - val_mae: 2.8316\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.3872 - mae: 0.8765 - val_loss: 20.0573 - val_mae: 3.0231\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.2601 - mae: 0.8136 - val_loss: 16.7762 - val_mae: 2.7824\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.3587 - mae: 0.8561 - val_loss: 18.4055 - val_mae: 2.9653\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.2404 - mae: 0.8122 - val_loss: 17.1643 - val_mae: 2.8402\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.3537 - mae: 0.8445 - val_loss: 18.5086 - val_mae: 2.9262\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.3282 - mae: 0.8292 - val_loss: 17.2954 - val_mae: 2.7867\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.3894 - mae: 0.8474 - val_loss: 18.3838 - val_mae: 2.8977\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.1990 - mae: 0.8102 - val_loss: 18.1822 - val_mae: 2.9145\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.2897 - mae: 0.8215 - val_loss: 18.4152 - val_mae: 2.9135\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 717us/step - loss: 1.3154 - mae: 0.8169 - val_loss: 17.1404 - val_mae: 2.7833\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 1.3393 - mae: 0.8452 - val_loss: 17.5394 - val_mae: 2.8300\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 0s 699us/step - loss: 1.3499 - mae: 0.8382 - val_loss: 17.9557 - val_mae: 2.8916\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.2640 - mae: 0.8309 - val_loss: 21.1796 - val_mae: 3.2031\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.3387 - mae: 0.8056 - val_loss: 18.1344 - val_mae: 2.9282\n",
      "Epoch 243/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.2429 - mae: 0.8108 - val_loss: 17.9685 - val_mae: 2.9184\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.2027 - mae: 0.7848 - val_loss: 17.3829 - val_mae: 2.8461\n",
      "Epoch 245/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.2178 - mae: 0.8008 - val_loss: 17.5165 - val_mae: 2.9630\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.3116 - mae: 0.8296 - val_loss: 16.8772 - val_mae: 2.7748\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.2156 - mae: 0.8058 - val_loss: 16.1992 - val_mae: 2.6345\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.4055 - mae: 0.8220 - val_loss: 19.0054 - val_mae: 2.9958\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.2681 - mae: 0.7811 - val_loss: 17.3148 - val_mae: 2.8259\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.1887 - mae: 0.7895 - val_loss: 17.7554 - val_mae: 2.8643\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.3783 - mae: 0.8149 - val_loss: 17.8994 - val_mae: 2.8380\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.1670 - mae: 0.7501 - val_loss: 18.1631 - val_mae: 2.9558\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.2094 - mae: 0.8175 - val_loss: 17.4273 - val_mae: 2.8461\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.2197 - mae: 0.7949 - val_loss: 19.0595 - val_mae: 2.9860\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 0s 701us/step - loss: 1.2002 - mae: 0.8026 - val_loss: 18.1028 - val_mae: 2.8499\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.1576 - mae: 0.7867 - val_loss: 17.8595 - val_mae: 2.9510\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 0s 700us/step - loss: 1.1775 - mae: 0.7993 - val_loss: 18.1492 - val_mae: 2.8786\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 1.0391 - mae: 0.7488 - val_loss: 19.6952 - val_mae: 3.0312\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 1.2753 - mae: 0.8164 - val_loss: 18.0020 - val_mae: 2.8669\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.1675 - mae: 0.8036 - val_loss: 16.7767 - val_mae: 2.8650\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.2413 - mae: 0.8326 - val_loss: 18.9369 - val_mae: 2.9206\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.2532 - mae: 0.8030 - val_loss: 17.7333 - val_mae: 2.9178\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.1013 - mae: 0.7756 - val_loss: 17.2010 - val_mae: 2.8197\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 0.9820 - mae: 0.7470 - val_loss: 17.6690 - val_mae: 2.9126\n",
      "Epoch 265/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.2696 - mae: 0.8372 - val_loss: 18.2807 - val_mae: 2.9926\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.1713 - mae: 0.7791 - val_loss: 19.2164 - val_mae: 2.9936\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.0041 - mae: 0.7201 - val_loss: 20.2013 - val_mae: 3.1666\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.2160 - mae: 0.7982 - val_loss: 17.8082 - val_mae: 2.9498\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.1841 - mae: 0.7904 - val_loss: 17.7940 - val_mae: 2.9067\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.1373 - mae: 0.7787 - val_loss: 18.0986 - val_mae: 2.9506\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.1555 - mae: 0.7908 - val_loss: 17.7584 - val_mae: 2.9465\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.2611 - mae: 0.8140 - val_loss: 16.8414 - val_mae: 2.7997\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 1.1866 - mae: 0.8162 - val_loss: 16.9022 - val_mae: 2.8136\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.1209 - mae: 0.7577 - val_loss: 17.8817 - val_mae: 2.9060\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.1531 - mae: 0.7636 - val_loss: 17.8285 - val_mae: 2.9076\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.1056 - mae: 0.7900 - val_loss: 17.8586 - val_mae: 2.9174\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.2129 - mae: 0.8081 - val_loss: 17.6803 - val_mae: 2.9235\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.1904 - mae: 0.8065 - val_loss: 18.3221 - val_mae: 3.0116\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.1873 - mae: 0.7994 - val_loss: 17.5410 - val_mae: 2.9077\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.0720 - mae: 0.7709 - val_loss: 17.1432 - val_mae: 2.8435\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.1941 - mae: 0.7881 - val_loss: 18.6373 - val_mae: 2.9325\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.9934 - mae: 0.7152 - val_loss: 18.2107 - val_mae: 2.9584\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.2236 - mae: 0.8091 - val_loss: 18.0190 - val_mae: 2.8819\n",
      "Epoch 284/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.1298 - mae: 0.7511 - val_loss: 16.8338 - val_mae: 2.8184\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 1.1443 - mae: 0.7669 - val_loss: 16.4568 - val_mae: 2.7995\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.1848 - mae: 0.8077 - val_loss: 18.2133 - val_mae: 2.9123\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 1.1167 - mae: 0.7698 - val_loss: 18.2393 - val_mae: 2.9429\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.0343 - mae: 0.7522 - val_loss: 17.8638 - val_mae: 2.9384\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.1848 - mae: 0.7847 - val_loss: 18.3628 - val_mae: 2.8834\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.9371 - mae: 0.7075 - val_loss: 17.3325 - val_mae: 2.8277\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.0104 - mae: 0.7475 - val_loss: 18.6309 - val_mae: 2.9814\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.2253 - mae: 0.7933 - val_loss: 16.9799 - val_mae: 2.8566\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 1.1245 - mae: 0.7645 - val_loss: 17.9541 - val_mae: 2.9552\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 1.1075 - mae: 0.7451 - val_loss: 17.9165 - val_mae: 2.9175\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 0.9615 - mae: 0.7141 - val_loss: 18.7691 - val_mae: 3.0278\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.0886 - mae: 0.7559 - val_loss: 17.1713 - val_mae: 2.9114\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 732us/step - loss: 1.0841 - mae: 0.7540 - val_loss: 18.9547 - val_mae: 2.9833\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.0218 - mae: 0.7509 - val_loss: 16.2472 - val_mae: 2.7833\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.1189 - mae: 0.7841 - val_loss: 17.6157 - val_mae: 2.8363\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 0.9830 - mae: 0.7260 - val_loss: 17.6628 - val_mae: 2.8669\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 1.0705 - mae: 0.7458 - val_loss: 17.9610 - val_mae: 2.8911\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 0s 700us/step - loss: 1.0194 - mae: 0.7090 - val_loss: 18.2391 - val_mae: 2.9608\n",
      "Epoch 303/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.0364 - mae: 0.7392 - val_loss: 18.8967 - val_mae: 3.0194\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.9673 - mae: 0.7098 - val_loss: 17.9427 - val_mae: 2.9080\n",
      "Epoch 305/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.1391 - mae: 0.7522 - val_loss: 17.3789 - val_mae: 2.8655\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 0.9599 - mae: 0.7147 - val_loss: 18.3990 - val_mae: 3.0061\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 0s 700us/step - loss: 0.8887 - mae: 0.7018 - val_loss: 17.3233 - val_mae: 2.8743\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.9459 - mae: 0.7204 - val_loss: 17.5737 - val_mae: 2.9310\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.0225 - mae: 0.7464 - val_loss: 18.1826 - val_mae: 2.9764\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.0612 - mae: 0.7188 - val_loss: 16.8694 - val_mae: 2.8101\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 0s 702us/step - loss: 1.0233 - mae: 0.7139 - val_loss: 18.1916 - val_mae: 2.9495\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.0389 - mae: 0.7553 - val_loss: 19.1357 - val_mae: 3.0552\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 1.0579 - mae: 0.7634 - val_loss: 18.2378 - val_mae: 2.9135\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.9923 - mae: 0.6972 - val_loss: 17.0317 - val_mae: 2.8921\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 0.9987 - mae: 0.7088 - val_loss: 19.5570 - val_mae: 3.0003\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 0.9763 - mae: 0.7273 - val_loss: 18.3056 - val_mae: 2.9899\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.9842 - mae: 0.7355 - val_loss: 18.8432 - val_mae: 3.0230\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 0.9779 - mae: 0.7238 - val_loss: 19.1928 - val_mae: 2.9621\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 0.9710 - mae: 0.7381 - val_loss: 19.2990 - val_mae: 3.0356\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.0497 - mae: 0.7402 - val_loss: 19.1536 - val_mae: 3.0303\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.0029 - mae: 0.6979 - val_loss: 17.8134 - val_mae: 2.9630\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 0.9091 - mae: 0.6808 - val_loss: 19.2033 - val_mae: 3.0597\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.9300 - mae: 0.7137 - val_loss: 17.2974 - val_mae: 2.9053\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 0.9088 - mae: 0.6918 - val_loss: 17.2362 - val_mae: 2.8680\n",
      "Epoch 325/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 1.0061 - mae: 0.7356 - val_loss: 17.9327 - val_mae: 2.9122\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 0.9437 - mae: 0.7043 - val_loss: 17.7235 - val_mae: 3.0010\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.8490 - mae: 0.6978 - val_loss: 17.9559 - val_mae: 2.8929\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.0181 - mae: 0.7712 - val_loss: 17.6529 - val_mae: 2.9155\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 0.9625 - mae: 0.7076 - val_loss: 18.9941 - val_mae: 3.0563\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 0.9249 - mae: 0.6834 - val_loss: 17.7530 - val_mae: 2.9013\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.8813 - mae: 0.7248 - val_loss: 17.5061 - val_mae: 2.8591\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 0.9784 - mae: 0.7142 - val_loss: 18.8756 - val_mae: 2.9998\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.8217 - mae: 0.6680 - val_loss: 19.2429 - val_mae: 2.9270\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 0s 772us/step - loss: 1.0271 - mae: 0.7354 - val_loss: 18.5806 - val_mae: 2.9398\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.9606 - mae: 0.7270 - val_loss: 18.5814 - val_mae: 2.9189\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.9211 - mae: 0.7040 - val_loss: 17.9282 - val_mae: 2.9104\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.0276 - mae: 0.7386 - val_loss: 17.1952 - val_mae: 2.8397\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 0.9857 - mae: 0.6960 - val_loss: 17.7236 - val_mae: 2.8717\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 0.9879 - mae: 0.6923 - val_loss: 18.6882 - val_mae: 2.9904\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 0.9353 - mae: 0.6817 - val_loss: 19.4860 - val_mae: 3.0578\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.9202 - mae: 0.6924 - val_loss: 18.9340 - val_mae: 2.9414\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 0s 692us/step - loss: 1.0451 - mae: 0.7338 - val_loss: 18.1549 - val_mae: 2.8949\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.8675 - mae: 0.7331 - val_loss: 19.3187 - val_mae: 3.0448\n",
      "Epoch 344/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 0.9281 - mae: 0.7031 - val_loss: 17.9702 - val_mae: 2.9070\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.8964 - mae: 0.7051 - val_loss: 19.0380 - val_mae: 2.9822\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 0.9734 - mae: 0.7197 - val_loss: 18.5941 - val_mae: 2.9396\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 0.8879 - mae: 0.6794 - val_loss: 17.1539 - val_mae: 2.8304\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.9601 - mae: 0.6847 - val_loss: 17.4201 - val_mae: 2.8364\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 0.8133 - mae: 0.6632 - val_loss: 17.8484 - val_mae: 2.8927\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 0.8964 - mae: 0.7154 - val_loss: 19.1120 - val_mae: 2.9203\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.7890 - mae: 0.6751 - val_loss: 18.5053 - val_mae: 2.9952\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.9164 - mae: 0.6988 - val_loss: 19.2476 - val_mae: 3.0264\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.8712 - mae: 0.6644 - val_loss: 17.3132 - val_mae: 2.9547\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.9074 - mae: 0.6897 - val_loss: 17.5975 - val_mae: 2.9070\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.7913 - mae: 0.6479 - val_loss: 18.1801 - val_mae: 2.9169\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 712us/step - loss: 1.0045 - mae: 0.7098 - val_loss: 19.3533 - val_mae: 3.0674\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.8540 - mae: 0.6827 - val_loss: 18.1036 - val_mae: 2.9197\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.8216 - mae: 0.6439 - val_loss: 19.6282 - val_mae: 3.0387\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 0.8629 - mae: 0.6689 - val_loss: 17.5303 - val_mae: 2.8462\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.9157 - mae: 0.6867 - val_loss: 20.0547 - val_mae: 3.1970\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 0.8270 - mae: 0.6843 - val_loss: 18.8735 - val_mae: 3.0181\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.7815 - mae: 0.6465 - val_loss: 17.5083 - val_mae: 2.9405\n",
      "Epoch 363/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 0.9011 - mae: 0.6992 - val_loss: 17.7372 - val_mae: 2.9736\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 0.8111 - mae: 0.6929 - val_loss: 18.4665 - val_mae: 3.0543\n",
      "Epoch 365/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.8680 - mae: 0.6581 - val_loss: 18.7559 - val_mae: 3.0212\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.9012 - mae: 0.6941 - val_loss: 15.9986 - val_mae: 2.8615\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 0.8456 - mae: 0.6723 - val_loss: 17.5074 - val_mae: 2.9270\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.8029 - mae: 0.6600 - val_loss: 16.8817 - val_mae: 2.8532\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 0.7989 - mae: 0.6375 - val_loss: 18.6367 - val_mae: 2.9337\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 0.8917 - mae: 0.6874 - val_loss: 17.4289 - val_mae: 2.8928\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 0.8226 - mae: 0.6605 - val_loss: 18.1655 - val_mae: 2.9794\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 0.9276 - mae: 0.6827 - val_loss: 18.0644 - val_mae: 2.9177\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 0.7594 - mae: 0.6617 - val_loss: 17.2806 - val_mae: 2.8250\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 0.8715 - mae: 0.6658 - val_loss: 18.2796 - val_mae: 2.9040\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 0s 752us/step - loss: 0.8193 - mae: 0.6477 - val_loss: 18.4295 - val_mae: 2.9420\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 0.8476 - mae: 0.6643 - val_loss: 18.0345 - val_mae: 2.9599\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 0.9236 - mae: 0.6821 - val_loss: 17.3736 - val_mae: 2.9402\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.7709 - mae: 0.6470 - val_loss: 19.1603 - val_mae: 3.0017\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 0.8531 - mae: 0.6601 - val_loss: 17.8918 - val_mae: 2.8692\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 0s 782us/step - loss: 0.8198 - mae: 0.6884 - val_loss: 18.8439 - val_mae: 2.9360\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 0.7814 - mae: 0.6598 - val_loss: 17.6816 - val_mae: 2.8985\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 0.8152 - mae: 0.6618 - val_loss: 18.3556 - val_mae: 3.0033\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.8369 - mae: 0.6646 - val_loss: 18.2402 - val_mae: 2.8853\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.8516 - mae: 0.6256 - val_loss: 18.3714 - val_mae: 2.9453\n",
      "Epoch 385/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.8200 - mae: 0.6562 - val_loss: 18.1422 - val_mae: 2.9776\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 0.8112 - mae: 0.6507 - val_loss: 18.4769 - val_mae: 2.9637\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 0s 697us/step - loss: 0.8720 - mae: 0.6809 - val_loss: 19.2411 - val_mae: 3.1416\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 0.8288 - mae: 0.6564 - val_loss: 18.7828 - val_mae: 2.9221\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 0.7713 - mae: 0.6618 - val_loss: 17.7496 - val_mae: 2.8432\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.8062 - mae: 0.6676 - val_loss: 17.7394 - val_mae: 2.8322\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.8207 - mae: 0.6664 - val_loss: 19.5538 - val_mae: 3.0778\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 0s 702us/step - loss: 0.7890 - mae: 0.6592 - val_loss: 17.8671 - val_mae: 2.8926\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.9025 - mae: 0.6623 - val_loss: 18.6344 - val_mae: 2.9762\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 0.8705 - mae: 0.6743 - val_loss: 17.0008 - val_mae: 2.8323\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.8063 - mae: 0.6667 - val_loss: 18.4020 - val_mae: 2.9100\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.8418 - mae: 0.6362 - val_loss: 18.2895 - val_mae: 2.9464\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.8209 - mae: 0.6481 - val_loss: 17.5734 - val_mae: 2.8781\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.8406 - mae: 0.6607 - val_loss: 17.3629 - val_mae: 2.9642\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.8826 - mae: 0.6667 - val_loss: 17.9453 - val_mae: 2.9075\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 0.7901 - mae: 0.6225 - val_loss: 18.1916 - val_mae: 2.9092\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 0.8688 - mae: 0.6879 - val_loss: 17.3971 - val_mae: 2.8639\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.7622 - mae: 0.6585 - val_loss: 19.6398 - val_mae: 3.0582\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 0s 700us/step - loss: 0.6987 - mae: 0.6130 - val_loss: 18.3059 - val_mae: 2.9997\n",
      "Epoch 404/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.8748 - mae: 0.6964 - val_loss: 17.3685 - val_mae: 2.8104\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 0.7092 - mae: 0.6199 - val_loss: 19.7249 - val_mae: 3.0109\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.8738 - mae: 0.7024 - val_loss: 19.5911 - val_mae: 2.9845\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 0.7306 - mae: 0.6078 - val_loss: 17.5927 - val_mae: 2.8718\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.7934 - mae: 0.6364 - val_loss: 17.6184 - val_mae: 2.8285\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.8594 - mae: 0.6576 - val_loss: 19.3014 - val_mae: 2.9257\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 0.8298 - mae: 0.6466 - val_loss: 18.9038 - val_mae: 3.0217\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.7961 - mae: 0.6459 - val_loss: 19.3087 - val_mae: 2.9739\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.8174 - mae: 0.6488 - val_loss: 18.0614 - val_mae: 2.9321\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 0.8606 - mae: 0.6671 - val_loss: 19.2585 - val_mae: 3.0447\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 0s 701us/step - loss: 0.8267 - mae: 0.6699 - val_loss: 18.6564 - val_mae: 2.9172\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 704us/step - loss: 0.7318 - mae: 0.6286 - val_loss: 18.3899 - val_mae: 2.9025\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.7971 - mae: 0.6419 - val_loss: 18.2522 - val_mae: 2.8964\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.7666 - mae: 0.6494 - val_loss: 16.9608 - val_mae: 2.8251\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 0.8549 - mae: 0.6382 - val_loss: 18.8874 - val_mae: 2.9301\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.6752 - mae: 0.6130 - val_loss: 20.0116 - val_mae: 3.0383\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 0.8334 - mae: 0.6531 - val_loss: 20.0657 - val_mae: 2.9997\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.8893 - mae: 0.6857 - val_loss: 19.5487 - val_mae: 2.9481\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 0.7751 - mae: 0.6450 - val_loss: 18.6004 - val_mae: 2.9227\n",
      "Epoch 423/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.8041 - mae: 0.6478 - val_loss: 19.3364 - val_mae: 3.0338\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.8793 - mae: 0.7076 - val_loss: 18.4121 - val_mae: 2.9594\n",
      "Epoch 425/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.6691 - mae: 0.6009 - val_loss: 18.4310 - val_mae: 2.9037\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 0.8004 - mae: 0.6162 - val_loss: 19.5279 - val_mae: 3.0452\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.8359 - mae: 0.6530 - val_loss: 17.2547 - val_mae: 2.8170\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.7864 - mae: 0.6390 - val_loss: 20.4173 - val_mae: 3.0260\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 0.7093 - mae: 0.6256 - val_loss: 19.4542 - val_mae: 3.0586\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 0.8430 - mae: 0.6459 - val_loss: 18.5836 - val_mae: 2.8810\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.7263 - mae: 0.6183 - val_loss: 20.3522 - val_mae: 3.0855\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.7168 - mae: 0.6266 - val_loss: 18.5557 - val_mae: 2.9642\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.7322 - mae: 0.6322 - val_loss: 18.5457 - val_mae: 2.9348\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.6751 - mae: 0.6010 - val_loss: 17.4966 - val_mae: 2.7983\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 0.7792 - mae: 0.6116 - val_loss: 17.1694 - val_mae: 2.8058\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.7972 - mae: 0.6062 - val_loss: 18.7480 - val_mae: 2.9447\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.7630 - mae: 0.6242 - val_loss: 17.5392 - val_mae: 2.8460\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 0.7375 - mae: 0.6165 - val_loss: 17.8568 - val_mae: 2.8398\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.7915 - mae: 0.6557 - val_loss: 18.2099 - val_mae: 2.8725\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.7068 - mae: 0.6203 - val_loss: 19.1380 - val_mae: 2.9935\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 0.8407 - mae: 0.6519 - val_loss: 18.3853 - val_mae: 2.8856\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.7450 - mae: 0.6404 - val_loss: 18.5603 - val_mae: 2.8671\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.7478 - mae: 0.6316 - val_loss: 19.9337 - val_mae: 3.0057\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 0s 934us/step - loss: 0.7990 - mae: 0.6411 - val_loss: 18.0210 - val_mae: 2.9197\n",
      "Epoch 445/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.7473 - mae: 0.6272 - val_loss: 18.5907 - val_mae: 2.9027\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 0.7082 - mae: 0.6219 - val_loss: 18.0057 - val_mae: 2.9354\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 0.7210 - mae: 0.6358 - val_loss: 17.1565 - val_mae: 2.8652\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.8340 - mae: 0.6466 - val_loss: 18.5412 - val_mae: 2.8929\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.8262 - mae: 0.6548 - val_loss: 18.1361 - val_mae: 2.9468\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 0s 795us/step - loss: 0.7136 - mae: 0.6243 - val_loss: 17.4068 - val_mae: 2.8537\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 0s 800us/step - loss: 0.8102 - mae: 0.6309 - val_loss: 18.7319 - val_mae: 3.0489\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 0s 780us/step - loss: 0.7345 - mae: 0.6072 - val_loss: 18.7767 - val_mae: 2.9077\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 0s 860us/step - loss: 0.7947 - mae: 0.6392 - val_loss: 17.8687 - val_mae: 2.8438\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 0s 792us/step - loss: 0.7445 - mae: 0.6138 - val_loss: 18.8200 - val_mae: 2.9916\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 0s 796us/step - loss: 0.7038 - mae: 0.6112 - val_loss: 19.0694 - val_mae: 2.9600\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 0s 805us/step - loss: 0.7049 - mae: 0.6076 - val_loss: 19.4208 - val_mae: 2.9813\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 0s 786us/step - loss: 0.8607 - mae: 0.6534 - val_loss: 19.1459 - val_mae: 2.9444\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 0s 752us/step - loss: 0.6842 - mae: 0.6102 - val_loss: 18.6078 - val_mae: 2.9611\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 0s 792us/step - loss: 0.7280 - mae: 0.6163 - val_loss: 18.3400 - val_mae: 2.9455\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 0s 787us/step - loss: 0.7562 - mae: 0.6274 - val_loss: 17.8632 - val_mae: 2.8448\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 0s 753us/step - loss: 0.8001 - mae: 0.6570 - val_loss: 18.4837 - val_mae: 2.9682\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 0s 782us/step - loss: 0.6896 - mae: 0.6104 - val_loss: 16.7156 - val_mae: 2.7639\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 0s 857us/step - loss: 0.6577 - mae: 0.5732 - val_loss: 18.6013 - val_mae: 2.9494\n",
      "Epoch 464/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 0.7703 - mae: 0.6230 - val_loss: 18.8447 - val_mae: 3.0316\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.7579 - mae: 0.6301 - val_loss: 17.9789 - val_mae: 2.9464\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 0s 806us/step - loss: 0.8222 - mae: 0.6201 - val_loss: 18.9468 - val_mae: 2.9499\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 0s 875us/step - loss: 0.6464 - mae: 0.5829 - val_loss: 18.8371 - val_mae: 2.9665\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.7435 - mae: 0.6176 - val_loss: 19.8942 - val_mae: 3.0993\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 0.6612 - mae: 0.6051 - val_loss: 18.0085 - val_mae: 2.8407\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 0.8678 - mae: 0.6687 - val_loss: 18.4529 - val_mae: 2.9027\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.6742 - mae: 0.5954 - val_loss: 18.5993 - val_mae: 3.0099\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 0s 886us/step - loss: 0.7408 - mae: 0.6445 - val_loss: 17.7951 - val_mae: 2.8558\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 0s 744us/step - loss: 0.6614 - mae: 0.5930 - val_loss: 19.5096 - val_mae: 2.9675\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 709us/step - loss: 0.6758 - mae: 0.5854 - val_loss: 19.3334 - val_mae: 3.0248\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 0.6781 - mae: 0.6055 - val_loss: 18.3896 - val_mae: 3.0209\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.7866 - mae: 0.6310 - val_loss: 18.3173 - val_mae: 2.9449\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.7761 - mae: 0.6347 - val_loss: 17.6537 - val_mae: 2.8794\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 0.7168 - mae: 0.6202 - val_loss: 17.2905 - val_mae: 2.7990\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 0.7281 - mae: 0.6059 - val_loss: 18.0198 - val_mae: 2.9087\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 0.7234 - mae: 0.6081 - val_loss: 18.0537 - val_mae: 2.8913\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 0.6847 - mae: 0.5820 - val_loss: 18.6082 - val_mae: 2.9876\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.6818 - mae: 0.6077 - val_loss: 19.8415 - val_mae: 3.0002\n",
      "Epoch 483/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 0.6877 - mae: 0.6185 - val_loss: 18.6306 - val_mae: 2.9675\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.7571 - mae: 0.6198 - val_loss: 18.8409 - val_mae: 2.9960\n",
      "Epoch 485/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 0.6471 - mae: 0.6007 - val_loss: 18.1254 - val_mae: 2.9540\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 0.8156 - mae: 0.6227 - val_loss: 18.4741 - val_mae: 2.9860\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.7273 - mae: 0.6197 - val_loss: 17.6928 - val_mae: 2.9115\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 0.7511 - mae: 0.6475 - val_loss: 19.1580 - val_mae: 2.9975\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 0s 694us/step - loss: 0.6318 - mae: 0.6061 - val_loss: 18.9593 - val_mae: 2.9676\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.7743 - mae: 0.6283 - val_loss: 17.5992 - val_mae: 2.8300\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.7662 - mae: 0.6017 - val_loss: 18.3697 - val_mae: 2.9535\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.7124 - mae: 0.6080 - val_loss: 18.0437 - val_mae: 2.9242\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.6618 - mae: 0.5943 - val_loss: 18.0013 - val_mae: 2.8956\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.6909 - mae: 0.6128 - val_loss: 17.7632 - val_mae: 2.8322\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 0.6552 - mae: 0.6017 - val_loss: 20.2224 - val_mae: 3.0998\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.6218 - mae: 0.5602 - val_loss: 19.4224 - val_mae: 2.9872\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.7851 - mae: 0.6342 - val_loss: 18.0182 - val_mae: 2.9212\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 0.7845 - mae: 0.6052 - val_loss: 18.6868 - val_mae: 2.9356\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.6856 - mae: 0.6067 - val_loss: 18.1623 - val_mae: 2.8764\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.7037 - mae: 0.6222 - val_loss: 18.0296 - val_mae: 2.9565\n",
      "{'val_loss': [34.48767653431301, 24.726490843852655, 18.949961300615183, 18.446380734724617, 17.65671190457121, 19.768194721181793, 16.546463587979492, 16.924730986221878, 18.24519736287622, 17.304644424782694, 14.792976701722047, 15.148300348223177, 14.912810746723288, 14.310886626970081, 15.258051636706645, 15.023042815797362, 15.929658729242425, 15.103113110037174, 15.200788915480342, 15.266697373845163, 14.613058414885954, 16.394093814863833, 14.441292653585286, 14.494624918202252, 13.396668586500898, 14.108940509069564, 14.680616056551756, 14.412179289774688, 14.556293058933296, 15.933086909860888, 13.947128652620341, 14.939310524234351, 13.782247635512267, 15.5718854742246, 13.46701351569569, 13.709572163178807, 13.71162493936871, 14.968515525028538, 13.46772173352339, 13.972200986868149, 14.189810935403267, 13.853603312774506, 13.910387163506913, 13.273939644824482, 14.036294319830596, 14.265987907854452, 13.996856713254871, 16.2466699696811, 15.049330526792575, 14.41420917795688, 14.770520347528423, 13.188709641389819, 14.850690757745697, 13.513310909763016, 14.023808056235632, 15.26093983634042, 15.537828655676032, 14.162015787376552, 14.138098024990235, 13.99121005182664, 15.18683205344449, 15.033768712437523, 14.486771217380227, 14.830976391963565, 14.362198818951043, 15.855918606487622, 13.714458745148143, 13.679562785504224, 15.221936255929725, 14.242218397361942, 15.10586912833537, 14.816131047483783, 15.284050874463352, 16.169573519855945, 15.869408463907087, 15.394956689140653, 15.09622058285761, 14.383076202262673, 15.329687452513152, 15.611501501293112, 14.860392919775897, 15.826562141400236, 15.957487445100474, 16.298380701738125, 16.006593586805526, 16.07265223555672, 15.901070881842136, 17.609760251391844, 15.567214433543526, 16.114592952160585, 15.598170661683872, 17.338225094423, 16.434576780032735, 17.578433431479514, 15.987364249866419, 16.518014725329962, 16.960742300864723, 16.563215265709832, 15.681918473905188, 17.693808116615834, 17.380001051626905, 16.169585418018357, 17.89801841563952, 17.313891919366647, 16.489084778793874, 16.530137108013005, 17.59980632110711, 17.847633337818714, 15.984592690293926, 16.59494201376075, 17.041660093477073, 17.721549872556785, 16.38196432873152, 18.02640259277887, 17.056974811354966, 18.6875817701111, 17.093070697997632, 20.060432641575666, 17.810139649055788, 17.495864221349585, 17.104524262785443, 17.530271445919695, 17.4694418559758, 17.28371278002932, 19.05551621358263, 18.245235699846173, 17.613917942746863, 17.76195348675206, 18.73457012684223, 19.604947112924116, 17.39818213295943, 17.62984570729939, 17.12953251390084, 18.912273295926816, 17.408768197926573, 18.29209643693083, 17.840549279834228, 17.747264441438194, 20.728291752766633, 17.228618995664586, 17.123781634185757, 16.99912024544446, 18.886170330436066, 18.76015316636191, 20.408834831291202, 16.130191755526592, 17.54993817619236, 17.24023933080025, 16.864873451236225, 17.06780005698821, 19.09421587429738, 19.020544775309833, 18.651888010031566, 17.00541295527292, 18.358403046652448, 18.118662001784674, 16.603013286740545, 18.19902232241383, 18.66864577895276, 17.024191934441326, 15.91518607935096, 21.258132362289302, 19.721798282624672, 17.780746429021548, 18.76041768670516, 18.448157737205626, 19.486473700445757, 19.048919362737028, 20.521079676934647, 17.971923747090717, 19.751090852340848, 18.05178788635594, 16.439227687727744, 16.535940071194442, 19.253330794367063, 17.472264880422816, 20.798030186411093, 17.99142846068607, 18.701544078057726, 17.875676056586833, 17.91734109008869, 18.935009752855507, 18.20673322548518, 18.974680727695247, 17.41967435457541, 18.59631251603697, 18.12807523989293, 18.783844364735547, 20.139468055652134, 20.69960568359213, 17.786897071687928, 17.816978803868082, 18.558051926738553, 18.646768504071353, 18.230505207261604, 17.595237630175834, 17.581770258337272, 17.2095820541761, 19.87522999998551, 18.22643429616819, 20.155340499286126, 18.09979196784483, 17.38666355551686, 19.102880000820157, 19.305253816141498, 18.56489266736674, 16.582542113952872, 19.304165832589998, 18.13543802603396, 18.91256916329454, 18.672927584185643, 17.077011638705383, 17.044071584952636, 18.789385871821093, 22.610291719572654, 18.129571716082143, 18.635196838617823, 19.487832255545648, 18.911893848590275, 18.679577003675742, 17.312493605668873, 18.25570037702299, 17.67710631663939, 19.61312719289557, 18.69043483469053, 16.60699195515766, 18.167877934550656, 17.91968133029445, 20.057342133823653, 16.776242768850135, 18.405491525959974, 17.164290231790872, 18.508606496184033, 17.295390541901543, 18.38382754134623, 18.18223490141618, 18.415182022873477, 17.140382018453813, 17.539379974703262, 17.955672231332244, 21.17963747096958, 18.134379635306793, 17.968529059845288, 17.382916296946373, 17.51652968985416, 16.87724155327233, 16.19917605110873, 19.005385972222886, 17.31475681418295, 17.755426931757444, 17.899401156320515, 18.163137229444498, 17.427259848785205, 19.059516216383177, 18.102764154895755, 17.85945683469567, 18.149201295447494, 19.695151728499532, 18.002003074500024, 16.776724570776604, 18.936865853490353, 17.7333317830799, 17.200963369275744, 17.669046631707328, 18.280710129311657, 19.216368936786942, 20.201252417537468, 17.808214944260897, 17.794003575468565, 18.09857186905597, 17.758407535434426, 16.841432397189266, 16.902190435177527, 17.881695994332727, 17.82854000913671, 17.85858112642666, 17.680307657778318, 18.32207120635165, 17.540950147082366, 17.143172547858875, 18.63728274976475, 18.210707191870195, 18.01895048645902, 16.833755201430183, 16.456768376936903, 18.21333293488196, 18.239263853994153, 17.863842730932536, 18.362772593210167, 17.332514841589006, 18.630926326894382, 16.979948482551094, 17.95407695418436, 17.91650283358885, 18.769103121300606, 17.171332305690303, 18.9546724909958, 16.24716318150323, 17.615718336596665, 17.662782269296915, 17.961014244180166, 18.23906947004074, 18.896710838118306, 17.942693488833743, 17.37885383048814, 18.399028444131904, 17.323252346894762, 17.573740031367333, 18.182557701196586, 16.869405936429594, 18.19155195851967, 19.135672466856075, 18.23781819365997, 17.031657516975347, 19.55696651718965, 18.30564348789688, 18.843211319309077, 19.192824628548742, 19.298971943941662, 19.15359256497935, 17.81337068508691, 19.203298564912696, 17.2974355708974, 17.236209253245725, 17.932703216175206, 17.72354203989697, 17.955943872080194, 17.652871630613294, 18.99412632595268, 17.752985295466157, 17.506060263610678, 18.8756196988063, 19.24290891322319, 18.580642666946634, 18.581444738054703, 17.9281966119894, 17.195244641901954, 17.72364558475, 18.688237561970503, 19.485999817602398, 18.933973007793952, 18.1548835087065, 19.31870591035574, 17.97017874270862, 19.038045686934897, 18.594134999909393, 17.15391297175521, 17.420117152569237, 17.848444316314882, 19.11195434444805, 18.505306015051083, 19.24762757366182, 17.31319215855363, 17.59745853754239, 18.180104343017728, 19.35326803997528, 18.103636225055567, 19.628181204264337, 17.530325369540567, 20.054691747882135, 18.873518761615085, 17.508277427376626, 17.73724903175515, 18.466457420300767, 18.75592351983098, 15.998638538092763, 17.50738406466265, 16.881699543106997, 18.63674698678297, 17.42890785623683, 18.16551409426173, 18.064413612602408, 17.280553512191652, 18.279630979463704, 18.42949305052205, 18.034528135046557, 17.373624929339893, 19.160324860704225, 17.891775054345946, 18.84392792416914, 17.68161594422792, 18.35557095072057, 18.240223497066467, 18.371385403779694, 18.14219169291762, 18.476942345058536, 19.241052099217725, 18.78281246130784, 17.749574972441682, 17.73943847174483, 19.553842422208923, 17.867139256803668, 18.63441386948902, 17.000843703199585, 18.4019802821331, 18.28952704087859, 17.573365790257693, 17.36286443804211, 17.945348149125746, 18.191626887763896, 17.397069726445906, 19.63979580536448, 18.305888673428925, 17.368528871481207, 19.724943877776422, 19.591136179261582, 17.592749595347016, 17.61837845821496, 19.301356094658818, 18.903799927157195, 19.308693756460038, 18.061385924176523, 19.258471744135022, 18.65641644693413, 18.38986134196437, 18.252188462927265, 16.96082585973038, 18.887439815235314, 20.011561773970442, 20.065712078500972, 19.548681331964126, 18.600357939004255, 19.336418310273814, 18.412061094421674, 18.430984128358784, 19.527898308649856, 17.254676077753192, 20.417284733705866, 19.45420721705775, 18.583551301736165, 20.35215654550812, 18.555705364098504, 18.545668699269445, 17.49658101989074, 17.16943256870848, 18.74804293849773, 17.53916037619047, 17.85684577901972, 18.20992273316834, 19.138029637774174, 18.38527704026587, 18.560337683019956, 19.933688604595638, 18.020950445213753, 18.59072565776411, 18.005691540241934, 17.156522242930986, 18.541176774096446, 18.136075888578272, 17.406767630805323, 18.731917906119165, 18.77668918515809, 17.868703876271624, 18.819960256429887, 19.069428075003522, 19.42079516500249, 19.145875186004705, 18.60778627902763, 18.340013415386696, 17.86320215635149, 18.483716634378798, 16.715570133960476, 18.601327043286172, 18.844670747537027, 17.978943743107905, 18.946787171914142, 18.83709751257712, 19.894229439310966, 18.008453312811746, 18.452913429531602, 18.599267760411568, 17.795142909441612, 19.50955289734803, 19.33335902371172, 18.389593920265877, 18.31727109700591, 17.65371515137134, 17.29051865779738, 18.01975260611559, 18.05367392693683, 18.60816351456501, 19.84148239600011, 18.630600553443067, 18.840914669664492, 18.12542287195055, 18.474110789991233, 17.69278609342781, 19.157974862673385, 18.959349824724733, 17.599216344245907, 18.369682054530994, 18.043719509445907, 18.001286701768368, 17.763158632740886, 20.222353849420553, 19.422418904050467, 18.01823200576653, 18.686838573296694, 18.162256202964542, 18.02956276600904], 'val_mae': [4.060083389282227, 3.181749105453491, 2.917046546936035, 2.715465784072876, 2.6590523719787598, 2.888761043548584, 2.600802183151245, 2.76889705657959, 2.9492852687835693, 2.9565205574035645, 2.4536590576171875, 2.570052146911621, 2.555616855621338, 2.37174916267395, 2.437380313873291, 2.6460719108581543, 2.5894625186920166, 2.4750797748565674, 2.5013394355773926, 2.607358932495117, 2.4344234466552734, 2.571866989135742, 2.5480005741119385, 2.4618442058563232, 2.3502376079559326, 2.4238884449005127, 2.57694411277771, 2.5375051498413086, 2.572462320327759, 2.6362428665161133, 2.447225332260132, 2.483365058898926, 2.3795039653778076, 2.5221011638641357, 2.377823829650879, 2.3458974361419678, 2.304180145263672, 2.540127992630005, 2.4796788692474365, 2.4131319522857666, 2.5774307250976562, 2.3021554946899414, 2.454268455505371, 2.3078157901763916, 2.5599045753479004, 2.585663080215454, 2.4934279918670654, 2.674945592880249, 2.6658380031585693, 2.506556272506714, 2.534377098083496, 2.4727797508239746, 2.580568552017212, 2.3772833347320557, 2.5186192989349365, 2.762866973876953, 2.609983205795288, 2.4829366207122803, 2.4795773029327393, 2.480506420135498, 2.5499870777130127, 2.580667734146118, 2.6328444480895996, 2.5047996044158936, 2.518568515777588, 2.74074649810791, 2.3812918663024902, 2.4949440956115723, 2.65081524848938, 2.502487897872925, 2.643425703048706, 2.4616780281066895, 2.662105083465576, 2.8224081993103027, 2.8084235191345215, 2.6274213790893555, 2.6491143703460693, 2.5323376655578613, 2.561443328857422, 2.5457301139831543, 2.5073940753936768, 2.6760525703430176, 2.6244213581085205, 2.700697898864746, 2.6859774589538574, 2.5676419734954834, 2.605684995651245, 2.841413736343384, 2.624972105026245, 2.6787898540496826, 2.5909409523010254, 2.761113166809082, 2.6996994018554688, 2.779268264770508, 2.5537848472595215, 2.6721320152282715, 2.701411247253418, 2.6747937202453613, 2.656700849533081, 2.8374483585357666, 2.7467050552368164, 2.6491527557373047, 2.919720411300659, 2.7701005935668945, 2.774432897567749, 2.682771682739258, 2.7717294692993164, 2.7734336853027344, 2.6191225051879883, 2.69201922416687, 2.684877634048462, 2.8511602878570557, 2.636981964111328, 2.7816433906555176, 2.7158713340759277, 2.7853686809539795, 2.693929433822632, 3.005216121673584, 2.7780001163482666, 2.751091718673706, 2.694490671157837, 2.8219852447509766, 2.759406328201294, 2.762953042984009, 2.902336597442627, 2.7423524856567383, 2.7725093364715576, 2.7364368438720703, 2.74530029296875, 2.8371646404266357, 2.76125431060791, 2.701472759246826, 2.651299476623535, 2.8158352375030518, 2.747739791870117, 2.7624030113220215, 2.85067081451416, 2.7158350944519043, 3.000474691390991, 2.5959091186523438, 2.6442625522613525, 2.7220377922058105, 2.8666393756866455, 2.886906147003174, 2.932060718536377, 2.6480562686920166, 2.711475372314453, 2.689617872238159, 2.6426446437835693, 2.671339511871338, 2.7515175342559814, 2.9804980754852295, 2.856419324874878, 2.668797016143799, 2.8214271068573, 2.7151694297790527, 2.598820447921753, 2.7667832374572754, 2.8069560527801514, 2.686305522918701, 2.6627042293548584, 3.2271528244018555, 2.944430112838745, 2.7987208366394043, 2.845219373703003, 2.7924487590789795, 2.9226436614990234, 2.863354444503784, 3.0050787925720215, 2.767993688583374, 3.027092933654785, 2.8412461280822754, 2.6348342895507812, 2.679912567138672, 2.9089155197143555, 2.7564361095428467, 3.059185266494751, 2.744093418121338, 2.893089771270752, 2.861504077911377, 2.751300811767578, 2.8569750785827637, 2.821382999420166, 2.917463541030884, 2.7737460136413574, 2.9041988849639893, 2.7991280555725098, 2.8606622219085693, 3.0293118953704834, 3.0322766304016113, 2.738957166671753, 2.751741886138916, 2.878260850906372, 2.912065029144287, 2.733729600906372, 2.692349910736084, 2.719805955886841, 2.814866065979004, 3.000714063644409, 2.829423427581787, 2.9708828926086426, 2.9116976261138916, 2.6937456130981445, 2.834925889968872, 2.9307405948638916, 2.8865532875061035, 2.630800724029541, 3.0599923133850098, 2.8002126216888428, 3.012662410736084, 2.865844488143921, 2.8551888465881348, 2.7754898071289062, 2.8330881595611572, 3.3524622917175293, 2.8656272888183594, 2.916839361190796, 3.0114364624023438, 2.9473936557769775, 2.8706815242767334, 2.7746899127960205, 2.8576266765594482, 2.8264565467834473, 2.9917571544647217, 2.807211399078369, 2.733328342437744, 2.8120851516723633, 2.8315868377685547, 3.0230653285980225, 2.7824392318725586, 2.9653170108795166, 2.8401894569396973, 2.926219940185547, 2.7866904735565186, 2.8977465629577637, 2.914487361907959, 2.9134697914123535, 2.783344030380249, 2.830047369003296, 2.8915698528289795, 3.2030763626098633, 2.928246021270752, 2.918419361114502, 2.8461008071899414, 2.9630277156829834, 2.774812698364258, 2.634537696838379, 2.995814800262451, 2.8258814811706543, 2.8643412590026855, 2.8379814624786377, 2.9558346271514893, 2.846095323562622, 2.985959529876709, 2.849891185760498, 2.9509711265563965, 2.8786094188690186, 3.0312118530273438, 2.866851568222046, 2.865013837814331, 2.9206202030181885, 2.917832374572754, 2.8196845054626465, 2.9125657081604004, 2.992628335952759, 2.9935801029205322, 3.166626214981079, 2.949836254119873, 2.9067420959472656, 2.9505865573883057, 2.946540355682373, 2.799668788909912, 2.8135666847229004, 2.9059946537017822, 2.9076321125030518, 2.9174373149871826, 2.923543691635132, 3.011552333831787, 2.9076945781707764, 2.8435473442077637, 2.9324793815612793, 2.958409309387207, 2.881855010986328, 2.8183672428131104, 2.7995331287384033, 2.9123198986053467, 2.9428868293762207, 2.9384076595306396, 2.8833885192871094, 2.8276968002319336, 2.98136830329895, 2.856633186340332, 2.9551711082458496, 2.917532444000244, 3.02783203125, 2.9114418029785156, 2.9833173751831055, 2.7833051681518555, 2.8362886905670166, 2.8669049739837646, 2.891089916229248, 2.9608192443847656, 3.019350528717041, 2.90796160697937, 2.8655154705047607, 3.006101608276367, 2.874321937561035, 2.931037187576294, 2.9763853549957275, 2.81014084815979, 2.949455738067627, 3.0551860332489014, 2.913492441177368, 2.892108201980591, 3.000257968902588, 2.989881753921509, 3.0229790210723877, 2.9621121883392334, 3.0356433391571045, 3.0303244590759277, 2.962998390197754, 3.059687614440918, 2.905341148376465, 2.8679897785186768, 2.9122307300567627, 3.000990867614746, 2.8929169178009033, 2.9155209064483643, 3.0563433170318604, 2.9013302326202393, 2.8591392040252686, 2.999844789505005, 2.9269847869873047, 2.9398257732391357, 2.9188902378082275, 2.9103832244873047, 2.839735507965088, 2.871730327606201, 2.9904353618621826, 3.057828903198242, 2.9413533210754395, 2.894907236099243, 3.044844627380371, 2.907036304473877, 2.982175827026367, 2.9396069049835205, 2.8303751945495605, 2.836393117904663, 2.8926515579223633, 2.920257329940796, 2.995197296142578, 3.0263545513153076, 2.9546637535095215, 2.906984329223633, 2.9168601036071777, 3.067404270172119, 2.919663906097412, 3.0386769771575928, 2.8462069034576416, 3.197042942047119, 3.018087863922119, 2.9405429363250732, 2.973590135574341, 3.0542502403259277, 3.0212130546569824, 2.8615028858184814, 2.9269535541534424, 2.8531763553619385, 2.933655023574829, 2.892815113067627, 2.9794251918792725, 2.917656421661377, 2.8250222206115723, 2.9039671421051025, 2.941983699798584, 2.959855794906616, 2.940239667892456, 3.0016627311706543, 2.869171380996704, 2.9359517097473145, 2.8984768390655518, 3.003342628479004, 2.885327100753784, 2.945283889770508, 2.9775896072387695, 2.9636924266815186, 3.1415984630584717, 2.9220995903015137, 2.8432207107543945, 2.8322014808654785, 3.077826976776123, 2.8926243782043457, 2.976191520690918, 2.832304000854492, 2.9099998474121094, 2.946382522583008, 2.8780951499938965, 2.9642014503479004, 2.907538414001465, 2.9091851711273193, 2.863935947418213, 3.0581562519073486, 2.999704599380493, 2.8104426860809326, 3.010854959487915, 2.9845380783081055, 2.871774435043335, 2.8284542560577393, 2.9257068634033203, 3.0216901302337646, 2.9739389419555664, 2.932122230529785, 3.0446925163269043, 2.917210578918457, 2.902458667755127, 2.896440029144287, 2.8250887393951416, 2.9300811290740967, 3.0382518768310547, 2.9997386932373047, 2.948086977005005, 2.922668695449829, 3.033841609954834, 2.9594478607177734, 2.9037346839904785, 3.0452160835266113, 2.8170394897460938, 3.0260093212127686, 3.0586354732513428, 2.8809878826141357, 3.0855259895324707, 2.964163064956665, 2.9347639083862305, 2.7983338832855225, 2.805772304534912, 2.944671392440796, 2.8460237979888916, 2.8398213386535645, 2.8724677562713623, 2.9935224056243896, 2.8855502605438232, 2.86710524559021, 3.005725860595703, 2.919743299484253, 2.902665615081787, 2.9354302883148193, 2.8651938438415527, 2.892888069152832, 2.9467780590057373, 2.8536882400512695, 3.048879861831665, 2.9077260494232178, 2.8438382148742676, 2.9916257858276367, 2.9599945545196533, 2.9812827110290527, 2.944350242614746, 2.961073875427246, 2.9455316066741943, 2.8447751998901367, 2.9681849479675293, 2.7638652324676514, 2.949449300765991, 3.0316085815429688, 2.946427822113037, 2.9499354362487793, 2.9665095806121826, 3.099290370941162, 2.8406949043273926, 2.902729034423828, 3.00992488861084, 2.8557581901550293, 2.967491626739502, 3.0248286724090576, 3.0209240913391113, 2.944916009902954, 2.8793647289276123, 2.7989728450775146, 2.9087071418762207, 2.891309976577759, 2.9875566959381104, 3.0002477169036865, 2.9674556255340576, 2.996014356613159, 2.9540417194366455, 2.9859707355499268, 2.911491870880127, 2.99753737449646, 2.967616081237793, 2.8300421237945557, 2.9534900188446045, 2.9242031574249268, 2.895570993423462, 2.8321824073791504, 3.0997748374938965, 2.987198829650879, 2.921177387237549, 2.935614585876465, 2.876354217529297, 2.9565393924713135], 'loss': [174.8522256689684, 25.973692108111877, 18.65010590365201, 15.969989620383707, 13.750891283915221, 11.993147303519754, 11.766440629225267, 10.90381294934695, 10.395805399354407, 9.98386041968869, 9.739436692278526, 9.114442694338631, 8.967897245654084, 8.688424698043631, 8.326835841666439, 8.16227638143282, 7.744427516215335, 7.521298131807331, 7.5527069768903, 7.176276070653444, 6.898370867967783, 6.953636444993571, 7.075517719666095, 6.935693061704489, 6.662573297394191, 6.8489363748195435, 6.487281636609869, 6.34051652812613, 6.3208100730015495, 6.397080872347924, 5.914889423226029, 6.0668061615308675, 6.049283680373223, 6.034063259025211, 6.050059807423342, 5.845108685603354, 5.699303756170332, 5.647215720283009, 5.730958052681132, 5.608320717346774, 5.71379500323283, 5.609200100625301, 5.6866469426747575, 5.6225413015258185, 5.61724421013744, 5.198213820265508, 4.841056713111864, 5.111443760771226, 5.078452111628367, 4.883717045450857, 4.857467467129675, 4.810378676481369, 4.832058587133817, 4.82920358070872, 4.6943493810138195, 4.5950294041936806, 5.018334246143976, 4.865403488670414, 4.664213654801132, 4.698494864088493, 4.501709474300381, 4.603820070965397, 4.201076529792208, 4.1401085595021785, 4.357782089564587, 4.092327232550701, 4.2214552369771, 4.101966316706407, 3.973575390769346, 4.2807781335248745, 3.6371238647940722, 4.002304626379537, 4.046997615970324, 4.130891630207002, 4.108002083745371, 3.629982632375767, 4.08691226215914, 3.848218756295735, 3.687013539595517, 3.896544998234285, 3.8011708816065526, 3.558046148833317, 3.7174795158335288, 3.461042286342052, 3.369687149048842, 3.5865162962178814, 3.439578725159639, 3.520853035743268, 3.609188428582255, 3.465044560522554, 3.1784062972882063, 3.4091137419764044, 3.2062217975744653, 3.532775204515028, 3.155213414030597, 3.199901402143957, 3.181717067097401, 3.1008115514375123, 3.344464185755893, 2.937095966429537, 3.023846314158621, 3.122298666806678, 2.681890178220063, 3.21029736977948, 2.8084411566429694, 2.9286143410981254, 3.0346348186963117, 2.993753754722558, 2.6363547820838833, 3.034518415950077, 2.7559218613700454, 2.7935849302641036, 2.4180608437951383, 2.777806941951609, 2.6890470902538977, 2.423880475902509, 2.4207811281807565, 2.34516462198567, 2.676569967262682, 2.5638348202233896, 2.39721605699925, 2.5678182862335572, 2.4394080313410664, 2.5041896466281237, 2.690672431186715, 2.4089623384658716, 2.031393244756707, 2.6093832767299965, 2.292380549275768, 2.2625460949322718, 2.4122613093341707, 2.1130959755949035, 2.2386895546700027, 2.1801988586526035, 2.3466111663268143, 2.0839735744144017, 2.225074899937351, 2.4463552626468372, 2.1088308273847662, 2.3805192313377943, 2.32799874434623, 2.252855713424651, 2.140855661504241, 2.1113331055948046, 2.3242486970336325, 2.17296110144314, 1.9335698457068935, 2.188514182187238, 2.138859322111529, 2.2908972808567847, 1.9511059439428449, 1.7556185551066867, 1.8945274009086464, 2.091630861289028, 2.0303083410637477, 2.175251457606329, 1.858467591688534, 1.9691730762636688, 2.0546241743674543, 1.805958386061194, 1.8874233530138131, 1.7514580433933635, 1.9925186557205594, 1.7124783240857178, 1.9778801738626954, 1.805996889926199, 1.7276564522028703, 1.7300424406735102, 1.7829904525089613, 1.7602222600157487, 1.6846299239052327, 1.7075324083495254, 1.8182786506895174, 1.7172948209976096, 1.5721603508299276, 1.9500990218383665, 1.6754796034527064, 1.4941495683230008, 1.750286373883511, 1.5997941878496582, 1.7875074483485955, 1.5254716760599196, 1.794921292827915, 1.6940798738421765, 1.6238730517300313, 1.509600116376244, 1.808642403561829, 1.304653181882182, 1.9689506978408342, 1.4872911224167795, 1.6028281006712302, 1.5120361424558382, 1.600289570309926, 1.5185887750824028, 1.4815178712109651, 1.5541412880689442, 1.6025065905701839, 1.615479474839646, 1.3677471352841448, 1.7288983604273436, 1.3422291807013602, 1.306249383982996, 1.3851808948645514, 1.6346545675602797, 1.4727189868142485, 1.634228721232728, 1.330505347575958, 1.3731229342350224, 1.565799591318369, 1.323174535349218, 1.479098899334738, 1.4250241911045889, 1.4432642919269747, 1.453154973379743, 1.234966996887043, 1.536291269373695, 1.4637590196877077, 1.3546472783186996, 1.447855342929705, 1.4058188374997416, 1.3102700685336135, 1.3981294849375148, 1.3641797584031556, 1.3203656081510033, 1.3225953138935678, 1.413731371287315, 1.360688667277104, 1.3370957332122944, 1.3871951700944054, 1.2601401925912257, 1.3587246244191575, 1.2403642623488034, 1.353654768549724, 1.32818441458831, 1.389438595293919, 1.1989713366075905, 1.2897244399766963, 1.3154053129925616, 1.3392894752260234, 1.3499145943798927, 1.2640481335302136, 1.338713669703451, 1.2429019761440683, 1.2027385813673372, 1.217751876478606, 1.311566765023419, 1.2155733835687277, 1.4055344233952007, 1.2680591274386406, 1.1887131112353289, 1.378288845768327, 1.167026502323322, 1.209382503878845, 1.2196855583087478, 1.2002084987165433, 1.1575930519599358, 1.1774550366118204, 1.039142058485535, 1.2753233841972946, 1.1675462312738967, 1.2412853233584822, 1.253230417465704, 1.1013205805596527, 0.9820383605206864, 1.2696336616328594, 1.1712718283100065, 1.0041349940283397, 1.215963818038521, 1.1841432600441195, 1.1373324172503152, 1.155538477480762, 1.2610613613602981, 1.186597365770434, 1.1208559895199304, 1.1530847178356114, 1.105556104119741, 1.2129084515763469, 1.1904460067868394, 1.1872709706401077, 1.071984267554906, 1.1940854351906147, 0.9933609401341528, 1.2236455179843826, 1.129798754648114, 1.1443164391648228, 1.1847597503393705, 1.116747998588694, 1.0343017214581178, 1.1847603984787933, 0.9371214105170415, 1.010399864124686, 1.2252904981035533, 1.1245041882725206, 1.1074637926488053, 0.9615352499538425, 1.0886280779997095, 1.0840784373131191, 1.021776020846848, 1.1189147461325402, 0.9830463883243361, 1.0705301457388552, 1.0193722449985096, 1.0363941164026917, 0.9672529964592337, 1.1390998542725752, 0.959932006981797, 0.8886694973256147, 0.9459194577754082, 1.0225083397602641, 1.0612257583904974, 1.0232579109257196, 1.0389259915949511, 1.0578747561978803, 0.9922697368820802, 0.9986506235764074, 0.9763318985424481, 0.9842376003273757, 0.9778762440947314, 0.9709659082465156, 1.0496554674625886, 1.0028589588424084, 0.9090830676947673, 0.9299812837321088, 0.9088138861021651, 1.0061046987485007, 0.9436714724189028, 0.8489558261671996, 1.018108734588732, 0.9625246895013676, 0.9249095422726373, 0.881346773907251, 0.978387073284052, 0.8216500505736578, 1.027054342728121, 0.960553140647018, 0.9211446977424322, 1.027588097287566, 0.98572769401269, 0.9878516995210489, 0.9353222595606291, 0.9202441899514399, 1.0451186479608339, 0.8675480323907941, 0.9280638147803546, 0.8963673472160123, 0.9733852149773684, 0.8879286051141937, 0.9601222684951329, 0.8132503624600287, 0.8963877744598703, 0.789015799618325, 0.9163931600228458, 0.8712496104626882, 0.9074303772950612, 0.7912847780880689, 1.0045064624972186, 0.8539939083193261, 0.821591402467789, 0.8629027665540141, 0.9157294822555564, 0.827024793281864, 0.7815298051611037, 0.9010814012093784, 0.8111070990678783, 0.8679847274556702, 0.90119285875791, 0.8455720749415117, 0.8029001919726563, 0.7988667896010541, 0.8917011524446496, 0.8226147615100566, 0.9276179951724345, 0.7594472386642004, 0.8715217780654442, 0.819288345438133, 0.8476094115008627, 0.9236125185714436, 0.7708834806002018, 0.8531484592155058, 0.8197838921054901, 0.7814212331488859, 0.8151689452324388, 0.8369126037869618, 0.8516100791970614, 0.8200439218760907, 0.8111509436956701, 0.872041607663092, 0.8288326053908731, 0.771334704615235, 0.8061721561812867, 0.8206717084095205, 0.7890186912006324, 0.9024793776416629, 0.8705353564341674, 0.8063219355663203, 0.8417600289715548, 0.8209446110344972, 0.8406296814680437, 0.8825949028278617, 0.7901052861139256, 0.8688491385784002, 0.7622029724100898, 0.6986680159275013, 0.8748441597060381, 0.7091773938432213, 0.8737974507367884, 0.7305765566217977, 0.7933611413631442, 0.8594350853168795, 0.829804409259421, 0.7961471168965356, 0.8174121763930646, 0.8605864026918041, 0.8266545573203763, 0.7317590950856311, 0.7971343690474811, 0.7666237749925449, 0.8549191609500538, 0.6752370122816705, 0.8334203743330909, 0.8893267342744354, 0.7750914345161339, 0.8041149098498863, 0.8793310835402369, 0.6690883886362842, 0.8003574519913041, 0.8358974137278079, 0.7864329389114886, 0.7092944853367485, 0.843027488298212, 0.726263765012077, 0.7167864931335878, 0.7321741636191496, 0.6750540704180743, 0.7791876947266705, 0.7972021934534022, 0.7630310590934266, 0.7374833360034113, 0.7914817849963427, 0.7067833072516096, 0.840741984252949, 0.745049738754223, 0.7477844971584994, 0.7990078839601104, 0.7473460702006951, 0.7082048740300073, 0.7210072143530287, 0.833952708377783, 0.82620079855042, 0.7135679628013605, 0.810171445668932, 0.7345281053806115, 0.7947178224610307, 0.7445475224860046, 0.7037890408266604, 0.704871863448914, 0.8607482323799313, 0.6842178019116077, 0.7279664715929463, 0.7561739795045388, 0.8001161295028261, 0.6896078340135441, 0.6576898324468371, 0.77031546988174, 0.7579352856381874, 0.8221732378966534, 0.6463651455429145, 0.7435327330477887, 0.6611691319048386, 0.8678082097779708, 0.674231769665921, 0.7408426593494201, 0.6614417065045796, 0.6758047236992695, 0.6781282054317842, 0.786556815831249, 0.7760631161627226, 0.7167687365578542, 0.7280630445603093, 0.7234060622880285, 0.6847082145263257, 0.6818064873454319, 0.6876581217266263, 0.7571122667346217, 0.6471257027742017, 0.8156104268489246, 0.7273357412913996, 0.7510656378683844, 0.6318310294991893, 0.7743151779625748, 0.7661912354493751, 0.7124295413650753, 0.6617632553161786, 0.6908724359898097, 0.6551614829609882, 0.621787374920747, 0.7850891057023186, 0.7845220229707409, 0.6855566880546663, 0.7036529693159237], 'mae': [9.778637, 3.5893793, 2.9260783, 2.7430363, 2.540137, 2.4081168, 2.3351703, 2.270893, 2.2573695, 2.133479, 2.1705832, 2.1272938, 2.0653439, 2.039254, 2.0238395, 1.9429432, 1.9673404, 1.9014084, 1.92991, 1.9147692, 1.9069436, 1.8628484, 1.8362103, 1.8300556, 1.7817074, 1.8683014, 1.7728736, 1.7664279, 1.76393, 1.7384351, 1.7186388, 1.6712708, 1.7162753, 1.7130611, 1.7199953, 1.6820312, 1.6523292, 1.7188737, 1.5891604, 1.6353492, 1.6270249, 1.6603446, 1.6401578, 1.5363796, 1.6393248, 1.5420105, 1.591418, 1.529742, 1.5632061, 1.529002, 1.5633899, 1.5284436, 1.517912, 1.5058234, 1.5488698, 1.5294603, 1.5426141, 1.5342116, 1.425294, 1.5068302, 1.5150952, 1.5254967, 1.4643879, 1.4498522, 1.4488788, 1.3890705, 1.4490912, 1.3820025, 1.4032555, 1.4392408, 1.3695467, 1.3617569, 1.4237134, 1.3839512, 1.4306213, 1.3936181, 1.431602, 1.3770808, 1.4085965, 1.3855903, 1.4110448, 1.3940276, 1.3694127, 1.3318977, 1.3300189, 1.359126, 1.3064924, 1.3322854, 1.356448, 1.3460634, 1.3091593, 1.3080939, 1.3516966, 1.3186877, 1.2680606, 1.3203778, 1.2575152, 1.3047495, 1.2658856, 1.2604038, 1.2521125, 1.2451205, 1.1863548, 1.2983692, 1.2151186, 1.2410126, 1.2312738, 1.2305635, 1.179655, 1.2514739, 1.2356893, 1.1870224, 1.1590631, 1.2518536, 1.1440376, 1.1596671, 1.1571728, 1.1255448, 1.1991216, 1.1792885, 1.1542616, 1.1858578, 1.1214511, 1.1848983, 1.1865954, 1.1124787, 1.0608177, 1.1870549, 1.1118475, 1.1153407, 1.0970399, 1.0889156, 1.1038431, 1.0805777, 1.1020896, 1.0340798, 1.0989327, 1.1508954, 1.0301948, 1.1220874, 1.1281455, 1.0863883, 1.031059, 1.0590837, 1.1105635, 1.0693338, 1.0290377, 1.0146526, 1.0483423, 1.1251565, 1.0097041, 0.9849354, 1.006738, 1.0603299, 1.0016829, 1.0454228, 0.9970227, 1.0483497, 1.0006727, 0.9864677, 1.0034119, 0.9985269, 1.0393394, 0.94867164, 1.027346, 0.9546659, 0.96706194, 0.9914225, 0.978346, 0.9685044, 0.92974895, 0.94921553, 1.0125322, 0.9607747, 0.9494442, 1.0024085, 0.92031157, 0.9134412, 0.9272842, 0.93098235, 0.9707954, 0.9119168, 0.99564666, 0.9308254, 0.9549629, 0.9130811, 0.9638115, 0.85578924, 1.0003818, 0.89934194, 0.9003157, 0.89704275, 0.9512887, 0.89282125, 0.9012028, 0.93250924, 0.91695756, 0.9245251, 0.850553, 0.9452867, 0.87524533, 0.8596549, 0.8730886, 0.90781283, 0.85894495, 0.91039425, 0.8562629, 0.8585084, 0.9271375, 0.881028, 0.8699818, 0.8614484, 0.8769293, 0.8928804, 0.8517184, 0.91079986, 0.86804825, 0.8314983, 0.8811159, 0.8917065, 0.847959, 0.85855013, 0.86137867, 0.854167, 0.79632455, 0.85472745, 0.846662, 0.8370759, 0.87654096, 0.8135786, 0.8560926, 0.8121981, 0.8445002, 0.82917213, 0.8474415, 0.81017476, 0.82145065, 0.8168603, 0.8451839, 0.8381963, 0.8308783, 0.80563295, 0.81080955, 0.78484315, 0.80079824, 0.8296332, 0.8058093, 0.82204837, 0.7810964, 0.7894662, 0.8148871, 0.75009334, 0.8175014, 0.79494244, 0.8025521, 0.78668904, 0.7992596, 0.7488299, 0.81643426, 0.8036194, 0.8326409, 0.803047, 0.77562463, 0.7469509, 0.83716446, 0.7790577, 0.7200857, 0.798182, 0.79039735, 0.7787273, 0.79079145, 0.81403124, 0.8162368, 0.7577307, 0.7636422, 0.78998876, 0.8080789, 0.80653816, 0.7993921, 0.77091604, 0.78814524, 0.7151562, 0.8090935, 0.75111014, 0.76690155, 0.8077238, 0.7698193, 0.75221336, 0.78474224, 0.7075242, 0.7474854, 0.7932757, 0.7645197, 0.74511486, 0.7141433, 0.7558886, 0.75400513, 0.7508584, 0.7840607, 0.72604746, 0.7458356, 0.70897186, 0.73918855, 0.70979697, 0.7521981, 0.71471405, 0.7018383, 0.7204154, 0.7464384, 0.7188395, 0.71389616, 0.75528175, 0.7633964, 0.6972268, 0.70876735, 0.7272883, 0.7355491, 0.72380817, 0.7381137, 0.7402009, 0.69786817, 0.68084586, 0.7137432, 0.6917733, 0.7356173, 0.7043163, 0.697787, 0.7711742, 0.7075715, 0.6834241, 0.72482055, 0.71423995, 0.668015, 0.7353727, 0.72699803, 0.70397353, 0.73857796, 0.69601834, 0.6923337, 0.68171614, 0.69235903, 0.73384637, 0.7330803, 0.70307684, 0.7051057, 0.7197303, 0.67944396, 0.68467957, 0.6631647, 0.71538717, 0.67514837, 0.6987868, 0.66440046, 0.6896667, 0.6479279, 0.70979, 0.68269, 0.64390737, 0.6688877, 0.6866733, 0.68428606, 0.6464585, 0.6991526, 0.6929305, 0.6580907, 0.69406897, 0.6722662, 0.6599556, 0.6374756, 0.6874106, 0.6605364, 0.6827302, 0.6616865, 0.66578215, 0.6477085, 0.6643331, 0.68207407, 0.647006, 0.6601468, 0.6883755, 0.65977913, 0.661767, 0.6645572, 0.6256245, 0.6562278, 0.6506601, 0.68086416, 0.65645, 0.6618048, 0.6675936, 0.66642386, 0.65924037, 0.6623376, 0.67425585, 0.66671413, 0.6362462, 0.6481029, 0.6606905, 0.6666628, 0.6225216, 0.68794405, 0.65848196, 0.6130152, 0.69639874, 0.61993426, 0.70235395, 0.6077519, 0.6363701, 0.65761775, 0.6466393, 0.6459142, 0.6488284, 0.66711587, 0.6699078, 0.62861246, 0.64187455, 0.64935917, 0.63822263, 0.6130083, 0.65314543, 0.6856681, 0.6450242, 0.6478158, 0.7076024, 0.6008908, 0.6162172, 0.65302426, 0.63904715, 0.6255852, 0.6459226, 0.6183477, 0.62663615, 0.6322137, 0.60103494, 0.6115635, 0.60620797, 0.6242197, 0.6164607, 0.65568066, 0.6203418, 0.6518821, 0.6404121, 0.63161623, 0.6410893, 0.6272046, 0.6219284, 0.6357924, 0.6466417, 0.65475434, 0.6242856, 0.63093454, 0.60724366, 0.6392417, 0.6138296, 0.6112354, 0.60763353, 0.6533597, 0.61022216, 0.616327, 0.627414, 0.65703714, 0.61037755, 0.5731558, 0.62296164, 0.6301325, 0.62006754, 0.58285695, 0.61755234, 0.6051207, 0.6687327, 0.5954292, 0.6445228, 0.592987, 0.585401, 0.60554206, 0.6309821, 0.6346674, 0.62018925, 0.6058662, 0.6080573, 0.5820337, 0.60765725, 0.6184547, 0.61979467, 0.60070145, 0.6227185, 0.6196527, 0.6474602, 0.60610014, 0.62828857, 0.60168046, 0.60803825, 0.5942567, 0.612768, 0.60170174, 0.56018156, 0.63416725, 0.6051722, 0.60669225, 0.6221818]}\n",
      "processing fold # 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 202.2230 - mae: 10.5519 - val_loss: 65.2403 - val_mae: 5.5408\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 30.7250 - mae: 3.6685 - val_loss: 35.7034 - val_mae: 4.0402\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 0s 701us/step - loss: 21.1670 - mae: 3.0299 - val_loss: 30.3265 - val_mae: 3.5898\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 18.0429 - mae: 2.8030 - val_loss: 25.2920 - val_mae: 3.3016\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 16.0906 - mae: 2.5279 - val_loss: 26.7563 - val_mae: 3.1479\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 14.2043 - mae: 2.4058 - val_loss: 20.6798 - val_mae: 2.7988\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 13.2277 - mae: 2.3295 - val_loss: 21.1932 - val_mae: 2.8949\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 12.5822 - mae: 2.2957 - val_loss: 18.4376 - val_mae: 2.7288\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 11.8625 - mae: 2.2189 - val_loss: 17.1050 - val_mae: 2.6409\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 11.4177 - mae: 2.2059 - val_loss: 16.7305 - val_mae: 2.5894\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 10.8741 - mae: 2.1208 - val_loss: 18.6738 - val_mae: 2.7101\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 10.3608 - mae: 2.1281 - val_loss: 15.5180 - val_mae: 2.5177\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 10.0799 - mae: 2.0581 - val_loss: 19.1556 - val_mae: 2.8863\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 10.1530 - mae: 2.0453 - val_loss: 15.2897 - val_mae: 2.5244\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 9.7691 - mae: 2.0267 - val_loss: 13.8883 - val_mae: 2.4855\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 0s 760us/step - loss: 9.3979 - mae: 1.9581 - val_loss: 19.1859 - val_mae: 3.0301\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 9.9308 - mae: 1.9955 - val_loss: 14.2136 - val_mae: 2.4269\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 9.2533 - mae: 1.9887 - val_loss: 13.8489 - val_mae: 2.4940\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 8.4173 - mae: 1.9455 - val_loss: 15.7637 - val_mae: 2.6752\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 8.5222 - mae: 1.9401 - val_loss: 14.2958 - val_mae: 2.4917\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 8.6298 - mae: 1.9464 - val_loss: 13.6023 - val_mae: 2.4583\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 8.4147 - mae: 1.8677 - val_loss: 13.9875 - val_mae: 2.4978\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 8.3255 - mae: 1.8813 - val_loss: 14.7821 - val_mae: 2.7491\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 8.1867 - mae: 1.8553 - val_loss: 14.9808 - val_mae: 2.7080\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 8.2295 - mae: 1.8386 - val_loss: 12.8919 - val_mae: 2.4301\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 7.9029 - mae: 1.8088 - val_loss: 13.8884 - val_mae: 2.4838\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 7.6110 - mae: 1.7700 - val_loss: 13.2995 - val_mae: 2.5148\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 7.4297 - mae: 1.7500 - val_loss: 12.6130 - val_mae: 2.4030\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 7.4467 - mae: 1.7968 - val_loss: 12.7165 - val_mae: 2.4151\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 7.0990 - mae: 1.7515 - val_loss: 14.7263 - val_mae: 2.6472\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 7.4464 - mae: 1.7966 - val_loss: 12.4030 - val_mae: 2.4071\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 7.1151 - mae: 1.7371 - val_loss: 13.4548 - val_mae: 2.5138\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 7.1025 - mae: 1.7788 - val_loss: 11.6746 - val_mae: 2.3579\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 7.0977 - mae: 1.7883 - val_loss: 12.6947 - val_mae: 2.4803\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 7.2467 - mae: 1.7546 - val_loss: 11.9694 - val_mae: 2.3694\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 6.9275 - mae: 1.7030 - val_loss: 14.6032 - val_mae: 2.7173\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 6.7289 - mae: 1.6646 - val_loss: 11.4892 - val_mae: 2.3509\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 6.4737 - mae: 1.5901 - val_loss: 13.7600 - val_mae: 2.6493\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 6.7477 - mae: 1.6955 - val_loss: 11.4547 - val_mae: 2.3368\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 6.5971 - mae: 1.6245 - val_loss: 13.6561 - val_mae: 2.7198\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 6.0500 - mae: 1.5817 - val_loss: 12.8299 - val_mae: 2.5554\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 6.1355 - mae: 1.6228 - val_loss: 11.6025 - val_mae: 2.4143\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 6.1860 - mae: 1.5696 - val_loss: 13.2691 - val_mae: 2.6604\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 6.3425 - mae: 1.6213 - val_loss: 13.2330 - val_mae: 2.6216\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 6.4231 - mae: 1.5870 - val_loss: 11.5414 - val_mae: 2.3741\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 5.9468 - mae: 1.6384 - val_loss: 12.9921 - val_mae: 2.6513\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 6.2305 - mae: 1.6289 - val_loss: 12.6900 - val_mae: 2.5864\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 6.2929 - mae: 1.5845 - val_loss: 11.7058 - val_mae: 2.3968\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 5.9316 - mae: 1.5838 - val_loss: 12.2388 - val_mae: 2.4960\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 5.7929 - mae: 1.5536 - val_loss: 12.2060 - val_mae: 2.5106\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 0s 749us/step - loss: 6.1392 - mae: 1.5541 - val_loss: 11.3169 - val_mae: 2.4273\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 5.8745 - mae: 1.5040 - val_loss: 12.1320 - val_mae: 2.4306\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 5.7408 - mae: 1.5681 - val_loss: 11.1640 - val_mae: 2.4158\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 5.4525 - mae: 1.4936 - val_loss: 12.1266 - val_mae: 2.5626\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 5.3826 - mae: 1.5615 - val_loss: 13.2822 - val_mae: 2.6166\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 5.4472 - mae: 1.5312 - val_loss: 10.7176 - val_mae: 2.2090\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 5.6237 - mae: 1.4941 - val_loss: 13.4336 - val_mae: 2.5995\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 5.8075 - mae: 1.4801 - val_loss: 12.1528 - val_mae: 2.4629\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 5.3747 - mae: 1.5052 - val_loss: 14.7244 - val_mae: 2.9014\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 720us/step - loss: 5.6209 - mae: 1.5193 - val_loss: 10.8582 - val_mae: 2.2975\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 5.4356 - mae: 1.5164 - val_loss: 10.8097 - val_mae: 2.2680\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 5.0691 - mae: 1.4812 - val_loss: 11.8248 - val_mae: 2.4080\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 5.1127 - mae: 1.4970 - val_loss: 13.3448 - val_mae: 2.6007\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 5.4268 - mae: 1.4613 - val_loss: 10.6877 - val_mae: 2.2890\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 4.9675 - mae: 1.4416 - val_loss: 10.5728 - val_mae: 2.2737\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 5.0313 - mae: 1.4633 - val_loss: 11.5365 - val_mae: 2.4948\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 5.1845 - mae: 1.4552 - val_loss: 11.3474 - val_mae: 2.3399\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 5.1600 - mae: 1.4720 - val_loss: 10.7338 - val_mae: 2.3769\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 5.0884 - mae: 1.4822 - val_loss: 10.5963 - val_mae: 2.1750\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 5.2768 - mae: 1.4749 - val_loss: 10.8251 - val_mae: 2.3070\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 4.9695 - mae: 1.5091 - val_loss: 11.4911 - val_mae: 2.3477\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 4.9595 - mae: 1.4174 - val_loss: 11.0631 - val_mae: 2.3348\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 5.1851 - mae: 1.4311 - val_loss: 10.9381 - val_mae: 2.3168\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 5.0376 - mae: 1.4006 - val_loss: 10.8549 - val_mae: 2.2398\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 4.7756 - mae: 1.4229 - val_loss: 11.5281 - val_mae: 2.3393\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 4.8066 - mae: 1.3875 - val_loss: 13.1441 - val_mae: 2.4813\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 4.9090 - mae: 1.4576 - val_loss: 10.7448 - val_mae: 2.2172\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 4.7568 - mae: 1.4467 - val_loss: 12.2867 - val_mae: 2.4063\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 4.6930 - mae: 1.3956 - val_loss: 11.5291 - val_mae: 2.4670\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 4.5534 - mae: 1.3877 - val_loss: 11.4286 - val_mae: 2.4875\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 4.4899 - mae: 1.3448 - val_loss: 10.9110 - val_mae: 2.3801\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 4.4116 - mae: 1.4385 - val_loss: 13.1249 - val_mae: 2.6229\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 4.4517 - mae: 1.3962 - val_loss: 12.0312 - val_mae: 2.3875\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 4.6533 - mae: 1.3765 - val_loss: 11.2611 - val_mae: 2.3596\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 4.3401 - mae: 1.3949 - val_loss: 10.9250 - val_mae: 2.2504\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 0s 749us/step - loss: 4.6431 - mae: 1.3760 - val_loss: 11.4936 - val_mae: 2.3611\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 3.9731 - mae: 1.3655 - val_loss: 14.7261 - val_mae: 2.6965\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 4.5106 - mae: 1.4370 - val_loss: 10.9887 - val_mae: 2.4189\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 4.0837 - mae: 1.2826 - val_loss: 12.9308 - val_mae: 2.6169\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 4.3296 - mae: 1.3274 - val_loss: 11.5251 - val_mae: 2.4006\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 4.4038 - mae: 1.3571 - val_loss: 11.2100 - val_mae: 2.3794\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 4.2483 - mae: 1.3086 - val_loss: 11.1426 - val_mae: 2.4438\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 4.3997 - mae: 1.3742 - val_loss: 11.5882 - val_mae: 2.3954\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 4.0423 - mae: 1.3497 - val_loss: 11.1597 - val_mae: 2.3677\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 4.2762 - mae: 1.3060 - val_loss: 10.6327 - val_mae: 2.2733\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 4.1149 - mae: 1.3227 - val_loss: 10.9742 - val_mae: 2.3428\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 4.1131 - mae: 1.3303 - val_loss: 11.9510 - val_mae: 2.5286\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 4.1180 - mae: 1.3467 - val_loss: 12.1129 - val_mae: 2.4337\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 3.9930 - mae: 1.3496 - val_loss: 11.5506 - val_mae: 2.3046\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 3.7620 - mae: 1.2879 - val_loss: 11.0584 - val_mae: 2.3705\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 0s 728us/step - loss: 4.0822 - mae: 1.3053 - val_loss: 12.4876 - val_mae: 2.4337\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 4.0925 - mae: 1.2650 - val_loss: 11.0846 - val_mae: 2.2723\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 0s 886us/step - loss: 4.1039 - mae: 1.2818 - val_loss: 11.1646 - val_mae: 2.2751\n",
      "Epoch 104/500\n",
      "303/303 [==============================] - 0s 849us/step - loss: 3.7019 - mae: 1.2469 - val_loss: 11.6168 - val_mae: 2.3319\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 3.9466 - mae: 1.3091 - val_loss: 11.9891 - val_mae: 2.3571\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 3.9099 - mae: 1.2951 - val_loss: 10.8771 - val_mae: 2.2620\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 3.9225 - mae: 1.2799 - val_loss: 11.5119 - val_mae: 2.3675\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 3.9575 - mae: 1.3064 - val_loss: 11.6621 - val_mae: 2.4077\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 3.9829 - mae: 1.2875 - val_loss: 11.5718 - val_mae: 2.4778\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 3.9119 - mae: 1.2749 - val_loss: 10.9435 - val_mae: 2.2151\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 3.8741 - mae: 1.2860 - val_loss: 11.6947 - val_mae: 2.2995\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 3.7579 - mae: 1.2615 - val_loss: 11.6256 - val_mae: 2.2907\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 3.5871 - mae: 1.2187 - val_loss: 11.6812 - val_mae: 2.3608\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 4.0151 - mae: 1.2310 - val_loss: 12.4658 - val_mae: 2.6179\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 3.5070 - mae: 1.2297 - val_loss: 10.6274 - val_mae: 2.2337\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 3.8699 - mae: 1.2168 - val_loss: 11.1833 - val_mae: 2.3565\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 3.7780 - mae: 1.2684 - val_loss: 11.4062 - val_mae: 2.4174\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 3.8848 - mae: 1.2447 - val_loss: 10.8637 - val_mae: 2.2798\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 3.8086 - mae: 1.2780 - val_loss: 12.2010 - val_mae: 2.3934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "303/303 [==============================] - 0s 704us/step - loss: 3.9661 - mae: 1.2388 - val_loss: 12.9373 - val_mae: 2.6818\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 3.6696 - mae: 1.2156 - val_loss: 13.8248 - val_mae: 2.6500\n",
      "Epoch 122/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 3.5644 - mae: 1.2445 - val_loss: 12.3815 - val_mae: 2.5952\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 3.6814 - mae: 1.2313 - val_loss: 11.4989 - val_mae: 2.3686\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 3.8022 - mae: 1.2060 - val_loss: 11.3437 - val_mae: 2.3393\n",
      "Epoch 125/500\n",
      "303/303 [==============================] - 0s 760us/step - loss: 3.4231 - mae: 1.2033 - val_loss: 11.0531 - val_mae: 2.2666\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 0s 759us/step - loss: 3.7397 - mae: 1.1887 - val_loss: 11.5613 - val_mae: 2.3140\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 3.4591 - mae: 1.1509 - val_loss: 11.0822 - val_mae: 2.3569\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 3.6476 - mae: 1.1786 - val_loss: 11.2011 - val_mae: 2.2552\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 3.6820 - mae: 1.2105 - val_loss: 12.1084 - val_mae: 2.3847\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 0s 738us/step - loss: 3.6624 - mae: 1.2246 - val_loss: 12.3419 - val_mae: 2.4778\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 3.5551 - mae: 1.1939 - val_loss: 12.3818 - val_mae: 2.4011\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 3.5632 - mae: 1.1600 - val_loss: 11.7162 - val_mae: 2.3798\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 3.5729 - mae: 1.1933 - val_loss: 14.2855 - val_mae: 2.6730\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 3.4685 - mae: 1.1540 - val_loss: 11.8953 - val_mae: 2.3726\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 3.3340 - mae: 1.2062 - val_loss: 11.1834 - val_mae: 2.3086\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 3.5824 - mae: 1.1459 - val_loss: 12.4368 - val_mae: 2.4654\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 3.4328 - mae: 1.1857 - val_loss: 11.0435 - val_mae: 2.3776\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 3.3454 - mae: 1.1429 - val_loss: 14.4483 - val_mae: 2.6422\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 3.2149 - mae: 1.1834 - val_loss: 11.3001 - val_mae: 2.2976\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 3.6431 - mae: 1.1834 - val_loss: 12.6705 - val_mae: 2.4771\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 3.2005 - mae: 1.1141 - val_loss: 13.4621 - val_mae: 2.6688\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 3.6654 - mae: 1.1618 - val_loss: 11.4340 - val_mae: 2.2852\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 3.3038 - mae: 1.1780 - val_loss: 11.7972 - val_mae: 2.4353\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 3.3643 - mae: 1.2010 - val_loss: 12.3868 - val_mae: 2.4072\n",
      "Epoch 145/500\n",
      "303/303 [==============================] - 0s 831us/step - loss: 3.3575 - mae: 1.1810 - val_loss: 12.4204 - val_mae: 2.4144\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 0s 748us/step - loss: 3.2851 - mae: 1.1154 - val_loss: 13.1249 - val_mae: 2.4982\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 3.2244 - mae: 1.1067 - val_loss: 12.7047 - val_mae: 2.4909\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 3.2337 - mae: 1.1604 - val_loss: 12.4019 - val_mae: 2.4049\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 3.2662 - mae: 1.1376 - val_loss: 15.2389 - val_mae: 2.7984\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 3.3176 - mae: 1.1592 - val_loss: 12.0116 - val_mae: 2.3556\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 0s 870us/step - loss: 3.0206 - mae: 1.1583 - val_loss: 11.4216 - val_mae: 2.2717\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 0s 927us/step - loss: 3.2714 - mae: 1.1308 - val_loss: 12.1339 - val_mae: 2.4615\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 0s 790us/step - loss: 3.1476 - mae: 1.1574 - val_loss: 12.3137 - val_mae: 2.4000\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 0s 892us/step - loss: 3.1856 - mae: 1.1216 - val_loss: 12.9976 - val_mae: 2.4936\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 0s 778us/step - loss: 3.1527 - mae: 1.1372 - val_loss: 12.9759 - val_mae: 2.5933\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 0s 785us/step - loss: 3.0847 - mae: 1.1339 - val_loss: 13.3887 - val_mae: 2.5423\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 3.0623 - mae: 1.1271 - val_loss: 13.3162 - val_mae: 2.4822\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 3.3073 - mae: 1.1989 - val_loss: 12.6443 - val_mae: 2.4586\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 3.1798 - mae: 1.1066 - val_loss: 12.2923 - val_mae: 2.4324\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 0s 914us/step - loss: 2.8994 - mae: 1.0737 - val_loss: 12.7133 - val_mae: 2.5759\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 2.9003 - mae: 1.1198 - val_loss: 12.3283 - val_mae: 2.4096\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 0s 912us/step - loss: 3.2853 - mae: 1.1509 - val_loss: 12.6447 - val_mae: 2.4157\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 0s 753us/step - loss: 2.8355 - mae: 1.1126 - val_loss: 14.5249 - val_mae: 2.8449\n",
      "Epoch 164/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 3.0481 - mae: 1.1157 - val_loss: 12.1711 - val_mae: 2.3550\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 3.1610 - mae: 1.0891 - val_loss: 13.2150 - val_mae: 2.4682\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 2.8097 - mae: 1.1418 - val_loss: 11.8632 - val_mae: 2.3534\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 2.8259 - mae: 1.0790 - val_loss: 13.3853 - val_mae: 2.5765\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 2.9002 - mae: 1.1087 - val_loss: 12.2072 - val_mae: 2.4664\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 2.9917 - mae: 1.1215 - val_loss: 12.9987 - val_mae: 2.5340\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 2.6746 - mae: 1.0710 - val_loss: 12.5984 - val_mae: 2.4758\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 2.9545 - mae: 1.0446 - val_loss: 12.8251 - val_mae: 2.5566\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 3.0476 - mae: 1.1236 - val_loss: 13.2546 - val_mae: 2.6229\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 3.0021 - mae: 1.1102 - val_loss: 12.8361 - val_mae: 2.4837\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 2.9162 - mae: 1.0332 - val_loss: 13.5311 - val_mae: 2.5621\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 2.8590 - mae: 1.0435 - val_loss: 13.2108 - val_mae: 2.5029\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 3.1080 - mae: 1.0579 - val_loss: 11.9560 - val_mae: 2.3532\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 2.8757 - mae: 1.0965 - val_loss: 13.8471 - val_mae: 2.5440\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 2.7686 - mae: 1.0480 - val_loss: 14.4874 - val_mae: 2.7798\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 725us/step - loss: 2.8855 - mae: 1.1055 - val_loss: 11.9174 - val_mae: 2.3723\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 2.9300 - mae: 1.0734 - val_loss: 12.8378 - val_mae: 2.4408\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 2.9598 - mae: 1.0789 - val_loss: 11.4882 - val_mae: 2.3314\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 2.4366 - mae: 1.0667 - val_loss: 15.7268 - val_mae: 2.8936\n",
      "Epoch 183/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 2.7640 - mae: 1.1073 - val_loss: 13.4729 - val_mae: 2.5091\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 0s 761us/step - loss: 2.7769 - mae: 1.0979 - val_loss: 12.6120 - val_mae: 2.5585\n",
      "Epoch 185/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 2.8543 - mae: 1.1016 - val_loss: 13.2380 - val_mae: 2.4969\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 0s 753us/step - loss: 2.6720 - mae: 1.0556 - val_loss: 13.0542 - val_mae: 2.4909\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 0s 751us/step - loss: 2.7683 - mae: 1.0496 - val_loss: 13.3413 - val_mae: 2.4855\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 0s 816us/step - loss: 2.8829 - mae: 1.1256 - val_loss: 12.7185 - val_mae: 2.4640\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 0s 760us/step - loss: 2.4668 - mae: 1.0673 - val_loss: 12.3576 - val_mae: 2.3570\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 0s 832us/step - loss: 2.4985 - mae: 1.0337 - val_loss: 12.7176 - val_mae: 2.4195\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 0s 875us/step - loss: 2.7397 - mae: 1.0722 - val_loss: 12.8308 - val_mae: 2.5184\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 0s 736us/step - loss: 2.7934 - mae: 1.0841 - val_loss: 13.3219 - val_mae: 2.5515\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 0s 841us/step - loss: 2.4841 - mae: 1.1090 - val_loss: 12.7734 - val_mae: 2.4669\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 0s 887us/step - loss: 2.4943 - mae: 1.0468 - val_loss: 12.7569 - val_mae: 2.5074\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 0s 699us/step - loss: 2.6849 - mae: 1.0864 - val_loss: 12.6505 - val_mae: 2.4692\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 2.4436 - mae: 1.0164 - val_loss: 12.6545 - val_mae: 2.4405\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 0s 700us/step - loss: 3.0038 - mae: 1.1242 - val_loss: 13.1291 - val_mae: 2.5601\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 0s 778us/step - loss: 2.6386 - mae: 1.0982 - val_loss: 12.9809 - val_mae: 2.5713\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 0s 927us/step - loss: 2.8450 - mae: 1.0938 - val_loss: 13.4725 - val_mae: 2.5913\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 0s 749us/step - loss: 2.7238 - mae: 1.0573 - val_loss: 14.0154 - val_mae: 2.7236\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 0s 768us/step - loss: 2.5249 - mae: 1.0231 - val_loss: 13.7162 - val_mae: 2.5520\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 2.6043 - mae: 1.0483 - val_loss: 12.9856 - val_mae: 2.5073\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 0s 946us/step - loss: 2.6484 - mae: 1.0457 - val_loss: 13.9052 - val_mae: 2.6335\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 0s 793us/step - loss: 2.4183 - mae: 1.0291 - val_loss: 14.1542 - val_mae: 2.6190\n",
      "Epoch 205/500\n",
      "303/303 [==============================] - 0s 823us/step - loss: 2.6698 - mae: 1.0215 - val_loss: 13.5821 - val_mae: 2.5743\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 0s 788us/step - loss: 2.7818 - mae: 1.0623 - val_loss: 13.4659 - val_mae: 2.5127\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 0s 891us/step - loss: 2.4618 - mae: 1.0225 - val_loss: 20.6715 - val_mae: 3.5343\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 0s 801us/step - loss: 2.4619 - mae: 1.0316 - val_loss: 13.7053 - val_mae: 2.6068\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 2.4604 - mae: 1.0385 - val_loss: 12.9559 - val_mae: 2.4342\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 0s 883us/step - loss: 2.4038 - mae: 1.0594 - val_loss: 14.2061 - val_mae: 2.6477\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 0s 752us/step - loss: 2.5255 - mae: 1.0367 - val_loss: 14.8328 - val_mae: 2.7210\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 2.4015 - mae: 1.0200 - val_loss: 13.8385 - val_mae: 2.5908\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 0s 753us/step - loss: 2.6614 - mae: 1.0656 - val_loss: 13.1238 - val_mae: 2.4647\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 2.4136 - mae: 1.0678 - val_loss: 13.3411 - val_mae: 2.5203\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 2.4515 - mae: 1.0137 - val_loss: 13.3146 - val_mae: 2.5059\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 2.1956 - mae: 0.9645 - val_loss: 13.7485 - val_mae: 2.4974\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 2.4166 - mae: 1.0039 - val_loss: 15.1661 - val_mae: 2.6391\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 2.2395 - mae: 0.9851 - val_loss: 14.4748 - val_mae: 2.5926\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 0s 754us/step - loss: 2.3744 - mae: 0.9756 - val_loss: 14.1905 - val_mae: 2.5763\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 2.2088 - mae: 1.0349 - val_loss: 14.4932 - val_mae: 2.6791\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 2.4155 - mae: 1.0136 - val_loss: 13.3145 - val_mae: 2.5283\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 0s 746us/step - loss: 2.3731 - mae: 1.0248 - val_loss: 13.5880 - val_mae: 2.4979\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 2.3930 - mae: 1.0545 - val_loss: 14.1793 - val_mae: 2.5743\n",
      "Epoch 224/500\n",
      "303/303 [==============================] - 0s 789us/step - loss: 2.2573 - mae: 0.9848 - val_loss: 14.5195 - val_mae: 2.6797\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 2.2999 - mae: 1.0222 - val_loss: 13.1538 - val_mae: 2.4698\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 0s 689us/step - loss: 2.1747 - mae: 0.9887 - val_loss: 14.7888 - val_mae: 2.7033\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 0s 780us/step - loss: 2.1509 - mae: 0.9929 - val_loss: 14.8406 - val_mae: 2.7005\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 0s 749us/step - loss: 2.1045 - mae: 0.9440 - val_loss: 15.7823 - val_mae: 2.8642\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 2.2314 - mae: 0.9998 - val_loss: 13.1606 - val_mae: 2.4901\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 2.2594 - mae: 1.0186 - val_loss: 14.0733 - val_mae: 2.6651\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 2.1295 - mae: 1.0049 - val_loss: 13.7341 - val_mae: 2.5792\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 0s 694us/step - loss: 2.1623 - mae: 0.9518 - val_loss: 13.2017 - val_mae: 2.5062\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 0s 692us/step - loss: 2.3688 - mae: 1.0039 - val_loss: 14.3006 - val_mae: 2.6599\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 0s 679us/step - loss: 2.0707 - mae: 0.9691 - val_loss: 13.6286 - val_mae: 2.5844\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 0s 698us/step - loss: 2.0944 - mae: 0.9641 - val_loss: 14.4641 - val_mae: 2.6943\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 0s 665us/step - loss: 2.0257 - mae: 0.9544 - val_loss: 14.1258 - val_mae: 2.6665\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 0s 686us/step - loss: 1.9579 - mae: 0.9738 - val_loss: 14.7700 - val_mae: 2.6390\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 694us/step - loss: 2.0873 - mae: 1.0200 - val_loss: 13.1783 - val_mae: 2.4946\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 0s 686us/step - loss: 2.1361 - mae: 0.9870 - val_loss: 14.4048 - val_mae: 2.6596\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 0s 691us/step - loss: 1.9934 - mae: 0.9414 - val_loss: 13.9301 - val_mae: 2.6651\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 0s 692us/step - loss: 2.2581 - mae: 0.9837 - val_loss: 12.1814 - val_mae: 2.4002\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 0s 675us/step - loss: 2.0520 - mae: 0.9747 - val_loss: 14.4229 - val_mae: 2.6210\n",
      "Epoch 243/500\n",
      "303/303 [==============================] - 0s 679us/step - loss: 2.1024 - mae: 0.9755 - val_loss: 13.3144 - val_mae: 2.5142\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 0s 695us/step - loss: 1.7683 - mae: 0.9218 - val_loss: 14.4483 - val_mae: 2.7585\n",
      "Epoch 245/500\n",
      "303/303 [==============================] - 0s 688us/step - loss: 2.0307 - mae: 0.9757 - val_loss: 13.7638 - val_mae: 2.6610\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 0s 676us/step - loss: 2.0588 - mae: 0.9932 - val_loss: 13.5054 - val_mae: 2.5349\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 0s 690us/step - loss: 2.1256 - mae: 0.9833 - val_loss: 13.8006 - val_mae: 2.5772\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 0s 686us/step - loss: 2.0940 - mae: 0.9732 - val_loss: 14.1085 - val_mae: 2.6693\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 0s 690us/step - loss: 1.9655 - mae: 0.9392 - val_loss: 13.1719 - val_mae: 2.5117\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 0s 694us/step - loss: 1.8011 - mae: 0.9584 - val_loss: 13.6659 - val_mae: 2.5766\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 0s 671us/step - loss: 2.1657 - mae: 0.9974 - val_loss: 14.2043 - val_mae: 2.6385\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 0s 675us/step - loss: 1.9529 - mae: 0.9775 - val_loss: 13.3241 - val_mae: 2.5244\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 0s 687us/step - loss: 2.0020 - mae: 0.9759 - val_loss: 13.4107 - val_mae: 2.5961\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 0s 675us/step - loss: 2.0635 - mae: 0.9400 - val_loss: 13.8090 - val_mae: 2.5943\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 0s 695us/step - loss: 2.0478 - mae: 0.9582 - val_loss: 13.7889 - val_mae: 2.6141\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 0s 680us/step - loss: 1.8715 - mae: 0.9588 - val_loss: 14.4254 - val_mae: 2.6988\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 0s 689us/step - loss: 1.8987 - mae: 0.9510 - val_loss: 13.6656 - val_mae: 2.5793\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 0s 690us/step - loss: 1.8051 - mae: 0.9531 - val_loss: 13.5797 - val_mae: 2.5572\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 0s 694us/step - loss: 1.9933 - mae: 0.9935 - val_loss: 13.9183 - val_mae: 2.5940\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 0s 687us/step - loss: 1.9718 - mae: 0.9720 - val_loss: 14.2260 - val_mae: 2.6156\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 0s 684us/step - loss: 1.8834 - mae: 0.9341 - val_loss: 13.5638 - val_mae: 2.6015\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 0s 688us/step - loss: 1.9299 - mae: 0.9550 - val_loss: 15.6993 - val_mae: 2.8992\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 0s 680us/step - loss: 1.9835 - mae: 0.9481 - val_loss: 14.9334 - val_mae: 2.7861\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 0s 685us/step - loss: 1.8190 - mae: 0.9029 - val_loss: 14.5612 - val_mae: 2.7251\n",
      "Epoch 265/500\n",
      "303/303 [==============================] - 0s 706us/step - loss: 1.8886 - mae: 0.9189 - val_loss: 14.0363 - val_mae: 2.6925\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 0s 698us/step - loss: 1.9081 - mae: 0.9137 - val_loss: 13.5199 - val_mae: 2.5958\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 0s 677us/step - loss: 1.7825 - mae: 0.9309 - val_loss: 12.8616 - val_mae: 2.5264\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 0s 687us/step - loss: 1.8953 - mae: 0.9380 - val_loss: 14.4496 - val_mae: 2.6593\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 0s 700us/step - loss: 1.8170 - mae: 0.9296 - val_loss: 13.2273 - val_mae: 2.5210\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 0s 696us/step - loss: 1.8107 - mae: 0.9406 - val_loss: 13.3353 - val_mae: 2.5626\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 0s 694us/step - loss: 1.7678 - mae: 0.9399 - val_loss: 13.6139 - val_mae: 2.5520\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 0s 681us/step - loss: 1.6087 - mae: 0.8807 - val_loss: 13.0636 - val_mae: 2.5035\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 0s 679us/step - loss: 1.9619 - mae: 1.0039 - val_loss: 14.3694 - val_mae: 2.6981\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 0s 679us/step - loss: 1.6026 - mae: 0.9029 - val_loss: 13.4509 - val_mae: 2.6013\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 0s 686us/step - loss: 1.8961 - mae: 0.9630 - val_loss: 12.9174 - val_mae: 2.4946\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 0s 686us/step - loss: 1.6975 - mae: 0.9144 - val_loss: 13.6222 - val_mae: 2.5956\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 0s 685us/step - loss: 1.8605 - mae: 0.9276 - val_loss: 13.6978 - val_mae: 2.6041\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 0s 705us/step - loss: 1.5849 - mae: 0.8954 - val_loss: 12.7656 - val_mae: 2.4794\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 0s 687us/step - loss: 1.6541 - mae: 0.9121 - val_loss: 14.0569 - val_mae: 2.6880\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 0s 755us/step - loss: 1.7360 - mae: 0.9291 - val_loss: 15.0992 - val_mae: 2.8668\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 0s 803us/step - loss: 1.6775 - mae: 0.9302 - val_loss: 12.6437 - val_mae: 2.4688\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 0s 797us/step - loss: 1.6109 - mae: 0.8797 - val_loss: 12.8714 - val_mae: 2.5633\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 0s 781us/step - loss: 1.7446 - mae: 0.9120 - val_loss: 13.4844 - val_mae: 2.6037\n",
      "Epoch 284/500\n",
      "303/303 [==============================] - 0s 918us/step - loss: 1.5485 - mae: 0.8998 - val_loss: 19.4759 - val_mae: 3.3572\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 1.6503 - mae: 0.9345 - val_loss: 12.9617 - val_mae: 2.4786\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.5619 - mae: 0.8781 - val_loss: 13.0151 - val_mae: 2.5199\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.6491 - mae: 0.9238 - val_loss: 13.5376 - val_mae: 2.5415\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.7785 - mae: 0.8916 - val_loss: 13.7522 - val_mae: 2.5558\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.6380 - mae: 0.8851 - val_loss: 13.7539 - val_mae: 2.5538\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.4899 - mae: 0.8656 - val_loss: 13.7882 - val_mae: 2.5968\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.6271 - mae: 0.8891 - val_loss: 13.5509 - val_mae: 2.5806\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.4757 - mae: 0.8688 - val_loss: 14.1447 - val_mae: 2.6466\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.7725 - mae: 0.9125 - val_loss: 12.8640 - val_mae: 2.4231\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.6663 - mae: 0.9257 - val_loss: 13.6514 - val_mae: 2.5670\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 1.3357 - mae: 0.8137 - val_loss: 13.9336 - val_mae: 2.5886\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 1.9829 - mae: 0.9410 - val_loss: 14.9061 - val_mae: 2.6457\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 717us/step - loss: 1.7013 - mae: 0.8724 - val_loss: 13.7018 - val_mae: 2.5981\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 1.6145 - mae: 0.8928 - val_loss: 14.3061 - val_mae: 2.6039\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 0s 723us/step - loss: 1.6540 - mae: 0.8975 - val_loss: 13.6807 - val_mae: 2.5248\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.7076 - mae: 0.8935 - val_loss: 14.5406 - val_mae: 2.6840\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.5464 - mae: 0.8767 - val_loss: 14.0604 - val_mae: 2.6180\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.7192 - mae: 0.8869 - val_loss: 13.7360 - val_mae: 2.5466\n",
      "Epoch 303/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 1.5405 - mae: 0.8742 - val_loss: 12.7531 - val_mae: 2.4700\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.4102 - mae: 0.8441 - val_loss: 14.1138 - val_mae: 2.6650\n",
      "Epoch 305/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.6042 - mae: 0.8523 - val_loss: 15.6747 - val_mae: 2.8636\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.4956 - mae: 0.8644 - val_loss: 14.4415 - val_mae: 2.6755\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.5719 - mae: 0.8764 - val_loss: 14.9692 - val_mae: 2.6633\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.5707 - mae: 0.8860 - val_loss: 14.0499 - val_mae: 2.6468\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.5815 - mae: 0.8763 - val_loss: 14.0531 - val_mae: 2.7378\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.4894 - mae: 0.8492 - val_loss: 14.1453 - val_mae: 2.5767\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.4865 - mae: 0.8839 - val_loss: 15.1985 - val_mae: 2.8039\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.5760 - mae: 0.8739 - val_loss: 12.6123 - val_mae: 2.4628\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 1.5702 - mae: 0.9057 - val_loss: 12.9770 - val_mae: 2.5332\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 0s 698us/step - loss: 1.4745 - mae: 0.8690 - val_loss: 13.9709 - val_mae: 2.6177\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 0s 703us/step - loss: 1.5037 - mae: 0.8437 - val_loss: 12.9326 - val_mae: 2.5003\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.4453 - mae: 0.8612 - val_loss: 13.9488 - val_mae: 2.5998\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.4410 - mae: 0.8400 - val_loss: 13.4879 - val_mae: 2.5257\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.5240 - mae: 0.8958 - val_loss: 13.5147 - val_mae: 2.5714\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 1.4187 - mae: 0.8453 - val_loss: 15.6715 - val_mae: 2.8513\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.5232 - mae: 0.8659 - val_loss: 14.3639 - val_mae: 2.6339\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.6026 - mae: 0.8957 - val_loss: 13.7314 - val_mae: 2.5914\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.3617 - mae: 0.8269 - val_loss: 13.7548 - val_mae: 2.6384\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.6088 - mae: 0.8849 - val_loss: 13.0922 - val_mae: 2.5336\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 0s 828us/step - loss: 1.4252 - mae: 0.8721 - val_loss: 13.3013 - val_mae: 2.5029\n",
      "Epoch 325/500\n",
      "303/303 [==============================] - 0s 818us/step - loss: 1.2798 - mae: 0.8102 - val_loss: 13.7004 - val_mae: 2.5443\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 0s 737us/step - loss: 1.5519 - mae: 0.8524 - val_loss: 13.3790 - val_mae: 2.5430\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 1.4157 - mae: 0.8684 - val_loss: 13.9280 - val_mae: 2.6421\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.3829 - mae: 0.8672 - val_loss: 14.8226 - val_mae: 2.7250\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 1.4964 - mae: 0.8618 - val_loss: 13.5633 - val_mae: 2.6460\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 1.4851 - mae: 0.8425 - val_loss: 13.3679 - val_mae: 2.5837\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 0s 950us/step - loss: 1.5115 - mae: 0.8744 - val_loss: 13.3205 - val_mae: 2.5441\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 0s 784us/step - loss: 1.2619 - mae: 0.8146 - val_loss: 14.0143 - val_mae: 2.6477\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 0s 784us/step - loss: 1.6117 - mae: 0.9060 - val_loss: 13.5465 - val_mae: 2.5883\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 0s 986us/step - loss: 1.2786 - mae: 0.8064 - val_loss: 13.6141 - val_mae: 2.6086\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.5348 - mae: 0.8724 - val_loss: 13.4673 - val_mae: 2.5690\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.3370 - mae: 0.8290 - val_loss: 14.0931 - val_mae: 2.6853\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.6133 - mae: 0.8765 - val_loss: 13.9376 - val_mae: 2.6538\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 0s 731us/step - loss: 1.2489 - mae: 0.8198 - val_loss: 13.9351 - val_mae: 2.6743\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 0s 890us/step - loss: 1.3557 - mae: 0.8477 - val_loss: 14.6122 - val_mae: 2.6861\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 0s 958us/step - loss: 1.5298 - mae: 0.8492 - val_loss: 13.0873 - val_mae: 2.4951\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 0s 847us/step - loss: 1.2642 - mae: 0.8138 - val_loss: 14.7637 - val_mae: 2.6813\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.2554 - mae: 0.8049 - val_loss: 12.2879 - val_mae: 2.4756\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.4838 - mae: 0.8860 - val_loss: 12.1405 - val_mae: 2.3977\n",
      "Epoch 344/500\n",
      "303/303 [==============================] - 0s 876us/step - loss: 1.2846 - mae: 0.8290 - val_loss: 14.0862 - val_mae: 2.6487\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 0s 788us/step - loss: 1.4419 - mae: 0.8350 - val_loss: 14.0987 - val_mae: 2.6644\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 0s 905us/step - loss: 1.3426 - mae: 0.8618 - val_loss: 12.4523 - val_mae: 2.5153\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.3469 - mae: 0.8386 - val_loss: 13.5282 - val_mae: 2.5866\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 0s 809us/step - loss: 1.3660 - mae: 0.7985 - val_loss: 14.5571 - val_mae: 2.7280\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 0s 872us/step - loss: 1.2355 - mae: 0.7794 - val_loss: 13.2677 - val_mae: 2.5172\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 0s 748us/step - loss: 1.2712 - mae: 0.8097 - val_loss: 13.3216 - val_mae: 2.5311\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 0s 770us/step - loss: 1.3900 - mae: 0.8270 - val_loss: 13.7423 - val_mae: 2.6278\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.4766 - mae: 0.8697 - val_loss: 12.6589 - val_mae: 2.5411\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 0s 948us/step - loss: 1.2756 - mae: 0.7898 - val_loss: 12.7570 - val_mae: 2.5122\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 0s 774us/step - loss: 1.2759 - mae: 0.8081 - val_loss: 14.9713 - val_mae: 2.7169\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 0s 756us/step - loss: 1.3195 - mae: 0.8027 - val_loss: 14.2142 - val_mae: 2.6813\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 723us/step - loss: 1.3740 - mae: 0.8429 - val_loss: 13.2991 - val_mae: 2.5138\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 0s 840us/step - loss: 1.4010 - mae: 0.7976 - val_loss: 15.2190 - val_mae: 2.7158\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 0s 886us/step - loss: 1.2988 - mae: 0.7966 - val_loss: 13.9500 - val_mae: 2.6917\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 1.4510 - mae: 0.8348 - val_loss: 13.0137 - val_mae: 2.5104\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.2771 - mae: 0.7925 - val_loss: 12.9274 - val_mae: 2.5508\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 0s 772us/step - loss: 1.2029 - mae: 0.7937 - val_loss: 13.2228 - val_mae: 2.5244\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 0s 918us/step - loss: 1.2457 - mae: 0.8092 - val_loss: 14.4616 - val_mae: 2.7439\n",
      "Epoch 363/500\n",
      "303/303 [==============================] - 0s 931us/step - loss: 1.3463 - mae: 0.8160 - val_loss: 13.0677 - val_mae: 2.5454\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 0s 918us/step - loss: 1.3624 - mae: 0.8396 - val_loss: 12.8098 - val_mae: 2.4862\n",
      "Epoch 365/500\n",
      "303/303 [==============================] - 0s 928us/step - loss: 1.2592 - mae: 0.7799 - val_loss: 12.9575 - val_mae: 2.5467\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 0s 787us/step - loss: 1.2721 - mae: 0.8193 - val_loss: 13.7439 - val_mae: 2.6126\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 0s 766us/step - loss: 1.2997 - mae: 0.7880 - val_loss: 13.4483 - val_mae: 2.5630\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 0s 762us/step - loss: 1.2889 - mae: 0.8036 - val_loss: 13.6431 - val_mae: 2.5882\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 0s 742us/step - loss: 1.3510 - mae: 0.8489 - val_loss: 13.8866 - val_mae: 2.6275\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 0s 791us/step - loss: 1.0979 - mae: 0.7678 - val_loss: 13.0422 - val_mae: 2.5161\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 1.2285 - mae: 0.7950 - val_loss: 12.5526 - val_mae: 2.4665\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 0s 881us/step - loss: 1.1699 - mae: 0.7789 - val_loss: 14.9608 - val_mae: 2.7892\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 0s 806us/step - loss: 1.2022 - mae: 0.7880 - val_loss: 13.0564 - val_mae: 2.5731\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 0s 825us/step - loss: 1.2711 - mae: 0.8172 - val_loss: 14.2899 - val_mae: 2.7081\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 0s 783us/step - loss: 1.1292 - mae: 0.7620 - val_loss: 13.2133 - val_mae: 2.5936\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 0s 776us/step - loss: 1.1536 - mae: 0.7511 - val_loss: 12.6808 - val_mae: 2.5215\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 0s 784us/step - loss: 1.3277 - mae: 0.8117 - val_loss: 14.5094 - val_mae: 2.6810\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 0s 801us/step - loss: 1.3299 - mae: 0.7753 - val_loss: 14.3174 - val_mae: 2.6596\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 0s 756us/step - loss: 1.2501 - mae: 0.7383 - val_loss: 15.3992 - val_mae: 2.7983\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.3746 - mae: 0.7834 - val_loss: 13.5677 - val_mae: 2.5462\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.2640 - mae: 0.7875 - val_loss: 14.5005 - val_mae: 2.6477\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 0s 783us/step - loss: 1.2006 - mae: 0.7892 - val_loss: 13.4116 - val_mae: 2.5066\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 1.2875 - mae: 0.8004 - val_loss: 13.4722 - val_mae: 2.5321\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 0s 743us/step - loss: 1.0735 - mae: 0.7477 - val_loss: 14.0234 - val_mae: 2.5389\n",
      "Epoch 385/500\n",
      "303/303 [==============================] - 0s 741us/step - loss: 1.2053 - mae: 0.7812 - val_loss: 14.9500 - val_mae: 2.6874\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.0708 - mae: 0.7499 - val_loss: 13.9969 - val_mae: 2.5278\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 0s 739us/step - loss: 1.0583 - mae: 0.7400 - val_loss: 15.1647 - val_mae: 2.7381\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 0s 733us/step - loss: 1.1182 - mae: 0.7745 - val_loss: 16.8373 - val_mae: 2.7807\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 0s 729us/step - loss: 1.2928 - mae: 0.7866 - val_loss: 13.8427 - val_mae: 2.5664\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 0s 752us/step - loss: 1.1808 - mae: 0.7757 - val_loss: 14.7244 - val_mae: 2.7428\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 0s 876us/step - loss: 1.3048 - mae: 0.8001 - val_loss: 14.9385 - val_mae: 2.6743\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 0s 893us/step - loss: 1.2993 - mae: 0.7902 - val_loss: 14.8133 - val_mae: 2.6443\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 0s 907us/step - loss: 1.1458 - mae: 0.7635 - val_loss: 16.2632 - val_mae: 2.7660\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 0s 847us/step - loss: 1.1196 - mae: 0.7585 - val_loss: 16.2410 - val_mae: 2.9175\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 0s 849us/step - loss: 1.1018 - mae: 0.7661 - val_loss: 17.2648 - val_mae: 2.9998\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 0s 912us/step - loss: 1.2324 - mae: 0.8113 - val_loss: 14.7734 - val_mae: 2.6990\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 0s 810us/step - loss: 1.1065 - mae: 0.7331 - val_loss: 17.3820 - val_mae: 2.9367\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 0s 800us/step - loss: 1.3591 - mae: 0.7891 - val_loss: 14.4389 - val_mae: 2.6461\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 0s 790us/step - loss: 1.2263 - mae: 0.7459 - val_loss: 14.8555 - val_mae: 2.6991\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 0s 848us/step - loss: 1.2162 - mae: 0.7581 - val_loss: 15.3106 - val_mae: 2.7750\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 0s 904us/step - loss: 1.3932 - mae: 0.7746 - val_loss: 15.0315 - val_mae: 2.6477\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 0s 923us/step - loss: 1.1587 - mae: 0.7675 - val_loss: 14.3354 - val_mae: 2.6177\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 0s 835us/step - loss: 1.0716 - mae: 0.7468 - val_loss: 15.4662 - val_mae: 2.7240\n",
      "Epoch 404/500\n",
      "303/303 [==============================] - 0s 859us/step - loss: 1.1067 - mae: 0.7543 - val_loss: 13.9026 - val_mae: 2.6158\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 0s 799us/step - loss: 1.2050 - mae: 0.7770 - val_loss: 15.6050 - val_mae: 2.7976\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 0s 836us/step - loss: 1.0262 - mae: 0.7225 - val_loss: 13.8456 - val_mae: 2.5871\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 0s 745us/step - loss: 1.1266 - mae: 0.7684 - val_loss: 14.7397 - val_mae: 2.6583\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 0s 874us/step - loss: 1.1494 - mae: 0.7697 - val_loss: 13.5852 - val_mae: 2.5379\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 0s 821us/step - loss: 1.1397 - mae: 0.7795 - val_loss: 14.3535 - val_mae: 2.6348\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 0s 928us/step - loss: 1.0706 - mae: 0.7355 - val_loss: 14.0817 - val_mae: 2.6206\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 0s 879us/step - loss: 1.0998 - mae: 0.7484 - val_loss: 16.2947 - val_mae: 2.8878\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.1411 - mae: 0.7875 - val_loss: 14.0460 - val_mae: 2.5429\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 0s 839us/step - loss: 1.0878 - mae: 0.7293 - val_loss: 14.8244 - val_mae: 2.7074\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 0s 881us/step - loss: 0.9852 - mae: 0.6997 - val_loss: 13.7926 - val_mae: 2.5508\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 770us/step - loss: 1.1167 - mae: 0.7421 - val_loss: 14.9010 - val_mae: 2.6269\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 0s 971us/step - loss: 1.1465 - mae: 0.7459 - val_loss: 14.0831 - val_mae: 2.5518\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 0s 763us/step - loss: 1.1282 - mae: 0.7900 - val_loss: 14.9074 - val_mae: 2.6907\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 0s 890us/step - loss: 1.1538 - mae: 0.7713 - val_loss: 14.6149 - val_mae: 2.6453\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 1.0486 - mae: 0.7589 - val_loss: 14.0121 - val_mae: 2.5708\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 0s 899us/step - loss: 1.0286 - mae: 0.7321 - val_loss: 14.9467 - val_mae: 2.6425\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 0s 818us/step - loss: 0.9985 - mae: 0.7406 - val_loss: 15.9265 - val_mae: 2.8224\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 0s 857us/step - loss: 1.1374 - mae: 0.7424 - val_loss: 15.2866 - val_mae: 2.7317\n",
      "Epoch 423/500\n",
      "303/303 [==============================] - 0s 785us/step - loss: 0.9871 - mae: 0.7016 - val_loss: 15.0039 - val_mae: 2.7181\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 0s 756us/step - loss: 1.1571 - mae: 0.7201 - val_loss: 14.5673 - val_mae: 2.5900\n",
      "Epoch 425/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.0521 - mae: 0.7357 - val_loss: 14.7785 - val_mae: 2.6581\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 0.9301 - mae: 0.7149 - val_loss: 15.0106 - val_mae: 2.6436\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.2358 - mae: 0.8005 - val_loss: 13.2251 - val_mae: 2.5208\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 0.9269 - mae: 0.6889 - val_loss: 15.1491 - val_mae: 2.7556\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.0744 - mae: 0.7161 - val_loss: 14.3442 - val_mae: 2.6680\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 0s 953us/step - loss: 1.0734 - mae: 0.7597 - val_loss: 14.2718 - val_mae: 2.6066\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 0s 757us/step - loss: 1.0939 - mae: 0.7324 - val_loss: 14.6563 - val_mae: 2.7283\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 0s 735us/step - loss: 0.9839 - mae: 0.7340 - val_loss: 15.4139 - val_mae: 2.7227\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 0s 865us/step - loss: 1.1402 - mae: 0.7785 - val_loss: 15.1039 - val_mae: 2.6523\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.9146 - mae: 0.7172 - val_loss: 15.8903 - val_mae: 2.7783\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.0907 - mae: 0.7593 - val_loss: 14.0716 - val_mae: 2.5642\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.0561 - mae: 0.7471 - val_loss: 16.5557 - val_mae: 2.8954\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.0839 - mae: 0.7281 - val_loss: 16.2548 - val_mae: 2.7677\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 1.0305 - mae: 0.7184 - val_loss: 14.3535 - val_mae: 2.7000\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 0.9595 - mae: 0.7230 - val_loss: 14.5622 - val_mae: 2.6663\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.0215 - mae: 0.7048 - val_loss: 14.1433 - val_mae: 2.5636\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 1.0412 - mae: 0.7314 - val_loss: 14.5167 - val_mae: 2.6214\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.0610 - mae: 0.7296 - val_loss: 14.5955 - val_mae: 2.7090\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.0311 - mae: 0.7304 - val_loss: 13.8173 - val_mae: 2.5634\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 0s 707us/step - loss: 0.9927 - mae: 0.7018 - val_loss: 14.7893 - val_mae: 2.6157\n",
      "Epoch 445/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.0531 - mae: 0.7590 - val_loss: 13.8431 - val_mae: 2.5795\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.9845 - mae: 0.7087 - val_loss: 14.1820 - val_mae: 2.5747\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.0342 - mae: 0.7068 - val_loss: 15.2434 - val_mae: 2.7777\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.9877 - mae: 0.7012 - val_loss: 13.8374 - val_mae: 2.5962\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.0488 - mae: 0.7380 - val_loss: 14.4238 - val_mae: 2.5970\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 1.0258 - mae: 0.7407 - val_loss: 14.5018 - val_mae: 2.6311\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 0s 734us/step - loss: 0.9950 - mae: 0.7181 - val_loss: 15.4729 - val_mae: 2.6418\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.0200 - mae: 0.7109 - val_loss: 14.6257 - val_mae: 2.7043\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 1.0402 - mae: 0.7269 - val_loss: 14.5599 - val_mae: 2.6011\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.0316 - mae: 0.7125 - val_loss: 13.6228 - val_mae: 2.5943\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 1.1645 - mae: 0.7538 - val_loss: 14.2798 - val_mae: 2.6744\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 0.9571 - mae: 0.6986 - val_loss: 15.3877 - val_mae: 2.7220\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 0s 711us/step - loss: 0.9888 - mae: 0.7181 - val_loss: 14.5364 - val_mae: 2.5962\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 1.0715 - mae: 0.7413 - val_loss: 14.6293 - val_mae: 2.6702\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 0.9277 - mae: 0.6895 - val_loss: 14.9224 - val_mae: 2.7338\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 0s 719us/step - loss: 1.0045 - mae: 0.7212 - val_loss: 13.2657 - val_mae: 2.4780\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 0s 722us/step - loss: 0.9807 - mae: 0.7138 - val_loss: 13.5400 - val_mae: 2.5013\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 0s 740us/step - loss: 0.9507 - mae: 0.7080 - val_loss: 14.2279 - val_mae: 2.6014\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.9605 - mae: 0.6810 - val_loss: 15.6021 - val_mae: 2.7325\n",
      "Epoch 464/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 0.9161 - mae: 0.6578 - val_loss: 15.4175 - val_mae: 2.6963\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 0s 717us/step - loss: 1.0001 - mae: 0.7071 - val_loss: 15.7655 - val_mae: 2.6891\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 0s 726us/step - loss: 1.0366 - mae: 0.7278 - val_loss: 13.8058 - val_mae: 2.5082\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 0s 730us/step - loss: 0.9965 - mae: 0.6878 - val_loss: 14.0173 - val_mae: 2.5479\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 1.1571 - mae: 0.7394 - val_loss: 14.3585 - val_mae: 2.6089\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.9180 - mae: 0.6751 - val_loss: 14.7613 - val_mae: 2.6245\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.9955 - mae: 0.6912 - val_loss: 14.2163 - val_mae: 2.6734\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 0s 708us/step - loss: 0.9701 - mae: 0.7073 - val_loss: 13.6267 - val_mae: 2.5349\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 0.9713 - mae: 0.7247 - val_loss: 13.9286 - val_mae: 2.5945\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 0s 721us/step - loss: 0.9225 - mae: 0.6852 - val_loss: 15.0422 - val_mae: 2.6390\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 709us/step - loss: 1.0410 - mae: 0.7063 - val_loss: 13.2901 - val_mae: 2.4906\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 0s 725us/step - loss: 1.0324 - mae: 0.6905 - val_loss: 15.2141 - val_mae: 2.7211\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.9225 - mae: 0.7074 - val_loss: 15.4246 - val_mae: 2.8122\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 0s 754us/step - loss: 0.9930 - mae: 0.6812 - val_loss: 15.8445 - val_mae: 2.7945\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.8801 - mae: 0.6937 - val_loss: 14.3526 - val_mae: 2.6545\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.9450 - mae: 0.7165 - val_loss: 13.6142 - val_mae: 2.5882\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.9458 - mae: 0.7209 - val_loss: 14.7787 - val_mae: 2.7254\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 1.0458 - mae: 0.7122 - val_loss: 14.2365 - val_mae: 2.6045\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.7655 - mae: 0.6184 - val_loss: 14.5266 - val_mae: 2.6957\n",
      "Epoch 483/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 1.0873 - mae: 0.7531 - val_loss: 15.9206 - val_mae: 2.7686\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 0s 720us/step - loss: 0.9500 - mae: 0.6908 - val_loss: 14.6218 - val_mae: 2.6574\n",
      "Epoch 485/500\n",
      "303/303 [==============================] - 0s 709us/step - loss: 0.9444 - mae: 0.7005 - val_loss: 14.1694 - val_mae: 2.6096\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.8832 - mae: 0.6635 - val_loss: 14.4392 - val_mae: 2.6198\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 0s 713us/step - loss: 0.9636 - mae: 0.6936 - val_loss: 14.0814 - val_mae: 2.6008\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 0s 732us/step - loss: 0.9702 - mae: 0.6923 - val_loss: 13.7549 - val_mae: 2.5416\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 0s 727us/step - loss: 1.0530 - mae: 0.7137 - val_loss: 13.8267 - val_mae: 2.5978\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 0s 724us/step - loss: 0.8591 - mae: 0.6659 - val_loss: 15.0807 - val_mae: 2.8265\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 0s 712us/step - loss: 0.9541 - mae: 0.6894 - val_loss: 13.6538 - val_mae: 2.5568\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.9282 - mae: 0.6835 - val_loss: 13.8687 - val_mae: 2.5921\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.8389 - mae: 0.6700 - val_loss: 13.2723 - val_mae: 2.5353\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.8590 - mae: 0.7037 - val_loss: 14.0136 - val_mae: 2.5818\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.9444 - mae: 0.6702 - val_loss: 14.7470 - val_mae: 2.6837\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 0s 710us/step - loss: 0.8670 - mae: 0.6569 - val_loss: 12.4829 - val_mae: 2.4342\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 0s 716us/step - loss: 0.9901 - mae: 0.7247 - val_loss: 15.6126 - val_mae: 2.7625\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 0s 715us/step - loss: 0.9088 - mae: 0.6947 - val_loss: 12.9034 - val_mae: 2.4695\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 0s 714us/step - loss: 0.9025 - mae: 0.7065 - val_loss: 14.1419 - val_mae: 2.5129\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 0s 718us/step - loss: 0.8168 - mae: 0.6443 - val_loss: 13.7095 - val_mae: 2.5490\n",
      "{'val_loss': [65.24034034287428, 35.7033894612583, 30.3265106797329, 25.292015159134937, 26.756324830054684, 20.679816964559606, 21.193212712151322, 18.437596225373373, 17.105010191691292, 16.730485659085748, 18.67383171758202, 15.51804673550005, 19.155648983974647, 15.289717567496758, 13.888257985814741, 19.185899906851684, 14.213556656607174, 13.84886459024649, 15.76365736012588, 14.295767201139537, 13.602315356987926, 13.987458124318815, 14.782122635286898, 14.98076691797538, 12.891879411461524, 13.888351453917151, 13.299543819514001, 12.613047914225078, 12.716541513360317, 14.726306474477163, 12.403028573001167, 13.454764637915131, 11.67459405429957, 12.694670371895421, 11.969395879867006, 14.603233230161932, 11.489153870404214, 13.759952569661644, 11.454707496190942, 13.656095415956635, 12.829922236399298, 11.60245414158923, 13.269105905676168, 13.232959789138242, 11.541387903811536, 12.992068889299304, 12.689980149101396, 11.705763000197482, 12.238780073279809, 12.20604488996692, 11.316879518960944, 12.131952977924271, 11.164045246160217, 12.126629664928025, 13.28220285947226, 10.717569160172577, 13.433559409225426, 12.152848133748158, 14.724445734331113, 10.858153656444923, 10.809744007500479, 11.824799195126777, 13.344792569408858, 10.687718584550252, 10.5728111598898, 11.536514824237859, 11.34735462350205, 10.733821418837012, 10.59633552215159, 10.825100812289747, 11.491138213445515, 11.063096806278745, 10.938064278935608, 10.854949160788813, 11.528110887809186, 13.144136142920516, 10.744787556235678, 12.28668098258129, 11.529146052142005, 11.428615676704219, 10.911001941244496, 13.124948615263595, 12.031167076236688, 11.261094517987406, 10.924988995831791, 11.493604160131804, 14.726055070418994, 10.988742952866106, 12.930780489544043, 11.525098143752876, 11.209959903920973, 11.142560147163966, 11.588183238735288, 11.159749229848938, 10.632731851982184, 10.97419261143054, 11.95096077256629, 12.112930059963192, 11.550556258643093, 11.058434914154379, 12.487578262762849, 11.084615834029668, 11.16458734823218, 11.616806096194479, 11.989067993609185, 10.877053808552729, 11.51188850956554, 11.6621097888484, 11.571756706250333, 10.943524765393622, 11.694725243823726, 11.62559911065578, 11.68123238499387, 12.46578837738725, 10.62740639319661, 11.183260564089638, 11.406230851558341, 10.863712314995835, 12.20098489877021, 12.937343382179774, 13.824802018477845, 12.381463246579088, 11.498931044016476, 11.343679187534086, 11.05308665647109, 11.561284269658056, 11.082190983469706, 11.201058503675608, 12.108392800140233, 12.341850063616059, 12.381836066824743, 11.716205172547333, 14.285485637505621, 11.895345863342138, 11.183352829067793, 12.436809993283315, 11.043472741053343, 14.448296960503194, 11.300060873125313, 12.670502740795273, 13.4621048798408, 11.43398188210512, 11.797173740102513, 12.386758072762545, 12.420411565413671, 13.124948806369142, 12.704694910841708, 12.401876078387792, 15.238928118490126, 12.01155026501096, 11.421615011250084, 12.133945711298228, 12.313680181307442, 12.99757492867077, 12.975941583189172, 13.388749766299538, 13.316218315621972, 12.644298201066956, 12.29226478805655, 12.713315565971252, 12.32828523976268, 12.644735104106724, 14.52494039991006, 12.171065999648539, 13.214973360259867, 11.863220281845377, 13.385277154027484, 12.207176133684985, 12.998676568081276, 12.59835290371286, 12.825104559042968, 13.254643301982064, 12.836050470931614, 13.531062354342668, 13.210810492449154, 11.956029550389083, 13.847088986327256, 14.487364625345597, 11.917435974415765, 12.837771478557578, 11.488162178373296, 15.726790479028777, 13.472892294604756, 12.611964930143982, 13.237962823621652, 13.05415350355503, 13.341263462583036, 12.7184865980416, 12.357600534597578, 12.717590988226382, 12.830801171199926, 13.32193296306823, 12.77342677720774, 12.756919319905101, 12.650499235733186, 12.65452068815259, 13.129095018940452, 12.980925917662312, 13.472483391298702, 14.015381504463708, 13.71623545322316, 12.985585531305134, 13.905245294531209, 14.154196853619784, 13.582110346788264, 13.465920274732156, 20.671504453405518, 13.705326802740139, 12.955858954727585, 14.206142913937997, 14.83283275887739, 13.83853396850395, 13.123775565331124, 13.341051077722176, 13.314590705512552, 13.748531257534298, 15.166118058085551, 14.474762624159622, 14.190460334163122, 14.493239091745563, 13.314458349647172, 13.588005714747815, 14.179282740573868, 14.519486810490502, 13.15383782073173, 14.788826597778566, 14.84056862243622, 15.78231414556674, 13.160615795283064, 14.073261182884327, 13.73410328800587, 13.201653710050085, 14.300638625420467, 13.628560781730155, 14.464142620143951, 14.125812497443093, 14.770015036283835, 13.17827453321459, 14.404847915215754, 13.93008431902969, 12.18143075696924, 14.422906691815376, 13.31436832898324, 14.448251963500855, 13.763832124023892, 13.50540427465711, 13.800601244138756, 14.108478882379996, 13.171897886318643, 13.66590767071149, 14.204301230572568, 13.32411639125197, 13.41067711398522, 13.809042610460892, 13.788942989663308, 14.42535882305566, 13.66561309363587, 13.579658823279148, 13.918341688516707, 14.225950201169109, 13.563770005212046, 15.699297391837186, 14.93337712357902, 14.561154322171674, 14.036304236700905, 13.51988143582614, 12.861590820841842, 14.449555829106997, 13.227294415906384, 13.335259923052117, 13.613930043726663, 13.063636398913413, 14.369388204389528, 13.45089129685343, 12.917385685820095, 13.622210285379978, 13.697784055819698, 12.76555876473298, 14.05691530961442, 15.099186606574978, 12.643710639219995, 12.871422106639878, 13.484364380418567, 19.47591428016082, 12.961676095172765, 13.015097932468773, 13.53756881470211, 13.75219924357895, 13.753919100909872, 13.788185197176494, 13.550853315468803, 14.14469230592154, 12.864016858647327, 13.651401811899758, 13.933588683335623, 14.906102585654436, 13.7018176109258, 14.306099253826508, 13.680729867517746, 14.540561482372537, 14.060375066151776, 13.73596082629675, 12.753059342674712, 14.11379504208234, 15.674687068983175, 14.441452534145464, 14.969175189380945, 14.049868785823456, 14.053131114387202, 14.145318759621713, 15.198512661593533, 12.612319007119403, 12.976984810366247, 13.97090931475914, 12.93264920634591, 13.948777718755352, 13.48792816649795, 13.514668360868892, 15.671479424881278, 14.363889635139431, 13.73140157776018, 13.754819362498083, 13.092229204314604, 13.301312762981114, 13.700437896207234, 13.379026920191187, 13.92804720934416, 14.822605698599968, 13.563256313642233, 13.367930469983765, 13.320539616557832, 14.014330247980151, 13.546530494519445, 13.614093993468288, 13.46731524168523, 14.093109931401582, 13.937587030131674, 13.935082704787797, 14.612249538631785, 13.08729728924052, 14.763747382798154, 12.28788386500731, 12.140532059699337, 14.086175564483458, 14.098675839065248, 12.452290131994015, 13.528154725175597, 14.55713053265172, 13.267657590073897, 13.321573637334554, 13.742311911343938, 12.658918210674114, 12.756979492124133, 14.971278327423848, 14.214185513643315, 13.299051079272044, 15.219045940198905, 13.950047601280957, 13.013715090870967, 12.927421389896846, 13.222802618984709, 14.461629843802104, 13.067693514694081, 12.809796824071574, 12.957450936528241, 13.743900098132505, 13.448296629459515, 13.64310813879202, 13.886609107004663, 13.042159546604656, 12.552553904915948, 14.960794711951166, 13.056395551508482, 14.289942828016407, 13.213315644474369, 12.680775924797842, 14.509394279145175, 14.317429566693649, 15.399180248853762, 13.567699021547986, 14.500453606189694, 13.411610017742271, 13.472249197949411, 14.023400407367488, 14.949982557906383, 13.99693430231041, 15.164733686279229, 16.83733228380771, 13.842743644558267, 14.7244428601577, 14.93852201313193, 14.813306743308779, 16.26317251406006, 16.240990202023163, 17.264828924724227, 14.773434911714089, 17.38198288054725, 14.438902362080356, 14.855526994083926, 15.310565292482531, 15.031495977288929, 14.335367470391851, 15.466217607507708, 13.902575557720663, 15.60503040404995, 13.845618920679675, 14.73967588171455, 13.585198118533516, 14.353510042334939, 14.081681804155174, 16.294732289844784, 14.046041591583998, 14.824427394712767, 13.7926205492643, 14.900973604522912, 14.083065355512415, 14.907391295381037, 14.614881187889466, 14.012075890646326, 14.94668960149197, 15.926474524459037, 15.286648721498723, 15.00389647455932, 14.567312652178456, 14.778485931602617, 15.010579343995836, 13.225129407729105, 15.149106773976605, 14.344237117133666, 14.271781820723197, 14.656330816753325, 15.413872588550358, 15.103891871350882, 15.890340920611479, 14.071611228315989, 16.555654081545935, 16.25476642674453, 14.3535371988938, 14.562239997570707, 14.143340960693648, 14.516687901349425, 14.59552530793789, 13.817282153179525, 14.789270169544409, 13.843115606387308, 14.181985679280825, 15.243440452930841, 13.837434800360167, 14.42375505473874, 14.501762154342094, 15.472939815968425, 14.625732452869139, 14.559861517141892, 13.622799505009938, 14.2797697012481, 15.38773598998876, 14.536358778244795, 14.62932983528659, 14.922448870532865, 13.265706017458958, 13.539959818069445, 14.227907425982158, 15.60205118620257, 15.41746094880976, 15.765475536591724, 13.805841565187468, 14.017315792314026, 14.35848142214867, 14.761256858794217, 14.216310630534604, 13.626693287674144, 13.928643870480949, 15.04220099967736, 13.290136146382197, 15.214076251358065, 15.424583020886448, 15.844523565479472, 14.352570731690761, 13.614178177891391, 14.778687904920835, 14.236508969798463, 14.526616254982788, 15.92059098451864, 14.621778155872391, 14.169407960963678, 14.439173479426172, 14.081441234477962, 13.754919774262095, 13.826691368677755, 15.080652746020373, 13.653750819979365, 13.868701052208088, 13.27228769414717, 14.013558339743131, 14.746999478353318, 12.482945639288685, 15.612598978636537, 12.90335775243976, 14.141864926369843, 13.70946549890692], 'val_mae': [5.540767669677734, 4.040188312530518, 3.5897865295410156, 3.30157208442688, 3.1478893756866455, 2.798849582672119, 2.8949029445648193, 2.72884464263916, 2.640923500061035, 2.589371681213379, 2.710132360458374, 2.5177173614501953, 2.8863136768341064, 2.524402618408203, 2.4854965209960938, 3.03011417388916, 2.426868200302124, 2.494044303894043, 2.675208568572998, 2.491689443588257, 2.458287239074707, 2.4978342056274414, 2.749124050140381, 2.7079684734344482, 2.430140733718872, 2.4837682247161865, 2.5147578716278076, 2.402966260910034, 2.4150819778442383, 2.647158145904541, 2.407071590423584, 2.5137529373168945, 2.3578708171844482, 2.480304479598999, 2.3693833351135254, 2.717261552810669, 2.3508901596069336, 2.6492555141448975, 2.3368210792541504, 2.7198410034179688, 2.5554304122924805, 2.414322853088379, 2.6603989601135254, 2.6215741634368896, 2.374105215072632, 2.6513097286224365, 2.586418867111206, 2.396787643432617, 2.495987892150879, 2.510587215423584, 2.4272549152374268, 2.430617094039917, 2.415809392929077, 2.5626494884490967, 2.6166491508483887, 2.208963632583618, 2.5995144844055176, 2.462923049926758, 2.9013659954071045, 2.297532796859741, 2.268049955368042, 2.408017635345459, 2.600677490234375, 2.288972854614258, 2.273716926574707, 2.4948089122772217, 2.339948892593384, 2.3768913745880127, 2.1749939918518066, 2.3069541454315186, 2.3476619720458984, 2.334775924682617, 2.3168394565582275, 2.239757537841797, 2.339332103729248, 2.4812991619110107, 2.217184066772461, 2.406292200088501, 2.4669744968414307, 2.4875049591064453, 2.3800904750823975, 2.622898578643799, 2.387462854385376, 2.359586238861084, 2.250415325164795, 2.3611042499542236, 2.6964809894561768, 2.4189186096191406, 2.616947889328003, 2.40055775642395, 2.3793721199035645, 2.4438209533691406, 2.395390033721924, 2.3677122592926025, 2.273339033126831, 2.342813730239868, 2.528627872467041, 2.4336702823638916, 2.304551124572754, 2.3704640865325928, 2.433659791946411, 2.272284507751465, 2.2750625610351562, 2.331857681274414, 2.357058048248291, 2.2620489597320557, 2.3675379753112793, 2.4077398777008057, 2.4778122901916504, 2.2151191234588623, 2.2994611263275146, 2.2907497882843018, 2.360800266265869, 2.6179120540618896, 2.233736038208008, 2.356520891189575, 2.4173851013183594, 2.2797622680664062, 2.3933866024017334, 2.681837320327759, 2.6499621868133545, 2.5951719284057617, 2.368561029434204, 2.339296340942383, 2.2665798664093018, 2.314026117324829, 2.356870174407959, 2.2552053928375244, 2.3847336769104004, 2.477823257446289, 2.40114426612854, 2.379831552505493, 2.6729555130004883, 2.372631549835205, 2.3085827827453613, 2.4653820991516113, 2.37764835357666, 2.64218807220459, 2.2975783348083496, 2.4770758152008057, 2.668825626373291, 2.2851991653442383, 2.435250997543335, 2.4072155952453613, 2.41438364982605, 2.4982385635375977, 2.4909212589263916, 2.4048750400543213, 2.7984042167663574, 2.3556172847747803, 2.271717071533203, 2.461510181427002, 2.3999524116516113, 2.493582248687744, 2.5932533740997314, 2.542253017425537, 2.4822421073913574, 2.4586398601531982, 2.432387590408325, 2.5759334564208984, 2.409552812576294, 2.4157283306121826, 2.844851016998291, 2.35499906539917, 2.468228340148926, 2.3534276485443115, 2.5764553546905518, 2.466372489929199, 2.5340447425842285, 2.475843906402588, 2.5565731525421143, 2.6228599548339844, 2.483675718307495, 2.562063694000244, 2.5029451847076416, 2.353214979171753, 2.5440139770507812, 2.7797999382019043, 2.372283458709717, 2.4407527446746826, 2.331374168395996, 2.893634080886841, 2.509117603302002, 2.5584909915924072, 2.4969472885131836, 2.4908852577209473, 2.4854533672332764, 2.463980197906494, 2.356977939605713, 2.419503688812256, 2.5183820724487305, 2.5514819622039795, 2.4668567180633545, 2.5073957443237305, 2.4691977500915527, 2.440535068511963, 2.5600810050964355, 2.571279287338257, 2.5912833213806152, 2.723576307296753, 2.552046775817871, 2.507323980331421, 2.6335084438323975, 2.6190035343170166, 2.574289560317993, 2.512713670730591, 3.5342905521392822, 2.606752872467041, 2.4341671466827393, 2.647700548171997, 2.72096848487854, 2.5907692909240723, 2.4647374153137207, 2.5203299522399902, 2.5059070587158203, 2.4974493980407715, 2.6390717029571533, 2.5926096439361572, 2.5762722492218018, 2.679131269454956, 2.528319835662842, 2.497866153717041, 2.574289083480835, 2.6796953678131104, 2.46979022026062, 2.703319549560547, 2.700463056564331, 2.8641891479492188, 2.490060567855835, 2.665051221847534, 2.579192876815796, 2.5061709880828857, 2.6599464416503906, 2.5843634605407715, 2.694286584854126, 2.6665048599243164, 2.639005184173584, 2.4945812225341797, 2.6595730781555176, 2.665123462677002, 2.400172233581543, 2.6209540367126465, 2.5142159461975098, 2.75850772857666, 2.661010503768921, 2.5349438190460205, 2.5771894454956055, 2.6692957878112793, 2.5117146968841553, 2.57657527923584, 2.638451099395752, 2.5243892669677734, 2.5960817337036133, 2.594336986541748, 2.6141140460968018, 2.6987805366516113, 2.5792646408081055, 2.5571844577789307, 2.5939974784851074, 2.615647077560425, 2.6014819145202637, 2.8991644382476807, 2.7861087322235107, 2.7251498699188232, 2.6924588680267334, 2.5958220958709717, 2.5264363288879395, 2.6592905521392822, 2.520965099334717, 2.562593698501587, 2.5519790649414062, 2.503450393676758, 2.6980669498443604, 2.601318597793579, 2.494593381881714, 2.5956337451934814, 2.604081869125366, 2.4793999195098877, 2.6880154609680176, 2.866832733154297, 2.468785285949707, 2.5633435249328613, 2.603691816329956, 3.3572328090667725, 2.478619337081909, 2.5199084281921387, 2.541546583175659, 2.5557608604431152, 2.553804874420166, 2.5967531204223633, 2.5806174278259277, 2.6465976238250732, 2.4230778217315674, 2.5670437812805176, 2.588627576828003, 2.6457326412200928, 2.598128318786621, 2.6038951873779297, 2.52482533454895, 2.6840336322784424, 2.6179540157318115, 2.5466229915618896, 2.470013380050659, 2.6650400161743164, 2.8635714054107666, 2.675459146499634, 2.6632866859436035, 2.6468122005462646, 2.737766742706299, 2.5767006874084473, 2.8039326667785645, 2.4627845287323, 2.5332398414611816, 2.617715358734131, 2.5003106594085693, 2.5997824668884277, 2.5256621837615967, 2.5713560581207275, 2.851297616958618, 2.6339046955108643, 2.591416358947754, 2.638423204421997, 2.5335819721221924, 2.5029170513153076, 2.54425311088562, 2.542964458465576, 2.642146110534668, 2.7250232696533203, 2.6459851264953613, 2.583683490753174, 2.5440754890441895, 2.647686004638672, 2.588254690170288, 2.608555793762207, 2.569023609161377, 2.6852574348449707, 2.6538074016571045, 2.674288034439087, 2.6860649585723877, 2.495147943496704, 2.681267499923706, 2.475633144378662, 2.397674560546875, 2.648665428161621, 2.66436767578125, 2.5152928829193115, 2.586578130722046, 2.7280280590057373, 2.5172224044799805, 2.5310721397399902, 2.6278302669525146, 2.5410854816436768, 2.5122129917144775, 2.7168755531311035, 2.6812736988067627, 2.513828754425049, 2.715787410736084, 2.691666603088379, 2.510399341583252, 2.5507972240448, 2.524381399154663, 2.7438905239105225, 2.5454225540161133, 2.4861505031585693, 2.546719789505005, 2.612621307373047, 2.5629756450653076, 2.5881741046905518, 2.6275250911712646, 2.5160632133483887, 2.466454029083252, 2.7891736030578613, 2.5731074810028076, 2.708115577697754, 2.5936455726623535, 2.5215115547180176, 2.681034803390503, 2.6595966815948486, 2.7982752323150635, 2.5461573600769043, 2.647655487060547, 2.5065646171569824, 2.5320510864257812, 2.5389010906219482, 2.6873979568481445, 2.5278186798095703, 2.738126277923584, 2.7806613445281982, 2.566439151763916, 2.742816686630249, 2.6742794513702393, 2.6442670822143555, 2.7659709453582764, 2.917484998703003, 2.99981427192688, 2.6989598274230957, 2.9366636276245117, 2.6461410522460938, 2.6990721225738525, 2.774977207183838, 2.6476845741271973, 2.6177380084991455, 2.723952293395996, 2.6157925128936768, 2.797585964202881, 2.587071180343628, 2.6583330631256104, 2.5379445552825928, 2.6348254680633545, 2.6205649375915527, 2.887835741043091, 2.542926549911499, 2.707350254058838, 2.550757884979248, 2.6268749237060547, 2.5518038272857666, 2.6906991004943848, 2.6453499794006348, 2.570782423019409, 2.6424551010131836, 2.8223514556884766, 2.7316529750823975, 2.7181406021118164, 2.5899837017059326, 2.6581153869628906, 2.643634080886841, 2.520831823348999, 2.7556095123291016, 2.6679787635803223, 2.6065914630889893, 2.728259801864624, 2.722719669342041, 2.6523094177246094, 2.7782936096191406, 2.564241409301758, 2.895381450653076, 2.7676877975463867, 2.7000110149383545, 2.6663272380828857, 2.5635552406311035, 2.621439218521118, 2.7090258598327637, 2.563422203063965, 2.615654706954956, 2.5795347690582275, 2.5746912956237793, 2.7777483463287354, 2.59619140625, 2.5969905853271484, 2.631132125854492, 2.64184308052063, 2.7043027877807617, 2.6011226177215576, 2.5943005084991455, 2.6744003295898438, 2.7219998836517334, 2.5962471961975098, 2.670196533203125, 2.7338366508483887, 2.477952003479004, 2.5012903213500977, 2.601419687271118, 2.732511281967163, 2.6963255405426025, 2.689059019088745, 2.508220911026001, 2.547903537750244, 2.6089067459106445, 2.6244778633117676, 2.6733930110931396, 2.534928798675537, 2.5945065021514893, 2.6389541625976562, 2.4905905723571777, 2.7210516929626465, 2.8122284412384033, 2.794468402862549, 2.6544899940490723, 2.5881905555725098, 2.7254438400268555, 2.6045432090759277, 2.6956980228424072, 2.7685763835906982, 2.6574456691741943, 2.6096370220184326, 2.6198229789733887, 2.6007983684539795, 2.5415830612182617, 2.597839117050171, 2.826486825942993, 2.556849956512451, 2.5920650959014893, 2.5352983474731445, 2.5818233489990234, 2.683732032775879, 2.434166669845581, 2.762502431869507, 2.4694652557373047, 2.512892007827759, 2.5490007400512695], 'loss': [202.22297414774988, 30.72499985141948, 21.167044121777813, 18.042869043958298, 16.09064204683069, 14.204303772638632, 13.227703965319936, 12.582179977320344, 11.862531048975256, 11.417699260341623, 10.874078527804201, 10.360832862600358, 10.079877917699573, 10.153021744728472, 9.769146912327775, 9.3979124733672, 9.930831399393547, 9.253273151043254, 8.417320083056934, 8.522232918614908, 8.629757531865565, 8.41471970233463, 8.32554067788209, 8.186720772805717, 8.229486605184665, 7.902877563783375, 7.610956942434377, 7.429707643369502, 7.446668785019884, 7.099022247984484, 7.446438906414781, 7.115076180599152, 7.102501978304525, 7.097661413483696, 7.246699552139707, 6.92751955648709, 6.728888260469578, 6.473696969869461, 6.747708388782641, 6.597105752849586, 6.04997021637397, 6.13545509664132, 6.186017395362418, 6.342504705911713, 6.423112949269654, 5.946760944547948, 6.230461710363676, 6.292860173760424, 5.931610663186511, 5.792935519133187, 6.139230489229634, 5.8745295073193615, 5.740785872681047, 5.45246494359143, 5.382598758354056, 5.447191673108938, 5.623746165144323, 5.807488543874383, 5.374739583017283, 5.62093855751653, 5.435645916392303, 5.069106734513475, 5.112707714192559, 5.42677731224247, 4.9674677196022285, 5.031313378307657, 5.184514428350451, 5.1600073629719665, 5.0883542299456135, 5.276831834354327, 4.969470037211302, 4.9595090901965655, 5.1851369417725515, 5.03758661114983, 4.775551712395892, 4.806627114593608, 4.909047807509299, 4.756833190170915, 4.69303476584825, 4.553383226622731, 4.489948642109552, 4.411570276013855, 4.451742276559809, 4.653288463724415, 4.340135789163937, 4.643074916480317, 3.9731048872655497, 4.510550989538153, 4.083747897975381, 4.329608488125922, 4.403782701537319, 4.248304069730132, 4.399666631201566, 4.042261465059098, 4.276191376121619, 4.114933512513141, 4.113124161344344, 4.118032055334912, 3.9930259506359453, 3.762036116432019, 4.082162235760827, 4.0924591009041205, 4.103878417932275, 3.7019318577257594, 3.946574189648489, 3.909888059119928, 3.9225275935029935, 3.957472726127241, 3.9829160104576053, 3.9119334743411707, 3.8740531215328944, 3.7578502693882285, 3.5871442026497484, 4.015147292668519, 3.507022107542833, 3.8699007108240377, 3.778046212568652, 3.8847769627563897, 3.8086399800232167, 3.966064284355249, 3.6696059172985045, 3.564371689809104, 3.6813589518290732, 3.8022082210323074, 3.423071583612489, 3.7396693325778445, 3.459072010968439, 3.647641379642178, 3.6820487943287024, 3.6624127016276953, 3.555146429751577, 3.5632349632176936, 3.5728675179004488, 3.4684809021233054, 3.333994934436458, 3.58239698013707, 3.4328140561570257, 3.345441293326886, 3.2148781754954396, 3.6431256512704246, 3.2005239236178467, 3.665424085544644, 3.303845346922292, 3.364313083592969, 3.3574601310474614, 3.28512167175331, 3.2243825012184804, 3.233670578283408, 3.2661566723602338, 3.31761179762207, 3.0205980877276204, 3.271367954907126, 3.1476177491669373, 3.185597910230667, 3.15267088795343, 3.084728163497014, 3.062264656639359, 3.3072842920489403, 3.179809702186338, 2.899428351924771, 2.9002610072861432, 3.285287866888232, 2.8355273314851437, 3.0481339871835176, 3.1610400678899038, 2.8097451994609663, 2.8258835905293105, 2.900225548361278, 2.991667881504477, 2.674562288826135, 2.954488738899023, 3.04763922643565, 3.0021300680377125, 2.9161906327456566, 2.8589683337088694, 3.108008084195726, 2.8756746261207673, 2.7685925902082444, 2.8854785720371967, 2.929989300521868, 2.959789233643845, 2.4365921395984325, 2.76398952836038, 2.776880376652176, 2.854341908671552, 2.6720069078636826, 2.768305019621051, 2.882917798870904, 2.4667697933977424, 2.4984715707090586, 2.7396611965008733, 2.793428342182313, 2.484054419141205, 2.4943056768733434, 2.684904637809343, 2.443625167419116, 3.003822346006087, 2.638611483051274, 2.844951922466862, 2.723759683430898, 2.524922395784454, 2.6042641127216495, 2.6483950061561887, 2.4182837238343207, 2.669818878460208, 2.781799219500859, 2.461780296850478, 2.4619055125545772, 2.4604197424623124, 2.4038029260144547, 2.5255341711997867, 2.401450864612649, 2.661420690651596, 2.41356179231701, 2.451526541332659, 2.195555209754698, 2.4166097293696067, 2.2394529434740953, 2.374442877811288, 2.2087508209611055, 2.4154728054614774, 2.37311488469559, 2.393031479664378, 2.257250764619061, 2.2998565289028803, 2.174652360705625, 2.1508742226732442, 2.1045450906876013, 2.231356075404079, 2.2594433067974466, 2.1295230252591546, 2.162252606545813, 2.3688143559291817, 2.0707142082387557, 2.0944239304237042, 2.0257133721829286, 1.9578959641948561, 2.087303511253862, 2.1361106894470785, 1.9934309709595843, 2.2581181587353303, 2.0520222468348046, 2.1024117597574303, 1.768259095123999, 2.0306614364988027, 2.058813776147716, 2.1256109898491475, 2.0939955063926146, 1.9655372301380394, 1.801130601045389, 2.1656528745541306, 1.9529239595411565, 2.0020273394036026, 2.0635347559511366, 2.047792789145917, 1.8715261047895446, 1.8987096718924252, 1.8050740746484404, 1.9933209290648177, 1.9717636995773387, 1.8833936244922485, 1.9298614523395852, 1.9834568790958578, 1.819028889933041, 1.8885673207908802, 1.9080526262355382, 1.7824836557716937, 1.8953290244623349, 1.8169945007480461, 1.8106535180250611, 1.7678195227505993, 1.6087097193105286, 1.961936335377338, 1.6025884109293365, 1.8961249020715907, 1.6975018552779861, 1.8605309460721935, 1.5848600735935718, 1.6540945684115742, 1.7359519509696755, 1.6775423160379253, 1.610896016847961, 1.744583832470363, 1.54845065955925, 1.6502645653836074, 1.5618550797363022, 1.6491359688373963, 1.778479282450549, 1.638044792124503, 1.489895460706285, 1.6271101183561985, 1.475715843638988, 1.7725100144295955, 1.666252514711427, 1.3356587916376446, 1.982900723803426, 1.7013356785062228, 1.6144656048087835, 1.654049683993705, 1.7075517855072495, 1.5463508354189712, 1.7191623323725485, 1.5404587186531709, 1.4102155142699673, 1.604222588477737, 1.4955957348176747, 1.5719377895121478, 1.5706554581309367, 1.5814657258123057, 1.4894425092573602, 1.4864840965836583, 1.575982960607632, 1.570206356735881, 1.4744723814693006, 1.503680133141838, 1.445278352574923, 1.4410150236414812, 1.523993273024944, 1.4186948264297838, 1.5232243860078394, 1.602583643099309, 1.3617429689685576, 1.608818176893668, 1.425178589956955, 1.2798108243329414, 1.5519167611255247, 1.4157207636859017, 1.382911158603993, 1.4964460168701306, 1.4850718461738723, 1.5114507114049047, 1.2618884766832665, 1.6116650279813252, 1.278608914962902, 1.534807381516159, 1.3370233843802048, 1.6132905224496379, 1.2489146233961623, 1.3557118809759492, 1.5298192974194582, 1.2641754139450514, 1.255384306682419, 1.4837825687876462, 1.2845547848587182, 1.4418845137959988, 1.3426147081047723, 1.3468732696304684, 1.3659898249545834, 1.2355108005998197, 1.2711624664332482, 1.3900042993096071, 1.4766399239098986, 1.2755968180759563, 1.2759189297332862, 1.3194828175646973, 1.3740193384055661, 1.4010160049172422, 1.2987669655672962, 1.4510333614503883, 1.2771291178820205, 1.2028697724227422, 1.245680213187016, 1.3462502562856167, 1.3624005233013041, 1.2591531850079798, 1.2720554167775389, 1.2996745442672217, 1.2888992352254418, 1.3510013445736837, 1.0979169004401976, 1.228537618468547, 1.1698773018934745, 1.202179530957167, 1.2710690780640115, 1.1292081259143802, 1.1535680913024071, 1.3276841736345761, 1.329870383217303, 1.2501407548798393, 1.3745536261845976, 1.264021073307274, 1.2005994335485721, 1.2875396124044027, 1.073450467568979, 1.2052627815098242, 1.0708282527448227, 1.0582753455640912, 1.118157094593128, 1.2928471202014928, 1.1808246294733944, 1.3047951586047468, 1.299286975195044, 1.1457513222790277, 1.119599716770056, 1.1017749055902104, 1.2323645990526688, 1.1065360651614191, 1.3591450847225703, 1.2263474495343887, 1.2161649143797537, 1.393183959234403, 1.1586848828006209, 1.0716297454549115, 1.1066690567787871, 1.2049803264625742, 1.0262033112970312, 1.1265802313787856, 1.149438976176828, 1.139665599779925, 1.0706495815783734, 1.0998309139491065, 1.141099828058896, 1.087794195428065, 0.9852420640348133, 1.116708894576912, 1.146514694744045, 1.1282463713772928, 1.1537908597316893, 1.0486293151176027, 1.0286355117130779, 0.9984825462426923, 1.1373753584446862, 0.9871298218973072, 1.157090037031657, 1.0520981314822517, 0.930082959649226, 1.2358376348364208, 0.9269005475157953, 1.0744278117371842, 1.073448374545388, 1.093927278053466, 0.9838572843960335, 1.140175580583907, 0.9145571609496923, 1.0907129976706982, 1.056080703348175, 1.0839378838554874, 1.0305281050746313, 0.9594576669016665, 1.0214609055800141, 1.0411918744653257, 1.0610498515189217, 1.0310863027019872, 0.9926660789775035, 1.0531270196335016, 0.984480298904162, 1.034151532899018, 0.9877257903812663, 1.0488154491462705, 1.0257577298151632, 0.9949508176420326, 1.01999565088376, 1.0401836168747238, 1.0315657563614007, 1.164547512929041, 0.9571343291819077, 0.9887508376344671, 1.071457324507533, 0.92773909049703, 1.004477189000087, 0.9806706245893564, 0.9506548107455943, 0.9604572420665934, 0.9161093983763415, 1.0001109821017806, 1.0365981343922954, 0.9964958462140431, 1.15711121775452, 0.9179894414594167, 0.9955497235952664, 0.9701430903194153, 0.9713061848895288, 0.9225416552664575, 1.0409558185595538, 1.0324375581935017, 0.9225250199815731, 0.9929672913794823, 0.8801280000953189, 0.945003212047091, 0.9457829208615727, 1.045766389531342, 0.7654713811660216, 1.0873319799311714, 0.9499956611506073, 0.9443971497239455, 0.8832353014297263, 0.9636254990758305, 0.9701969289142491, 1.0529884825975548, 0.8590900909320865, 0.9540525933630442, 0.9282019797834863, 0.8388575624685173, 0.8590077120627191, 0.944435663569376, 0.8669683953024648, 0.9900936955948457, 0.9087649824178389, 0.9025122692322052, 0.816818284366818], 'mae': [10.551856, 3.6685352, 3.0299442, 2.8030155, 2.5279138, 2.4057925, 2.3294547, 2.2957494, 2.2189393, 2.2059495, 2.1208408, 2.1280951, 2.0580745, 2.045269, 2.026703, 1.9580978, 1.9954629, 1.9887394, 1.945469, 1.9400522, 1.9464287, 1.8676502, 1.8812985, 1.8553342, 1.8386021, 1.8088402, 1.7699599, 1.7499936, 1.7967552, 1.7514658, 1.7965733, 1.7370749, 1.7787768, 1.7883207, 1.7545669, 1.702989, 1.6646074, 1.5900639, 1.6954708, 1.6244633, 1.5816832, 1.6227573, 1.5696177, 1.6212652, 1.5870346, 1.6384331, 1.628866, 1.584523, 1.5838333, 1.5535696, 1.554077, 1.5039873, 1.56805, 1.4936209, 1.561458, 1.5311627, 1.494147, 1.4801031, 1.505225, 1.5192939, 1.5164422, 1.4811606, 1.4970157, 1.4612837, 1.4415832, 1.4633493, 1.45522, 1.4719994, 1.4821553, 1.4749148, 1.5090928, 1.4174156, 1.4311006, 1.4005845, 1.4229038, 1.3874915, 1.4575969, 1.4467158, 1.3955607, 1.3876524, 1.3447886, 1.4385431, 1.3962138, 1.3764948, 1.3948579, 1.3759973, 1.3655388, 1.4369798, 1.2826086, 1.3273741, 1.3571482, 1.3086013, 1.3742133, 1.3497404, 1.3060275, 1.3227115, 1.330275, 1.3466986, 1.349638, 1.2878648, 1.3052926, 1.2649544, 1.2818, 1.2469321, 1.3091285, 1.2950562, 1.2798686, 1.306385, 1.2875351, 1.2749101, 1.2859559, 1.2614822, 1.2187188, 1.2309563, 1.2297399, 1.2167748, 1.2683734, 1.2447495, 1.2780387, 1.2387528, 1.2155936, 1.2444961, 1.2313277, 1.206044, 1.2032881, 1.1887388, 1.1508807, 1.1786338, 1.2104794, 1.2246022, 1.1938545, 1.1599585, 1.193293, 1.1540384, 1.2061616, 1.145905, 1.1856861, 1.1429081, 1.1834304, 1.1833576, 1.1140712, 1.1617545, 1.1780198, 1.2009573, 1.1810182, 1.115432, 1.1067244, 1.160387, 1.1375874, 1.1592256, 1.1583054, 1.1308298, 1.157435, 1.1216058, 1.1371515, 1.1338744, 1.1271392, 1.1989365, 1.1065801, 1.0737106, 1.1198065, 1.1509124, 1.112622, 1.1157295, 1.089148, 1.1418095, 1.0790057, 1.1086967, 1.1214777, 1.0709716, 1.0446088, 1.1236017, 1.1102452, 1.0332085, 1.0435224, 1.0579278, 1.0964651, 1.0479592, 1.1054859, 1.0734178, 1.0789467, 1.0666747, 1.1072519, 1.0978663, 1.1016479, 1.0555698, 1.0495666, 1.125597, 1.0672715, 1.0337493, 1.072201, 1.0840716, 1.108967, 1.0468454, 1.086445, 1.0164058, 1.1241866, 1.0982395, 1.0938156, 1.0573493, 1.023141, 1.0482675, 1.0457455, 1.0291429, 1.0214974, 1.0622643, 1.0225046, 1.0316309, 1.0384691, 1.0593615, 1.0367168, 1.0199673, 1.0656031, 1.0677642, 1.013728, 0.9645082, 1.0038754, 0.9851152, 0.9755626, 1.0348696, 1.0135536, 1.0247977, 1.0545161, 0.9847657, 1.022185, 0.9886768, 0.992884, 0.94400406, 0.99978626, 1.018618, 1.0048711, 0.9517758, 1.0039307, 0.9690781, 0.96409553, 0.9543568, 0.97378814, 1.0200268, 0.98698246, 0.9414264, 0.9837457, 0.97467464, 0.97551453, 0.9218172, 0.97572654, 0.993173, 0.9832668, 0.97315156, 0.9392125, 0.9583736, 0.9973913, 0.97749, 0.9759339, 0.94003224, 0.9582307, 0.9588187, 0.95095503, 0.95310324, 0.9934889, 0.9719727, 0.9341466, 0.95500845, 0.9481274, 0.90291625, 0.9189173, 0.91372156, 0.9308625, 0.938022, 0.9295591, 0.9406011, 0.93986315, 0.88072675, 1.0038968, 0.9029287, 0.9629686, 0.91440344, 0.9276005, 0.8954095, 0.9121377, 0.9291021, 0.9302326, 0.87973475, 0.91196513, 0.8997556, 0.9344828, 0.8780862, 0.923763, 0.89162827, 0.88513756, 0.8656448, 0.889082, 0.8687579, 0.9124683, 0.9256618, 0.813666, 0.9410259, 0.87241244, 0.89275813, 0.89749, 0.8934916, 0.8766878, 0.8869197, 0.8742136, 0.8441158, 0.8523275, 0.8643684, 0.87644225, 0.8860433, 0.8763495, 0.849176, 0.88385576, 0.87391716, 0.90565, 0.8689714, 0.8437198, 0.86123157, 0.8400332, 0.89581966, 0.8453381, 0.86588895, 0.8956845, 0.8269098, 0.88493764, 0.8721192, 0.81019205, 0.85241073, 0.8684481, 0.86720854, 0.8617893, 0.8424635, 0.8743678, 0.81457996, 0.906019, 0.80637854, 0.8724228, 0.82897687, 0.8765146, 0.81979096, 0.84765345, 0.8491637, 0.81383747, 0.80486035, 0.88599235, 0.82895005, 0.83498436, 0.8618174, 0.83855927, 0.79850006, 0.77937907, 0.80968994, 0.82704276, 0.8697085, 0.7898496, 0.80814725, 0.8026677, 0.8428812, 0.7975988, 0.79658026, 0.83478767, 0.7924738, 0.7936856, 0.80924094, 0.81598043, 0.8396183, 0.7798748, 0.8192597, 0.787999, 0.80364406, 0.8489215, 0.7678256, 0.79495585, 0.7789384, 0.7879979, 0.8171565, 0.7620243, 0.7510748, 0.8117395, 0.7752734, 0.7382671, 0.7834075, 0.78746027, 0.7892412, 0.80040497, 0.74774414, 0.78121614, 0.74985254, 0.740039, 0.7744799, 0.7865827, 0.7756999, 0.8001169, 0.7901595, 0.76351464, 0.75845456, 0.76613224, 0.8112783, 0.73312443, 0.7890968, 0.7458925, 0.7580977, 0.7745706, 0.76752037, 0.74678963, 0.7542904, 0.7769998, 0.72254765, 0.768354, 0.769672, 0.7794679, 0.73549485, 0.748352, 0.78752095, 0.7292776, 0.69965136, 0.74205476, 0.7459096, 0.78998524, 0.77133024, 0.75891304, 0.7321083, 0.7405591, 0.7423925, 0.7015983, 0.72006637, 0.73568875, 0.7148544, 0.8004508, 0.6889212, 0.71613234, 0.7597125, 0.7324243, 0.7340443, 0.77854884, 0.7171923, 0.75929725, 0.7470925, 0.7281091, 0.7183947, 0.7230091, 0.7048469, 0.7314453, 0.7296491, 0.73039395, 0.70179194, 0.7590089, 0.7087129, 0.70675856, 0.70124376, 0.7379684, 0.74066895, 0.718118, 0.71086645, 0.7269456, 0.71254146, 0.75384927, 0.6985519, 0.71808696, 0.74134773, 0.68950653, 0.7212387, 0.71376836, 0.7080318, 0.680977, 0.6578417, 0.7071062, 0.7278211, 0.68775296, 0.7393757, 0.6751166, 0.69119817, 0.7072977, 0.7247177, 0.6852254, 0.70629805, 0.6905452, 0.7073992, 0.6811748, 0.6937007, 0.71650904, 0.7209057, 0.71216905, 0.61836195, 0.7530597, 0.690817, 0.7005322, 0.66350424, 0.6936102, 0.69226384, 0.713665, 0.6659026, 0.6893667, 0.68345916, 0.6700285, 0.7036669, 0.670154, 0.6568848, 0.7247278, 0.6947381, 0.7065016, 0.6442503]}\n"
     ]
    }
   ],
   "source": [
    "# Since we do not have much data we use the k folding approach.\n",
    "# E.g if we split out data into 3 segments [data][data][data]\n",
    "# Then we would have 3 iteration:\n",
    "# 1. [validation data][training data][training data]\n",
    "# 2. [training data][validation data][training data] \n",
    "# 3. [training data][training data][validation data] \n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 500\n",
    "all_mae_histories = []\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1)\n",
    "    print(history.history)\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    \n",
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history) \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
    "\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()\n",
    "# We see that the loss function gets worse after epoche 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 160us/step\n",
      "2.675260305404663\n"
     ]
    }
   ],
   "source": [
    "model = build_model() \n",
    "model.fit(train_data, train_targets,epochs=80, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "print(test_mae_score)\n",
    "# TODO: how to read this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_python_3_6",
   "language": "python",
   "name": "env_python_3_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
